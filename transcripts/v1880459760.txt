Hallo leute ich muss noch mal kurz aufs klo
so jetzt
Irgendwie habe ich in dem moment wo ich auf starten vom stream geklickt habe habe ich habe ich gemerkt es drückt ein bisschen
das war schnell noch aufs klo so jetzt bin ich ja wieder da
50 milliarden bits pog
erzähle euch auch gleich was wir heute machen
ausierungs champ
erst mal was trinken
small access point auch am start
Wir machen schon mal vor der stream so richtig losgegangen ist
Ich mache schon mal meine vm an heute mal 5h serveradministration ja unter anderem
Aber erst mal mache ich updates von meiner vm was da alles aktuell ist und ich muss mich bei google einloggen
So dass ihr das passwort nicht mitkriegt
So updaten wir erst mal wie warum habe ich da so viel pac-man sachen in das
So erst mal hier alles updaten
Gibt es neuigkeiten aus der arbeit bis nene bin ich nicht
Ich habe ich habe noch nicht offiziell zugesagt
So wir machen erst mal schnell package updates auf der vm dann starte ich die vm neu und dann erzähle ich euch was wir heute
machen
Aber ich könnte mich eigentlich cloud mäßig schon einloggen
Anmelden das nicht anderes konto verwenden
Skript
clipboard ausschalten
So tschätzke ihr müsst ihr müsst kurz weg gucken oder oder versprecht ihr nicht auf dem monitor zu gucken
Ihr dürft das passwort und den benutzernamen dürft ihr sehen aber das passwort dürft ihr nicht sehen
Das ist ein fake account bzw. ein fake account ein
eine account den ich extra für 200 300 dollar
Don't save ja das ist extra ein account den ich gemacht habe um
200 200 oder 300 dollar gut haben mal wieder zu bekommen für google cloud weil es für bastel ein immer ganz ganz nützlich ist
Alles klar passt ich mache euch wieder an ich mache euch wieder an
hoffe ich habe nichts geliegt jetzt
Ja sage ich was gleich zu wenn ich
Css der größte scheiß euer da gebe ich dir recht css ist wirklich abfuck
Abfuck
Wir haben aber ziemlich schlaue leute hier im stream wenn wenn es um css geht
Die kannst du ja konsulten
Und die lassen sich bestimmt auch konsulten gegen bezahlung
Wenn es was größeres ist also ich glaube bei mortges kann man auch so mal helfen
So das haben wir überall geupdated
Und jetzt rebooten wir die vm dann erzähle ich was was wir machen
Also folgendes
Ich versuche ich das mal kurz zu erklären
Was wechselst du vielleicht die abteilung
Ne mache ich nicht
Das ist eine gute idee
Ja lokale links vor allem ist also ein mindestens bsl aber richtig echte vm ist natürlich noch besser
Also was machen wir heute und zwar habe ich was gefunden bei google
Was ich unbedingt mal ausprobieren weil ich mir denke dass das auch bei uns auf der arbeit enorm praktisch sein könnte
Und ich dachte mir ich probiere das einfach mal hier aus dazu braucht man aber eine google cloud leute beste
lachs mit nudeln
Kek wait
Konsole google cloud
Wie viel geld habe ich noch leute 13 euro habe ich schon ausgegeben stell dir mal vor 13 euro von
275 credits habe ich just
Nein, wir aktivieren nicht volle count
Ich versuche seit fünf irgendwie zu schaffen dass ein dip sich fix auf die höhe des verfügbaren horizontalen
Okay, das erste das erste weiß ich wie es geht das ist das ist
Juhu with oder sogar es gibt vh oder hv oder vh
Nee
View with oder irgendwie so gibt es auch sobald in css ich glaube es ist es ist vw
Irgendwie so so also das das ist das einzige was ich kann
Es scrollbar da hört es bei mir schon auf
Da hört es bei mir auf css ist komplett
Da bin ich zu low IQ vielleicht fehlen wir einfach die prime subs dafür
Kannst du knicken css kriege ich auch immer nicht gebacken
Nee nee das wird er sicherlich schon ausprobiert haben ganz so einfach ist es nicht
In dem fall was sagt chat gpt wahrscheinlich irgendeinen schrott
Ja genau aber ich wollte euch erzählen was wir machen und zwar
Habe ich folgendes vor ich habe folgende sache gefolgt ich denke ich zeige euch das mal kurz ich zeige ich zeige euch mal kurz
Wir sind jetzt hier bei google in der cloud also ich habe noch ungefähr 250 euro übrig das sollte für heute reichen
Und ich glaube meine meine meine trial geht
Bis 21 oktober kann ich die kohle ausgeben also das passt schon
Also ich zeige euch mal was also wenn man hier auf sql geht da kann man eine datenbank in der cloud anlegen
Jet kurze kurze umfrage wie sieht es mit euch aus
So erfahrt
erfahrung cloud platform ich meine ich kann da auch vielleicht noch ein paar sachen dazu sagen und kann ich jetzt vielleicht mal eine viertelstunde
bisschen ein bisschen länger ausholen was wir eigentlich machen aber ich glaube es ist was mega nice ist was vielen auch was bringen könnte tatsächlich
Ich war mal eine umfrage ich mache mal eine umfrage
Erfahrung mit cloud anbietern
Übrigens leute ihr wisst ja dass man es nicht mehr cloud anbieter oder cloud provider nennt wie nennen die coolen leute das
Wer wer wer weiß es wer ist high iq
serverless
hyperscaler korrekt also ich war ich war mal eine umfrage
Erfahrung mit cloud anbietern und falls jemand erfahrung hat mit mehr als einem cloud anbieter
Dann nimmt er den cloud anbieter wo er sich am besten mit auskennt ok
Interessiert mich einfach mal oder oder wenn er sagt gar keine ahnung dann nix
Also das ist gcp das ist aws das ist asia
Nee hetzer erzähle ich mal in dem fall nicht hetzer ist ja kein wirklicher cloud anbieter auch wenn sie hetzer cloud heißen kannst bei
hetzer vms professionieren
und load balancer das war's
Die haben keine managed startenbank und sonstige geschichten wobei das das hoffe ich ja dass sie das noch machen das wäre mega nice
Hetzer ist besser als die drei wie ich finde wenn es rein um vms professionieren geht wenn es wenn es kurz und knackig gehen
Das ist hetzer top und günstig
Das ist eigentlich auch der riesen vorteil bei hetzer
Wenn man sich anguckt wie lange so ein kubernetes cluster bei google professioniert da sitzt erst mal 20 minuten müssen wir gleich auch noch machen
ok
Also also ich würde sagen die meisten leute haben erfahrung mit microsoft asia
gefolgt von aws und dann google
Was ich witzig finde das ist genau
entgegengesetzt
Naja nicht ganz ich glaube ich glaube von der verbreitung her ist aws das weit verbreitetste
sogar das most loved laut stackoverflow
Und ich glaube danach kommt asia und dann kommt google irgendwie so oder google und asia um den vergleich auf aber aws ist meistens meistens ganz ganz vorne
Leute ich fühle mich irgendwie so ein bisschen
Also irgendwie nicht so hundertprozentig fit ich muss mal kurz eine runde durch den durch durch das zimmer springen oder so dass ich dass ich
Bisschen aufwache ich war jetzt ungefähr so eine halbe stunde habe ich gerade im bett gelegen weil die katze der meinung war sie will
sich da jetzt hinlegen ob ich nicht mitkommen kann die klotz mich dann viertelstunde an
Seid auf katz ich lege mich jetzt mal kurz aufs bett kannst du nebenlegen bis die katze gestreichelt
Da bin ich so hundertprozentig fit
Okay, nix hat gewonnen
Ich muss mal kurz ich jump mal kurz eine runde durchs zimmer dass ich wach bin
Nicht ganz fit war da hat man einfach mal kurz zwei drei minuten voll drauf rum geklopft und dann war alles dann war man passend
Passende puls und herzfrequenz gehabt
Okay
Hoffentlich bin ich jetzt fit nee ich brauche nicht wieder einen boxsack wie in der alten wohnung das war mega praktisch
facecam wäre jetzt witz kann ich mir vorstellen
Hier kann ich aber nur einen boxsack nehmen den man hinstellen kann
Weil hier ist die decke also in der alten wohnung hatte ich auch einen den man hinstellen kann aber
Hier kann es auf jeden fall schon mal nix an die decke machen
So, okay, bisschen durchs zimmer gehüpft
Also ich habe die umfrage jetzt nicht beim kopf, aber ich glaube es hat nix hat gewonnen
gefolgt von
Microsoft und dann abs und dann google also was wir heute machen ist folgendes
aufblasbar was ist
Aufblasbar was ist
Nee die dinger sind kacke das muss schon ein bisschen was drin ist das sind auf aufblasbare boxsäcke sind nix
Das braucht das muss braucht schon ein bisschen widerstand und gewicht sonst kannst du da überhaupt nicht richtig richtig reinhauen
Gut also gehen wir mal hier wieder rüber und zwar ich erzähle ich erzähle mal so ganz ganz grob was wo wir hier
Eingeloggt sind das ist die klaugen die klätte klaugel leute
Die cloud plattform von google
Das was oftmals auch so als gcp läuft google cloud plattform und das steht wenn man sich einloggt sieht das so aus cloud
Geh genau wenn man sich einloggt sieht das so aus das ist aktuell ein trial account kann sich übrigens jeder aufmachen der bock hat
Wenn ihr euch dort anmeldet mit einem neuen account kriegt ihr 300 dollar also 275 euro gratisguthaben für
drei monate
Und das beste daran ist dass ihr auch nicht aufpassen müsst irgendeinen miss zu bauen weil solange hier nicht drauf klickt
Auf activate voll account könnt ihr nie über diese 300 dollar kommen das heißt selbst wenn ihr jetzt
den mega kubernetes cluster aufbaut mit sonst was für notes
Dann klappt das nicht
Ihr seid ein bisschen beschränkt
Ihr seid ein bisschen eingeschränkt in der trial phase was ssd speicher angeht ihr könnt pro
region glaube ich maximal 300 gigabyte
was
Ich habe vms noch noch übrig
Ich habe überhaupt keine vms angelegt das will das von mir weil das ist ja auch das projekt hier
Egal ich habe noch genug vor
Ich habe kein kubernetes cluster laufen das ist es ist nichts da
Ob es
Es ist es ist nichts da
Ich glaube das hat einfach nicht geupdated das quota dass das hat das zeug manchmal das packt manchmal ein bisschen rum
Zumindest
Wenn ihr euch wenn ihr euch so ein account macht
Ihr müsst keine angst haben dass ihr irgendwie arm werdet weil sobald ihr bei 300 dollar angekommen seid dann geht nicht geht nicht mehr
So das heißt wenn ihr euch bei google in der cloud einloggt das erste was ihr seht ist diese startseite hier oben könnt ihr projekte anlegen
Ich mache mal ganz jetzt im schnell schnell durchlauf dass sie ungefähr nachher mit mitkommt was wir heute machen
So oder ihr könnt euch projekte anlegen standardmäßig ist glaube ich mein test project oder irgendwie sowas angelegt zumindest
Das wichtigste was ihr wissen müsst bei google cloud ist hier neben dieses menü wenn ihr das ausklappt da könnt ihr alles machen
Wenn ihr das ausklappt da könnt ihr alles machen standardmäßig sind hier schon so die üblichen verdächtigen
Eingeblendet aber google hat noch deutlich mehr ja da blickt man dann gar nicht mehr durch wenn man den ganzen mist hier einblendet
Aber damit damit kommt man in der regel eigentlich schon wieder schon schon ganz gut aus also das wichtigste was man eigentlich braucht sind
Dieses ist das hier compute engine compute engine ist für 4ms das ist quasi der part den hetzer auch machen kann
So dieses eine tab hier im endeffekt hier kannst du 4ms anlegen ja kannst 4ms anlegen kannst vor allem templates anlegen kannst
Discs snapshots images alle möglichen was für 4ms braucht
Dann kann man also man kann angeblich auch bare metal server habe ich noch nie ausprobiert
Weiß gar nicht ob man das mit seinem quota quota machen kann
okay anscheinend kann man auch
Echte echte hardware server habe ich noch nie ausprobiert keine ahnung wie das funktioniert
Also wenn es das hier ist 4ms das hier ist manage kubernetes das hier ist storage also s3 storage
Das hier ist no sql und das hier ist wer hätte das gedacht
Manage datenbanken manage datenbanken darum geht es heute auch unter anderem gibt es mysql postgres und ja leider
den gibt es auch
Aber wir machen heute was mit postgres
So das ist eigentlich erst so alles was man auf die was man auf die schnelle wissen muss hier macht man netzwerksachen drüber und cloud run
Cloud run ist eine ganz coole funktion wenn man irgendwelche container hat die man einfach nur starten möchte und laufen lassen will ohne kubernetes ohne alles
Komplett komplett managed ich muss mal ein bisschen wupp wupp wupp anmachen
bisschen bisschen wupp wupp wupp ohne
Eise bisschen entspannung wupp wupp wupp genau und ansonsten
Gibt es noch
1000 sachen die man sonst noch bei google in der cloud machen kann also es gibt
Es ist manchmal ist das interface broken
Es gibt die die üblichen verdächtigen ihr könnt zum beispiel nach maps suchen
Dann könnt ihr sachen wie google maps und so dort einrichten aber
na ja
Aber es gibt es gibt tausend sachen von von service mesh bis edge computing
cloud
functions
rpgateface
Dinger wo ich keine ahnung habe was es ist ich weiß nicht mehr was
Ist alloy nicht die aus horizon zero dawn
alloy db
Big table das ist die alte no sql datenbank glaub von denen
redis
memcache
Also haben tausend sachen drin ist es jetzt nicht so als würde ich da bei allem durchblicken
Da gibt es wirklich da gibt es alles da geht es gar nicht die welt ja
Es gibt auch eine eigene container registry beziehungsweise artefakt registry die soll man ja eigentlich gar nicht verwenden für container images und sowas es
Gibt es gibt alles irgendwie es gibt auch pubs ab wer irgendwie eine message queue braucht alles mögliche
Ja das ding als spanner das ist auch irgendwas mit datenbanken ich bin mir nicht sicher was es genau ist
Ja cloud spanner
Fully managed relational database
Okay, das ist quasi das ist quasi die die sql datenbank von google wenn man keinen bock hat auskreis zu verwenden
Cloud spanner keine ahnung habe ich noch nie verwendet
Zumindest folgendermaßen was was ich heute machen will ist folgendes
Ich möchte eine datenbank instanz erstellen und dann auf die datenbank instanz zugreifen allerdings
jetzt kommt
Ohne
Dass ich direkt einstelle auf welche datenbank ich zugreife und ohne dass ich ein password dafür brauche und trotzdem sicher
Also ich muss euch das ich muss ich das gleich mal aufmalen wir stellen jetzt einfach mal eine datenbank dass ihr gesehen habt wie das
Funktioniert also es gibt drei varianten grundsätzlich wie man in der google cloud sachen erstellen kann
So eine datenbank setzt sich zusammen aus einer vm
Werdet ihr auch gleich sehen das kann man bei google in den docks lesen was das ist so eine datenbank ist unter der haube ist
das eine vm
Allerdings eine komplette managed vm die dann auch sich um so sachen wie
Backup für datenbanken kümmern kann und snapshots und recovery und alle möglichen dingern
zumindest
Wir erstellen jetzt mal eine datenbank es gibt drei es gibt grundsätzlich drei verschiedene arten wie man bei google in der cloud
Ressourcen erstellt wie zum beispiel so eine datenbank
Das erste ist und das offensichtlichste
Ist hier im web interface einfach sich die datenbank zusammen klicken wie man die haben will das ist in der regel relativ
Selbsterklärend man gibt dem dingen namen man gibt dem postgres user oder sagen wir dem admin user ein password hier zum beispiel kann man eins
eins generaten
Man kann aber auch selbst eins vergeben
Allerdings leckt
Das funktioniert man kann die datenbankversion auswählen und so ein bisschen
slas und und cpus und so was in der richtung
Und noch auswählen wie groß und wie klein die kisten sein sollen wir nehmen wir sehen jetzt mal hier eine development kiste
Oder hier das ist sandbox kiste reicht theoretisch auch aus development kiste also wir brauchen ja nicht wirklich viel wir machen mit der datenbank nichts
Genau und da kann man hier unten noch einstellen wo man das ganze hosten will wir wollen nach eu west oder europa
europa west 3 weil das ist frankfurt
Und da kann man auch ein paar andere sachen hier unten einstellen wie zum beispiel
wie viel speicherplatz man dem ding geben möchte und
Wie man darauf zugreifen will ob das ding eine public oder private ip bekommen soll
Ist eigentlich
Willst du dich lieber selber das db nee es geht mir explizit hier und postgres jetzt
Das ding kriegt eine private ip wobei wir haben noch kein network angelegt da war das ich lasse das mal ich lasse das mal in den
Cluster aufbauen so da gibt man den namen an hier mega
Nice
db brot
oder so was
Und dann kann man auch ein passwort
generate chat generatieren
und wir sagen
Ja, wir legen die erst danach dem ich netzwerke und sowas angelegt haben so so funktioniert das ist die erste variation
Wie man sachen bei google cloud anlegen kann das nächste ist
Nein, ich habe doch gar nichts angelegt das nächste ist über das google cloud command line tool
der iron champ
Pippo ist am bügeln also bei google cloud
Da kann man mit dem google cloud cli kann man sachen anlegen und das nächste ist
Errorform
Errorform ist ein tool da kann man einstellen das benutzen übrigens jetzt auch gleich da kann man einstellen was man anlegen will in der
Cloud und dann er bleibt das dass ihr werdet gleich sehen wir benutzen ein repo was es schon gibt
Nämlich bei mir auf github
Habe ich vorhin sogar was gepusht ja das da
Können wir gleich mal klonen
Das wäre dann wenn wir dann gleich gleich mal ausführen
Genau so
Und was wir heute machen werden ist folgendes lange rede kurzer sinn also wir legen eine datenbank an in der google cloud
In der postgres datenbank mysql oder so ist jetzt nicht so wild aber wir nehmen eine postgres datenbank
Und wir bauen unseren kubernetes cluster auf wir können auch einfach vms aufbauen im prinzip macht es keinen großen unterschied
Und dann gibt es jetzt die möglichkeit das habe ich nämlich letztens erst mal google gefunden gcp
aus proxy
Aber es gibt nämlich die möglichkeit dass man wenn man anwendungen in der cloud laufen lässt
Und auf eine auch in der cloud gehostete datenbank zugreifen will
dass man nichts mit connection strings hantieren muss und auch nicht mehr mit passwörtern hantieren muss für die für die
Datenbank da gibt es bei google sowas das nennt sich cloud sql aus proxy
der sieht dann
Das sieht dann so aus im endeffekt trifft es trifft es eigentlich ganz gut
Die anwendung von einem selbst also die anwendung die man ausführen will also normalerweise ist es so ja man hat hier seine kleinen vm
Und man hat hier eine datenbank
Und man braucht ein connection string zur datenbank also beispielsweise die ip von der datenbank
Man braucht ein user in der datenbank und man braucht ein passwort für die datenbank und dann greift er hier direkt darauf zu
Es gibt jetzt allerdings die möglichkeit
Das ist jetzt nicht neu aber das habe ich noch nie ausprobiert das ist aber mega nice
Dass man das über einen proxy macht und der proxy den kann man so einstellen dass er auf local host lauscht
Also quasi dort wo auch die anwendung läuft auf local host auf port 5000 zum beispiel standardmäßig und dann kann die anwendung hier
Braucht nicht mehr jedes ganze datenbank connection zeug können sondern
Du kannst bei der datenbank du kannst bei deiner applikation einfach einstellen meine datenbank ist auf local host port 5000
Und dann geht das an den proxy und der proxy geht an den endpunkt und dann zur datenbank instanz damit das ganze funktioniert
Musst du natürlich ein proxy erst mal starten logischerweise sonst klappt das nicht weil ich muss mal kurz hier licht licht dann machen
Decke jawohl
Also muss natürlich vorher eine proxy starten wir werden das ganze aus dem kubernetes cluster raus machen aber muss wir müssen uns doch gar nicht
So sehr gedanken um kubernetes machen
Man muss den muss den proxy starten man muss den proxy einmalig sagen zu welcher datenbank er connecten soll
Und jetzt kommt jetzt kommt der trick und das ist der grund warum ich das auch ausprobieren will bis zu dem zeitpunkt
bräuchtest du immer noch ein user und ein password für die datenbank weil ich meine damit hat der proxy ja nicht so wirklich was zu tun
aber
Es gibt jetzt seit nicht es ist noch nicht so lang dass es die möglichkeit gibt man kann diesen proxy client so einstellen
dass er das authentifizierung
Zeug von der google cloud direkt benutzt also sprich wenn ich beispielsweise sage
Meine vm also man kann wenn man wenn man vms erstellt hier bei google
Oder auch kubernetes cluster erstellt da kann man sagen dass die mit einem service account laufen sollen
Und diesem service account kann man verschiedene rechte geben
Und man kann es jetzt so einstellen in den proxy dass der proxy quasi den service account nimmt
Der vm oder des clusters auf dem er läuft auf dem der attached ist der service account
Und wenn der service account auf die datenbankinstanz zugreifen kann dann brauche ich kein password mehr solange ich eben vom proxy auf dieser vm komme
Das ist man könnte sagen oh das ist ja eigentlich ein sicherheitsproblem aber genau genommen ist es gar nicht so schlimm oder ist es eigentlich
Gar kein sicherheitsproblem weil der proxy der läuft ja nur auf local host auf dieser kiste
Das heißt damit dass jemand ausnutzen könnte müsst ihr halt auf die vm kommen oder in den container kommen
Dafür hast du den riesen vorteil du musst nicht mehr mit datenbank secrets rum hantieren
Und du musst dich auch nicht um connection strings und sonstige geschichten in der config in einem cluster in der anwendung sonst für kümmern
soweit soweit die idee
Und das ganze wollte ich mal ausprobieren damit wir das ausprobieren können
brauchen wir ein kubernetes cluster
Und da benutzen wir das gleiche was wir das letzte mal schon
Mit gar nicht sicher ob ich das hier noch mal klonen kann ich muss mal kurz gucken habe ich hier vielleicht etwas modernere version davon am start
Auch nicht wirklich oder
Ist eigentlich mehr oder weniger das gleiche
Dann erkläre ich euch das auch gleich mal kurz wenn wir das hier haben weil
Boah ich habe schon gedacht ich habe mein passwort irgendwie rein copy pasted liegt monkaS
Ich hoffe ihr seid nicht drin direkt ihr habt nicht auf dem monitor geguckt sehr gut chat
Yes wir trusten dem
Also wie ich gerade erzählt hat man kann in der google cloud es auf drei verschiedene wegen aufbauen hier über das webinterface über das google
Cloud cli oder über terraform dass die die terraform geschichte zeige ich euch zeige ich euch gleich wir müssen uns als erstes mal kurz einloggen
gcloud
also mit dem command line
Login geht das glaube ich
Nicht in dem browser falscher browser
alter browser
Max pogu wollen wir verwenden
allow
You are now authenticated für max pogu sehr schön
Your current project is keckel stream 1 nein das ist falsch ich will set project id
auf
mein aktuelles projekt setzen hier pro talon
Da soll das hin das ist ein random generierter projektname
So und jetzt haben wir uns authentifiziert gegen die google cloud jetzt können wir so sachen machen wie
gcloud
compute
compute
instance list und solche geschichten
Instanzes list
Genau da kann man sich die vms oder oder ich kann beispielsweise eine vm erstellen oder solche geschichten
Aber wir werden das google cloud cli gar nicht wirklich verwenden man braucht aber das login dass das funktioniert wo wir gerade dabei sind
Ich muss mal kurz gucken wie man
Gcloud component man kann das ding nämlich auch updaten
components
Update
Ich will nicht opt innen
Yes
Ja, wir updaten gerade mal den ganzen kram
Ja, ja, ja meistens schon
Das ist aber
sag mal so die bezeichnung sind da
Variabel ja also es kann auch sein dass es eine infrastruktur gene team gibt es kann auch sein dass ein cloud
Kompetenzteam oder irgendwie sowas gibt die das machen es kann auch sein dass es schlicht und ergreifend
Irgendwelche admins sind die das ganze mal geerbt haben das zu machen also das ist ein bisschen ein bisschen unterschiedlich ja aber sag mal so
Meistens sind die teams und abteilungen dann so gebaut das schon so die ganze alles was was
Mit cloud technologie zu tun hat so ein bisschen zusammenfasst weil es einfach meistens komplett anders läuft als wenn den eigenen server im rechten zentrum stehen
Deswegen ist es auch sinnvoll wenn du die
Das know-how für eine sache so ein bisschen zusammen hast gerade auch für alle anderen die da was benutzen wollen dass die eine zentrale stelle
Haben wurde fragen kannst
Bei der way wir haben eigentlich noch gar nichts gemacht
Wir haben uns gerade über google cloud angemeldet und haben uns das hier aktualisiert so und jetzt zeige ich euch mal mal in terraform also
Wenn man hier bei google cloud ist wie gesagt ich habe ja gesagt ihr könnt sachen anlegen über das webinterface über das google cloud
Cli oder über terraform terraform ist ein
Infrastructure as code tool das haben wir hier im stream schon öfters mal benutzt also
Wenn ich es ganz genau wissen wollte wie wir das unter anderem erstellt haben hier könnt ihr euch den stream im archiv angucken wo wir das
Benutzt haben zumindest terraform ist dafür da dass man reproduzierbar
Cloudinfrastruktur aufbauen kann und ich zeige euch mal ein beispiel in dem fall ich glaube es ist relativ überschaubar
So was wir jetzt anlegen wollen in der cloud
Glücklicherweise das ganze gibt es übrigens bei mir auf github wenn ihr euch das angucken wollt und
Ich habe es glücklicherweise auch mal ordentlich halbwegs ordentlich benannt
8000 zeilen ansible script was was machst du gerade
Was was soll am ende rauskommen also was wir in der google cloud brauchen ist folgendes wir brauchen
ein netzwerk
Wer hätte das gedacht ein nicht öffentliches netzwerk brauchen wir in der google cloud
Damit wir unsere vms und unsere datenbanken und unseren cluster verbinden können
Netzwerke legt man in der google cloud über terraform so an man sagt ihm hier man will ein netzwerk anlegen was
Regional ist also es gibt bei google in der
Sebasu-Chan dankeschön für den sub
IQ ist wieder richtig ins steigt ins unermächtliche im chat ich sehe schon an ihr wisst ja jeder prime sub mehr
IQ-Punkte für alle das wird das wird das wird halt auch ein bisschen durch die anzahl der user
Geteilt also sprich je mehr leute zugucken im stream je mehr prime subs brauchen wir auch gerade um das notwendige
IQ level zu maintainen
nur mal so nebenbei
angemerkt ja also
Wir brauchen jetzt natürlich ein netzwerk in der google cloud
Um das miteinander verbinden zu können was wir bauen an vms und klassen und sonst was das ganze ist regional genau das wollte ich erzählen
Bei google ist es so und das ist bei aws vermutlich auch so bei asia ist es so da weiß ich aber
Wie es bei aws ist weiß ich nicht habe selbst aws noch nicht so oft benutzt vielleicht jemand chat wenn ihr ahnung von aws habt
Könnt ihr mir mal sagen wie das bei aws ist also es gibt bei google gibt es zonen und regionen
so
Eine region setzt sich bei google aus mehreren zonen zusammen es gibt zum beispiel die region
europa west 3
europa ist drei ist frankfurt germany europa
Bei aws ähnlich ja bei asia auch ich gehe davon aus dass es mehr oder weniger bei allen cloud anbietern so sein wird bei
Bei hetzer gibt es das ganze auch
Sagen wir mal etwas light die variante davon
John can play dankeschön für den sub
exzellent subscription
Dankeschön für den sub
Bei hetzer gibt es das auch allerdings hetzer hat keine unter regionen sondern hetzer hat quasi nur einzelne regionen ohne dass man das jetzt genau
einstellen könnte
Bei google gibt es mehrere gibt es gibt es regionen und zonen also eine region setzt sich aus mehreren zonen zusammen die region ist
In dem fall europa west 3 europa west 3 ist aktuell frankfurt ja bei mir um die ecke
Ich bin mir nicht sicher ob das eine garantie gibt
dass
europa west 3
für immer und ewig
Frankfurt sein wird weil es hat sicherlich seinen grund dass das nicht europa frankfurt heißt sondern europa west 3
Also es könnte durchaus sein dass google auf die idee kommt den standort in frankfurt dicht zu machen
Und nach köln zu gehen zum beispiel
Und dann wird es weiter europa west 3 heißen aber es wäre dann halt nicht frankfurt sondern köln
Es ist relativ wahrscheinlich dass es auf absehbare zukunft frankfurt bleiben wird frankfurt bietet sich irgendwie als standort an gerade
Gerade weil du dann auch den d6 und internet traffic knotenpunkt und alles hast es bietet sich irgendwie an aber
Theoretisch könnte das könntest du ja sein ich meine vielleicht kommt bei google irgendwann auch mal europa west europa west 3d dabei und das ist
In köln oder so zumindest europa west ist die ist die region europa west 3 ist die region
Und das hier sind die unterzonen quasi die die zonen innerhalb dieser region ihr seht dass die zonen leicht
Unterschiedliche features haben für
Vms und hardware was die bereitstellen also sprich wenn ihr eine top aktuelle kiste haben wollt mit
Ja, keine ahnung weisen sonst was nach gut nähe sieht es sieht überall relativ relativ gleich aus hier manche haben beispielsweise
keine
Die hat beispielsweise keine m2
Das hat übrigens das hat übrigens nichts mit
Die steht hier oben ja auch das hat nichts mit mit apple zu tun direkt das sind benahmung von von
Maschinen also von von von von hardware könnte man quasi sagen von vms
Also
Manche sachen kann man nicht in jeder region aufbauen in der regel muss man sich da nicht so viel gedanken drüber mal guckt und nur
Hier in europa west 3d gibt es gpus zum beispiel
Also das sieht man aber in der regel muss man sich da nicht so viel gedanken drüber machen
So eine sache wo man viel geld verschenken kann bei google wenn man nicht aufpasst ist bei
Bei sehr vielen sachen ich würde mal sogar ich würde sagen bei den bei den meisten sachen kannst du beim erstellen in der cloud bei google
Auswählen ob du es regional ich könnte mich ich könnte mir im chat schreiben wie das wie das bei abs ist also bei asia ist es
Sehr ähnlich dazu kannst du auswählen ob du das ganze regional machen willst oder
Nur pro zone so jetzt sagen wir mal da gehen wir davon aus du legst
Nächste datenbank an in der cloud bei google
Und du wählst jetzt einfach nur europa west 3 an
Dann wird das unter der haube
Quasi repliziert war ganz vereinfacht ausgedrückt auf alle regionen in dieser zone auf alle
zonen in der region
Das heißt du bezahlst auch dreimal hardware beziehungsweise dreimal ressourcen
Wenn du wenn du die datenbank erstellst nur in europa west 3 minus a also in einer zone
Dann ist das nicht der fall aber
Sollte mal hier irgendwie strom ausfallen was kaputt gehen oder sonst was dann hast du ein problem
Dass das dann halt weg ist
Chat ihr könnt ja mal in discord gucken für alle css kenner das ist ja ich mache bald ich mache bald
Max pump fiver machen wir auf da gibt es hier auftragsvermittlung
Das kann man so gar nicht sagen es ist immer die frage als wie kritisch das ganze deklariert wird also
Man, kann durchaus services für dienst finanzdienstleister in der cloud laufen lassen viele viele sind da allerdings ein bisschen
so ein bisschen skeptisch
Alles in der cloud laufen zu lassen aber es läuft doch schon erstaunlich erstaunlich viel in der cloud
Genau also wenn du zum beispiel die datenbank anlegst und sagst du nimmst du machst sie
Regional dann ist es ausfallsicherer also wenn der dann wenn mal irgendwie wie beispielsweise letztens in paris
Weiß nicht ob ihr das mitbekommen habt in paris die hatten richtig richtig die arschkarte
heise heise dabei
wasser
warum findet man das nicht
Moment das müssen wir duckduck duckduck go suchen ich vermute fast dass das google da nichts findet
Also
Ich bin mir ziemlich sicher dass heise da nen
newsartikel dazu hatte
Nein, nein, nein, nein, ich meine nicht aufhören ich mein google ja genau aber der heise hatte ganz guten artikel dazu zumindest
in paris in google bei google im rechenzentrum in paris
die hatten erst hochwasser
und
Dann hat es irgendwie noch gebrannt
Und dann ist auch das strom ausgefallen
Also die
Ja
Cloud ausfall guck mal man das war doch
Oder was bei golem wo ich das gelesen habe
Keiner also suche ist pega die hatten hochwasser brand und stromausfall
ja
genau
Google rechenzentrum nach wasser schaden und brand offline und dann ist noch der strom ausgefallen danach
also man sieht ganz so
Super safe sind die sachen auch nicht
Und in dem fall ist es ich bin mir gar nicht sicher ob es in dem fall was gebracht hätte wenn man es über mehrere
Zonen in der gleichen region gemacht hätte vielleicht weiß ich nicht aber man sieht es ist auf jeden fall auch trotz cloud nicht gleich
Es ist aus es ist komplett
Komplett sicher und es kann nie was passieren
So das ist eigentlich das was ich im endeffekt im endeffekt sagen wollte und da muss man sich halt überlegen wie viel geld man dafür
Ausgeben möchte
Man kann es auch noch weiter hochdrehen man kann dann auch mehrere datenbanken aufbauen zum beispiel dass man dann sagt okay
Wir machen europa west und us ist und solche geschichten zumindest dass das muss man wissen so lange rede kurzer sinn das ist das
Wo sich das hier mit mit regional und zonen immer bezieht also ich zeige euch jetzt mal die die terraform geschichte die müssen wir
Nämlich gleich anschmeißen weil das dauert das baut schon zehn minuten auf also was wir an ressourcen in der google cloud heute brauchen ist
Wir brauchen ein netzwerk und zwar wir brauchen ein netzwerk mit
Dieser dieser ip range also 10.0.0 slash 24 dann brauchen wir für unsere
kubernetes pods
noch eine ip range und für unsere
Ich bin mir gar nicht sicher für die für die die eigentlich da ist brauche auch noch brauche auch noch
Keine ahnung für was wir die eigentlich gebraucht haben auch noch eine ip range dann brauchen wir einen cloud router
Dann müssen wir natte einschalten am cloud router dass wir ins internet raus können eigentlich relativ klar weil wir bauen hier ein privates netzwerk
Auf so ein privates netzwerk in der cloud kommt natürlich nicht so einfach ins internet
Das heißt was wir jetzt machen müssen wir brauchen router und wir müssen natte beim router einschalten damit wir nach
Raus nach nach nach draußen kommen ins internet
Und wir sagen eben dass alle subnetworks und all ip ranges nach raus quasi raus über natte geroutet werden sollen
Dann brauchen wir ein paar firewall regeln wir brauchen einmal ssh zugriff auf alle cloud ressourcen die wir aufbauen von von allen möglichen
Quellen und wir brauchen das ist eine firewall regel die ich so nicht unbedingt empfehlen würde wir geben einfach jeglichen tcp traffic frei
Also das würde ich standardmäßig nicht unbedingt so machen
Für uns ist es hier jetzt kein problem weil
Wir sind in einem privaten netzwerk wo man von außen nicht drankommt normalerweise würde ich nicht unbedingt eine firewall regel machen wir geben den
Kompletten tcp traffic frei das ist vielleicht nicht so
Nicht so sinnvoll habe ich aber hier drinne stehen einfach um sicherzustellen dass alles
Funktioniert wenn ich nicht an irgendwelche firewall regeln jetzt initial hier erstmal scheitere
Vielleicht wenn man es ernsthaft betreiben will nicht ganz so sinnvoll okay also so dann brauchen wir eine vm
Mit debian 11 in dem fall ja wir könnten auch debian 12 nehmen aber nehmen wir mal debian 11 ist eigentlich egal wir brauchen eine vm
Und zwar brauchen wir eine vm
Hier eine micro vm die hat zwei cpu kerne und irgendwie ein gigabyte ram die kostet nicht viel geld
Und die vm brauchen wir dass dass man von daheim
in das netzwerk reinkommt
Was bei google liegt weil das ist ein privates netzwerk was in der google cloud liegt
Und ich bei mir bin daheim auch in einem privaten netzwerk irgendwie muss ich ja über das internet dort rein
Dass ich das dass ich das benutzen kann das heißt wir bauen wir bauen eine vm über die wir uns dann connecten können in
Unser google cloud netzwerk dann brauchen wir noch ein kubernetes service account können wir nachher verwenden und dann bauen wir ein kubanetes cluster auf
Das ist so ziemlich die einfachste variante in terraform einen kubaneten google kubanetes cluster zu definieren
Man gibt dem ding einen namen man gibt dem ding einen ip und subnetwork
Man
stellt ein was wir von kubanetes versionen benutzen will und die ip range und das hier ist so ein ding das
Checkt keiner wenn er das das erste mal macht man braucht noch eine vierte ip range und zwar
Das ist die ip range über die google deinen cluster managet
Google managet ja den cluster für ein bis zu einem gewissen maße google macht zum beispiel
Versionsupgrades und sowas und dafür braucht google zugriff auf den kubanetes cluster und das passiert darüber
Und das muss ein slash 28 netz sein und ich glaube es muss auch in irgendwie in der ähnlichen ip range wie hier sein
Das ist das ist vorschrift von google sonst funktioniert der ganze krempel nicht
So und dann brauchen wir noch eine node pool das ist dort wo letztendlich unsere container drinnen laufen
Da wird eingestellt wir wollen ein kubanetes cluster bauen der drei unterschiedliche cluster nodes hat also das startet standardmäßig mit drei nodes
Und wir nehmen als vm typ unten drunter
E2 standard das hat vier cpu kerne pro node und ich glaube 16 oder 8 ich glaube 8 gigabyte ram
16 oder 8 gigabyte ram und 4 also schon ist schon ganz ordentlichen cluster also wir haben ein kubanetes cluster quasi mit insgesamt
12 12 cpu kern und
Glaub keine ahnung 32 gramm oder sowas 48 48 gigabyte ram
Was würde das kosten im monat?
Das ist ein bisschen
Also ich bin mir nicht ganz sicher ich weiß gar nicht ob google einen gescheiten rechner dafür hat er hat einen ganz guten rechner
Ich würde mal schätzen so 200 euro
Ungefähr das ist aber auch schon ganz schön ganz schön fett also du kommst auch mit deutlich kleineren vms aus als mit denen
Du brauchst nicht pro node vier kerne und und 16 gramm du kannst auch e2 small oder sowas nehmen zum beispiel dann hast du
Dann hast du mit einem kleinen cluster sage ich mal 70 euro im monat das ist aber immer noch relativ teuer also wenn es wenn es
Wenn du es günstiger haben willst dann guckt dir zum beispiel mal digital ocean an
Die sind hier kubanetes pricing die sind schon eine ganze ecke günstiger
Da bekommst du zum beispiel hier schon ein basic node für 12 dollar im monat pro node
Das ist da kannst du quasi für das was du hier was du hier bezahlst bei google kannst du hier kannst du dort quasi 20 node cluster
betreiben
Natürlich wird es dann auch teurer je nachdem was da wie viel ram und cpu und sonst was da drin steckt also billig billig ist das
ganze nicht
Genau und jetzt haben wir definiert was in der cloud angelegt werden soll
Und jetzt kommt terraform ins spiel terraform kann jetzt dieses ding so wie ich es hier in meinem text file definiert habe
So in der cloud erstellen das heißt auch ich kann es reproduzierbar immer wieder neu aufbauen
beziehungsweise auch wieder rückstandslos löschen
Ohne überlegt euch mal wenn ich diesen mist von hand klicken würde da wäre ich bestimmt eine stunde beschäftigt diesen ganzen mist hier von
Hand zusammen zu klicken naja haben wir eine halbe stunde beschäftigt
Ich bin mir jetzt allerdings nicht ganz sicher ob mein terraform script gescheit funktioniert was ich hier gebaut habe
Testen testen wir einfach mal ob das ob das funktioniert oder ob es kaputt ist
Schauen wir mal
Ja richtiges projekt ist es okay wir brauchen ein bucket
Following firewalls will be deleted okay yes
Das ist nicht da okay
Following networks will be deleted yes das ist auch nicht da
Auf fällt was ist jetzt kaputt fuck alle
Account account has been deleted ich habe doch irgendwo mist drinne stehen oder
Ich habe doch irgendwo mist drin stehen ich habe noch irgendwo das falsche projekt drinne stehen oder so was
Aber set project habe ich schon gemacht
Achso ich kacknub ich bin im falschen verzeichnis
Hat das jetzt ein bucket hat das jetzt ein bucket angelegt oder nicht
Das ist jetzt mein komisches in it script was ich mir gebaut habe was hier querien start was zum
Was ist mein was ist das?
Er hat doch er hat doch
Ich glaube ich bin noch mit ich glaube terraform denkt ich habe das falsche
Ich glaube ich muss ich habe aus irgendwelchen gründen noch einen
punkt terraform drinne
Terraform hat noch meinen alten google account warum
Ich habe ich habe kein altes
Date file
Ist ja nichts drin
Achso
Habe ich hier die richtigen end was
Ne brutal und es ist doch mal ein richtiges projekt oder
Alter das ist immer an so kleinen scheiß erst mal hängen das riecht mich auf
das ist richtig
Alter was ist mit meinem Wim los was ist hier für ein komisches zeichen drin
Invalid account moment wo wo habe ich mich noch nicht eingeloggt
Warte mal
Ja nervt mich auf list
Ich lösche ich lösche mal meinen alten account
Ich glaube provoke ist es oder revoke hier moment vielleicht vielleicht ich mache ich mache das noch mal vielleicht
Wer weiß vielleicht muss ich das noch mal setzen vielleicht hat das noch nicht gecheckt
Park okay was ist das problem terraform man warum ist es warum ist mein
Instances list ne das funktioniert alles
Okay
Big big brain time an welch warum denkt terraform dass ich noch nicht eingeloggt bin dass es doch mein alter account ist
Gute idee aber ich glaube da steht nichts für drinne
ne
Ja
Projekt da die projekte die ah ne es ist alles richtig
welch an welcher stelle
An welcher stelle mein terraform dass ich noch eingeloggt bin
bei google fragen
Das ist das liegt garantiert darin dass ich schon mal eingeloggt war
100 pro
Hier terraform returns invalid grant has been deleted
Okay, it's an authentication issue for me whatsoever
Meinen wegen
Max pogu lockt sich ein allow okay und jetzt geht das
Jetzt geht das okay google logik fragt mich nicht keine ahnung was das ding wieder für probleme hat
So und jetzt kommen wir mal zu der eigentlichen geschichte was das coole an terraform ist ich habe jetzt hier meine komplette
Infrastruktur definiert wie ich die haben will und jetzt sage ich einfach
terraform apply
Und jetzt guckt terraform nach was es machen müsste
Um das was ich hier definiert habe in meinem terraform fall in der cloud auch so anzulegen so das ist ein summary
Das steht drinne ich lege feuer ich lege eine firewall an und firewall regeln ich lege noch mehr firewall regeln an ich lege
Eine vm an mit diesen sachen ich lege netzwerke interfaces an netzwerke an router an nat regeln an
subnetze an netzwerke an das muss ich alles nicht von hand klicken jetzt
Ich lege ein kubernetes cluster an alle möglichen geschichten jetzt sage ich einfach jawohl terraform mach
Und jetzt können wir ungefähr zehn minuten däumchen drehen bis alles aufgebaut ist
Das liegt nicht daran dass terraform so lahm ist das liegt daran dass google cloud beim erstellen von
clustern übelst langsam ist
Ich weiß nicht warum die so langsam sind aber die sind übelst langsam ihr werdet es gleich sehen das geht alles relativ schnell guck hier
service account anlegen
Netzwerke anlegen router anlegen firewall regeln anlegen überhaupt kein problem firewall regeln applyen
Gar kein ding aber gleich gleich kommt der kubernetes cluster da werdet ihr sehen das hängt jetzt erst mal richtig
richtig krass für zehn minuten rum
Wenn man jetzt aber nachguckt wir können nämlich uns hier schon mal einloggen
Wenn ich jetzt zum beispiel hier auf netzwerke
Netzwerke gehen da werdet ihr sehen guck mal da es gibt jetzt schon ein neues netzwerk default das habe ich so genannt
Ja aber auch feuerwollt regeln gehen wir hier oder gehen wir mal auf
hier drauf
Da wollt ihr da seht ihr auch subnetze subnetze haben wir internal das ist die das was wir vorhin definiert haben in unserem terraform file
Und jetzt gehen wir bei firewall gucken guck hier sind auch meine firewall regeln drin
allow all beste firewall regel überhaupt ja die die braucht man
Cake wait
Wie gesagt es ist eh alles intern in dem internen netzwerk da kommt man gar nicht so weit von außen hin
So und jetzt läuft das erstellen des kubernetes clusters das seht ihr auch hier wenn man hier guckt falls es schon drinnen steht
Ja guck hier
Kubernetes cluster wird erstellt das dauert jetzt bestimmt sieben acht minuten
Was wird hier gemacht wir bauen gerade infrastruktur in der google cloud auf und dann gucken wir wie man
dieses feature verwenden kann von
Cloud
Und zwar das hier wie man von einer anwendung auf eine in der cloud gehosteten datenbank zugreifen kann ohne
Dass man einen connection string braucht und ohne dass man ein passwort braucht und trotzdem ist das ganze sicher
Das will ich mal ausprobieren weil ich denke mir das könnte bei uns auf der arbeit auch enorm viel bringen
zur zeit haben wir so ein bisschen ich versuche mal das problem zu erklären zur zeit haben wir so ein bisschen das problem
Das beispielsweise auf unseren kubernetes clusters kann aber auch genauso gut auf vm sein das ist eigentlich egal es macht keinen unterschied
Guck hier ist es auch eine vm in dem beispiel
Aber das problem
Dass wenn man sich zu einer datenbank connecten will dass man immer eine riesen zeremonie betreiben muss ja man muss sich irgendwelche neuen user
besorgen muss ich welche passwörter besorgen
Man muss sich connection strings besorgen und da drehen die entwickler immer halb am rad wenn die dann halben tag warten bis sich irgendjemand
Darum gekümmert hat ist aber auch kacke so und was ich mir jetzt überlegt habe was man was wir machen können ist
Wir richten einmal pro cluster
Einen service ein für diesen
Proxy wobei ich darf euch gleich verrichten ist nicht wirklich einmal pro service ein wir machen das ein bisschen anders
Gucke ich mir dann an wenn wir so weit so weit sind also sagen wir mal so wir richten pro anwendung einen service ein
Über den man sich zur datenbank connecten kann
Und das einzige was die leute machen müssen ist den passenden service account angeben zum connecten zur datenbank
Und solange sie die rechte haben damit dann geht es dann können sie einfach in ihre anwendung eintragen
Ich will mich connecten auf localhost port 5000 und es geht du brauchst keine
Datenbank passwörter mehr du brauchst keine datenbank connection strings mehr und auch keine ips und sowas also das wäre wirklich für alle beteiligt eine
Riesen erleichterung wenn das gut funktioniert so und warum ich jetzt überhaupt auf die idee komme ich habe folgendes gefunden von google
GitHub
Sql-proxy operator google hat vor so
Monat eins zwei monaten
Eins zwei monaten hat google dieses ding hier released das ist ein kubernetes operator
To bla bla bla bla man muss es im endeffekt gar nicht wissen was es macht
Anhand dieser beschreibung das ist ein service den installiere ich in meinem kubernetes cluster
Und der guckt dann ich kann euch mal das example zeigen dann wird es eigentlich relativ schnell klar
Docs example
Postgres so also alles was wir beispielsweise als admins von diesem server machen müssten wäre dann sowas hier anlegen
Übrigens der twitch chat ist gerade kaputt nicht wundern wenn ich gerade nichts mehr sehe weiß nicht was der für schmerzen hat der twitch
Jetzt der twitch chat geht wieder so wir würden einmal pro cluster sowas anlegen
Und wichtig ist dass man den workload selector richtig setzt was das jetzt macht ist folgendes der baut quasi für jede
Anwendung jemand auf diesem cluster deployed
sowas hier automatisch
auf also sprich
Irgendjemand deployt eine neue anwendung auf den cluster
labelt diese anwendung richtig
Und automatisch passiert beim starten der anwendung unter der haube durch diesen
Cloud sql proxy operator folgendes jede anwendung kriegt noch zusätzlich einen container mit dem sql proxy gestartet
über den er dann auf die datenbank connecten kann
Ohne dass die sich selbst beim deployment der anwendung oder bei irgendwie drum kümmern müssen das einzige was die noch machen müssen ist
Um sicher auf die datenbank connecten zu können
Ja eigentlich nur den user wissen für die datenbank und den da also den name der datenbank brauchen die noch also zum beispiel hier
Meine tolle anwendungs die also die die die datenbank
Also nicht ich meine es nicht den host namen sondern den namen der datenbank im endeffekt braucht man noch
Und den user alles andere handelt dieser proxy client wenn das denn so funktioniert und das ist natürlich mega nice
Du kannst einfach ganz viel zeug deployen
Du text das richtig und du hast zugriff auf die datenbank kannst du darüber auch dann berechtigung schon also sprich auf die ja kannst du
kannst du
Das also zumindest soweit ich das verstanden habe kannst du das und zwar funktioniert das folgendermaßen wir können ja schon mal eine
Cloud sql datenbank anlegen wenn wir gerade dabei sind
Wo ist meine google?
Der kubernetes cluster wird noch erstellt das dauert jetzt auch ein bisschen
Wir legen jetzt mal eine datenbank in der cloud an ich versuche ich das versuche ich das mal zu zeigen also create instance
Schau dir mal go teleport an ist was ähnliches opensource nee das bringt mir in dem fall nix
Ich will es ja von meinem google kubernetes cluster machen mit berechtigung die in der google cloud sind auf google services nee das
Bringt mir jetzt an dem fall das würde vielleicht was bringen wenn ich mich von irgendwelchen anderen anbietern dahin connecten will oder so ich
Kenne das ich kenne das
So wir legen jetzt mal eine datenbank in der cloud an also das ding nennt sich instance id
Instance id
PrimeSubOr
Ausfall
PrimeSubBrot heißt das ding okay so passwort generieren
Vollkommen egal das brauchen wir gar nicht also wenn das richtig funktioniert dann sollten wir dieses passwort nie brauchen zum connecten
Wir wählen hier zwar also enterprise plus datenbank wir müssen es nicht übertreiben wir brauchen jetzt für unseren test
Keine 99,99 prozent sla und wir werden das ganze auch ein bisschen
Runterschreiben runterschrauben auf eine development datenbank vier cpu 60 100 gigabyte storage reicht immer noch
Und wir gehen sogar noch ein stückchen weil wir sagen single zone single zone das ganze soll europa ist drei in der frankfurt
und
Hier gehen wir jetzt mal so weit und sagen machine configuration
Eigentlich reichen wir zwei cpus und 8 gigabyte ram dicker aus ich mache ja mit der datenbank nix bei connection
Machen wir public ip weg wir wollen keine public ip wir wollen nur eine private ip
Netzwerk default ja da muss man hier noch ein bisschen zeug klicken
Google gedöhnt das dauert jetzt kurz das muss man nur einmalig machen weil das projekt neu ist das noch nicht da
Aber es scheint auf den ersten blick nichts vergleichbares zu haben
Gute frage weiß ich nicht ich kenne mich ich glaube dir das mal weil ich also ich kenne mich mit aws nicht gut genug aus
Das zu wissen das zu wissen ich bin mir nicht sicher ob er sowas hat
Ich habe ich habe eine weile mit er schon nichts mehr gemacht, aber ich glaube
Es hat so eine art database gateway
Ja, es gilt database gateway also die haben auch irgendwie sowas ähnliches habe ich aber in erster noch nie benutzt
Jetzt schauen wir uns mal an was questions gibt
Das stimmt ja muss ich sagen finde ich mittlerweile auch
Aber insgesamt mag ich die asia july trotzdem noch noch lieber
habe ich gerade schon erklärt
hat
Mehr gab es eigentlich gar nicht
Ja wie gesagt ich denke mal sehen was um 200 euro ich bin gar nicht sicher ob das nicht vielleicht sogar
Irgendwo dran steht wenn ich in den cluster gleich reingehe
Jeder in der erstellung es kann sein dass wenn man hier mal bei kubernetes engine klasse manchmal machen die vorschläge so spare so und so viel
geld im monat
Ihr kost optimale da kann man gleich mal reingucken vielleicht sieht man irgendwo was ist was es einen theoretisch kosten würde
Gcp kost calculation asia hat einen guten
Calculator
Probiert probiert es doch mal aus was was würde mich das ganze kosten ja
Also compute engine standard gke wollen wir haben total number of nodes ja macht es mal kurz aus
What are these notes egal free container optimus provisioning model regular
ja
Can general purpose series e 2
Standard 4 ok 4 ok wir haben
Der ist der ist maßlos da ist unser cluster leute
Wir haben wir haben pro node 4 cpus und 16 gramm
Ja gut
Ich glaube ich glaube 40 g haben wir genommen für die disk
Frankfurt
24 aus
Ok gucken billig ist es nicht
Ist das bei gcp auch so undurch ja das ist so eine wissenschaft für sich welche welche vms man auswählen sollte welche typen
Und manchmal rät google auch explizit ab dafür was zu benutzen aber im endeffekt ist es das beste keine ahnung
Doch netzwerke kostet auch ein bisschen was habe ich erwähnt ist auch schon teuer genug oder
Also das ist ordentlich
400 euro im monat
Da hast du also ganz ehrlich für 400 euro im monat kann ich mir über digital ocean
Ordentlichen
cluster kaufen
Der performance technisch stehen hier wahrscheinlich in die tasche steckt mit kleineren nodes aber ist es deutlich günstiger also was ich empfehlen kann zum
ausprobieren ist
Was einfach mal ein 2 node cluster oder kannst du kann ein node cluster machen
Dann machen wir das kleinste was geht du willst e 2 und e 2 small
Das ist so dass das minimalste was ich was ich irgendwie empfehlen würde ein gigabyte ram ist zu wenig
Und hier kannst du auch nicht hier kannst du auch schon nicht alle workloads richtig richtig starten
So und dann waren wir hier 40 40 gig disk noch mal obendrauf at the estimator
Das kostet ich das kostet ich 20
Wobei realistischer realistischer ist natürlich wenn du wenn du drei node cluster machst und
Dann kostet sich das 60 euro im monat
Also dass das dann sind wir schon da sind wir schon
Etwas etwas normale aber damit kannst du jetzt wirklich keine großen sprünge machen mit so einem kleinen cluster weil das sind zwei cpu
kerne und 2 gigabyte ram pro
Node also da machst du echt keine das ist das ist im prinzip ungefähr die leistungsfähigkeit vom raspberry pi 4
Kannst du kein also ne noch netter mal
Da sind ja noch netter mal das sind ja die die kleinen das sind ja die ganz kleinen hier
Das ist ja noch nicht mal die sind shared core die kannst du noch mal sagen was es also
Da kannst du echt nicht viel drauf echt nicht so viel damit anfangen
Bei kleinen sachen kleine webanwendung und so kannst du ohne probleme drauf laufen lassen aber 2 gig ram
Zwei kerne es ist schon schon echt ein bisschen
Naja wir können das ganze mal ein bisschen realistischer man sagen wir nehmen jetzt nicht die shared core wir nehmen den kleinsten
Wir nehmen quasi den den den kleinsten normalen ja okay
Und dann sind wir schon bei 200 euro im monat also billig ist hosted manage kubernetes bei google wirklich nicht
Unser cluster ist da
Nice so lege ich mal kurz unsere datenbank an
Kennt sich jemand mit e-commerce aus gibt es tools wo gratis sind für performance analyse von meinem shop
Ja du willst du willst quasi so analytics haben so wie lange gehen die leute drauf ja was ich ganz nice was ich benutzt habe mal
Wie gesagt ich bin nicht hauptberuflicher frontend entwickler oder sonst was
War das hier da gibt es aber noch mehrere tools in dieser richtung
Das gute an dem ist dass die sagen sie sind der skv kompatibel weil sie standardmäßig nur hashes speichern und keine ips und sonst was
Sieht sieht dann folgendermaßen aus glaube ich hoffe die haben eine demo
Ja sowas kannst du dir dann angucken guck da hast du so minimale analytics soweit es halt möglich ist ohne ohne zu richtig gut zu tracken
Was ist also siehst du kannst unique visitors kannst du dir kannst du dir angucken bounce rate wie die leute ab
Abhauen von einem shop welche seiten also von welchen seiten die kommen auf welche seiten hauptsächlich zugegriffen wird welche browser die verwenden
So das habe ich auch verwendet fand ich gut lässt sich auch easy auf einer mini mini mini vm
Hosten oder sogar auf der gleichen vm wo du dann deinen shop drauflaufen lasst lässt oder zusätzlich als in einem container wenn sie im klartem koordinates läuft
Umami ist kaputt auf am 64
Wie bewertet man ein korp
Das ist in der tat ein bisschen wissenschaft für sich was es für einen korp ist
Es gibt irgendwo eine liste
Was da genau dahinter steckt aber so hundertprozentig wissen tut man es glaube ich nicht
Es kommt ein bisschen auf den maschinentype an also die sagen ja auch zum beispiel
Ja wenn man hier guckt
Ja zum beispiel hier n2 da guck hier die kannst du nachgucken
Beispielsweise wenn du maschinen nimmst vom typ n2
Dann ist das ice lake oder cascade lake zum größten teil wenn du
E2 nimmst dann schreiben sie beispielsweise
Das sind die älteren dann kannst du noch
N1 machines nehmen das also ein bisschen was steht da aber oftmals so ganz genau wissen tut man das nicht
So legen wir mal unsere datenbank an
Bla bla bla bla ich wollte noch die
Die disk verkleinern habe ich das gemacht 20g für eine test datenbank
Das ist übrigens auch ein sehr guter begriff
Du kannst automatisch den speicherplatz einer datenbank erhöhen lassen
Wenn du an das speicher limit kommst
Unter der haube weiß ich nicht wie die das machen ob sie in lvm resize oder irgendwie magic speicher haben wie sie das machen
Wie auch immer das eben genau implementiert ist das ist ja nice allerdings muss man halt sagen google macht es natürlich
mit
mit dem disk verkleinern
Implementiert ist das ist ja nice allerdings muss man halt sagen google macht es natürlich
Ja aus geld verdienen gründen also wenn du nicht aufpasst
Und deine datenbank gerade über nacht explodiert
kostet bis sie geld
Ach ja und zum testen würde ich auch noch eine sache machen ich würde data protection ausschalten
Weil ansonsten musste nachher dreimal klicken wenn du die datenbank wieder löschen willst normalerweise würde ich data protection immer anlassen da kann man nämlich
nicht ausversichern die datenbank löschen
Und maintenance window nicht backup window maintenance window ist bei kubernetes ich hab mich vertan
Create
Don't save ich brauche das passwort nicht wenn alles gut läuft
Leute ich esse nebenbei mal kurz ein brötchen ich habe übelst Hunger
Gut und ihr seht das ganze lief jetzt ungefähr 12 13 minuten mein mein mein ganzes terraform
Wie heißt denn das eigentlich bei ansible sind es playbooks wie nennen sich das bei terraform
Es lief gerade mein ganzes terraform
Deployment
ressourcen plan
Gute frage weiß gar nicht wie die das nennen
Was genau wollte eigentlich machen also guck mal wir wollen folgendes machen wir wollen eine anwendung betreiben
Die auf der datenbank zugreift
Allerdings sollte nicht direkt auf die datenbank zugreifen mit connection string username und passworten alle möglichen sondern
Über einen proxy so dass die anwendung selbst überhaupt nichts mehr großartig wissen muss außer den namen der datenbank
Dafür haben wir jetzt mit terraform und kubernetes klasse aufgebaut
Wir haben ich zeige euch mal was wir gerade alles aufgebaut haben also ihr werdet gleich feststellen es ist schon einiges was terraform im hintergrund
gemacht hat also
Als erstes haben wir mal ein bucket für unseren terraform state das ist jetzt aber nur so am rande
Dann wurde aufgebaut ein kubernetes cluster
Mit drei nodes insgesamt 12 cpus und 48 gigabyte ram low resource request oh oh das ist nicht gut
Also das ist dass man geld sparen kann
Guck jetzt sagen sie einmal könnte man kein geld sparen wenn man das
Umallocated
Kostoptimation lul wir wollen keine kosten optimiert haben kubernetes klasse angelegt
Dann hat terraform eine
Jump vm angelegt das sind übrigens die nodes von unserem cluster jene vm über die wir uns dann connecten können
Dann wurde ein netzwerk angelegt
Mit einem subnetz mit den ip ranges die wir haben und es wurden firewall regeln angelegt
Es wurden firewall regeln angelegt wo ich hoffe dass alle funktionieren ja das das war es eigentlich soweit
Note bitte mal erklären
Ein kubernetes cluster besteht aus mehreren nodes
Und jeder node in diesem kubernetes cluster ist in der google cloud halt unter der haube auch nur eine vm
Ich meine irgendwo müssen ja im endeffekt deine sachen drauf laufen
Sie laufen in einem container in dem kubernetes cluster aber irgendwo unten drunter besteht dieser kubernetes cluster aus drei nodes und in dem fall drei vms
Und im prinzip sind es auch genau die drei vms die wir vorhin über terraform professioniert haben was man hier auch sieht
E2 standard nach guck mal cpu plattform ein intel broadwell haben wir am start
Hast du eine konkrete anwendung für die datenbank also jetzt hier zum testen ja also zum testen habe ich eine ja
Aber es geht hauptsächlich darum den den proxy zu testen
Warum sagt man node anstatt der vm das ist immer die frage
Auf was man auf was man sich bezieht wenn man sich bei einem kubernetes cluster auf die
Einzelteile bezieht aus die der cluster besteht dann sagt man node wenn man sich auf das teil bezieht auf dem der node läuft
Beziehungsweise der der quasi teil des kubernetes clusters ist joint als neuer node dann ist es eine vm
Also wenn du zum beispiel fragst aus wie viel nodes besteht ein kubernetes cluster dann kannst du sagen drei stück
und
Jeder dieser nodes ist eine vm
Es muss ja nicht in der vm in der google cloud seine node könnte auch beispielsweise in raspberry pi bei dir daheim sein
Den kubernetes cluster join lässt
Guck mal kurz ob unsere datenbank da ist
nee noch nicht
Die datenbank ist glaube ich erst auf vier prime subs da
Braucht erstaunlich lange die datenbank bis die da ist
Na gut
warten wir mal ab
Ist aber nicht schlimm wenn die datenbank ein zwei minuten noch aufbaut dann kann ich mal kurz mein toastbrot beziehungsweise ein brötchen danach fertig
fordern und die jump vm ist was ganz einfaches
Ich zeige dir was die vm ist die vm
Ist schlicht und ergreifend diese jump vm ist schlicht und ergreifend eine ganz normale debian vm
Eine ganz stinknormale debian vm über die ich mich in das netzwerk auf der google cloud connecten kann
guck da sind wir hier
Endprog das ist eine vm mit zwei cpu kern und
Einem gig ramm
Und jetzt bin ich hier per ssh auf der vm und du siehst ich bin im netz wo auch der kubernetes cluster steht das heißt
Ich kann jetzt hier sowas machen wie cube ctl bla bla bla auf dieser vm
Ich jumpe in das netzwerk genau deswegen heißt das ding jump kann ich mir merken wofür die da ist
Benutzt du den jump für die cube ctl befehle naja
Kann man machen kann man machen
Gibt mehrere möglichkeiten was man jetzt machen kann also da kann ich vielleicht auch mal erzählen kurz während ich die datenbank ist da aber ich erzähl
es trotzdem mal kurz
Ja, ja bei bei asia heißt das ding übrigens sogar ganz offiziell glaube ich jump bastion oder so ja genau
War mal das mikrofon hoch dabei dass ich euch nicht ins ohr schmatze
Chat was gab es bei euch heute zu futtern?
Nudeln mit lachseier
glaube ich dir sofort
Noch auf der abend macht zu 47 das aber ganz schön spät also um zurückzukommen
Hast du eigentlich mal überlegt als freiberuflicher dozent nein nein da habe ich da habe ich nicht wirklich so viel bock drauf
Auf ja habe ich mir überlegt ist mir aber zu stressig
Aber ich habe ich keinen bock drauf musik track kann ich dir zeigen
Ja
Epic chillstep collection 2019
Man hört es ja auch wie epik das ist ja kann ich dir auch was dazu dazu sagen
Also kommen wir mal zurück zur ursprünglichen frage tommy erinnert mich dran wenn ich es nicht nachher vergesse aber kommen wir erstmal zur ursprünglichen frage
Benutzt du diese vm in der cloud um cube ctl befehle auszuführen also cube ctl ist das
Administrations tool für kubernetes ja könnte man machen ich könnte jetzt hier sowas sagen wie cube ctl get pods minus a und sowas aber
Es gibt jetzt mehrere möglichkeiten wie man das ganze machen kann man kann sich per ssh hier drauf connecten
und den kubernetes cluster von hier administrieren man kann
Zeige euch das mal
Man kann auch das finde ich persönlich einen ganz guten ganz guten mittelweg man kann auch sowas hier machen
ihr schaut mal
Wisst ihr was das jetzt macht das ist eigentlich mega five hat ssh befehlen das lockt sich per ssh ein
auf dieser kiste
Und macht jetzt ein port auf lokal lokal habe ich jetzt im port laufen der sich netztät minus tulpen
habe ich lokal habe ich jetzt im port 1337 laufen
Und das ist ein socks proxy das heißt ich kann jetzt
Muss ich mal kurz raussuchen wie das funktioniert
Ja, ich kann jetzt ein socks proxy setzen
hier so
Cube ctl get pods minus a das wird noch nicht funktionieren weil ich erst mal mich anmelden muss bei google
Damit ich auf mein kubernetes cluster zugreifen kann
war jetzt mal schnell
primary
connect
copy paste
Richtig ja
Okay, so und jetzt setze ich den setze ich den
Socks proxy und für kube ctl aus und zack kann ich mein kubernetes cluster administrieren
hat übrigens mit der connection hier oben nichts zu tun
Also die zwei varianten die zwei varianten gibt es
Das hat natürlich was mit der connection hier oben zu tun nicht ich kack nur weil hier oben ist die connection
Die connection in das netzwerk gewesen
Also guckt das funktioniert also was was jetzt passiert ist folgendes
Das ist das ist wirklich ein sehr guter kompromiss auch zu einem vpn oder sowas weil es einfach mega easy ist
Also was hier passiert ist eigentlich ganz einfach
Mit mit dem google cloud tool baut man eine ssh verbindung auf über den tunnel muss man nicht wissen was es ist
Das ist das ist von google was um tcp ip traffic zu tunneln
Also so baut man einen tunnel auf seine vm auf die also baut ssh verbindung auf die vm auf die sich jump nennt
Und das dahinten sind ssh
Options und minus d 1337 bei ssh ist mache einen socks proxy auf auf lokal port 1337
Und alles was über diesen port geht geht dann über den tunnel zur vm und dort dann als ausgang über die vm das heißt ich
baue jetzt einen tunnel auf
Und kann jetzt beim cube ztl sagen benutzt diesen socks proxy um dich über die vm zu tunneln in das netz bei google
Kann man der ganze sache halbwegs folgen
Also die verbindung geht jetzt im endeffekt hierhin also cube ztl geht über den socks proxy
Über die ssh verbindung und dort dann raus in das in das netz lokal bei google und wenn das ganze funktioniert weil die vm selbst
halt eben in dem in dem privaten netz in der google cloud steht
Ich glaube versteht man versteht man halbwegs was passiert oder
Also das ist das ist tatsächlich mega mega nice und das ist so ziemlich die
Einfachste variante sich ein privates netz zu tunneln wenn man kein vpn bauen will ich habe noch eine andere weil ich zu faul bin vpn
zu bauen
Die ist aber etwas fragil aber die werden wir jetzt trotzdem gleich gleich benutzen
Also das ist das ist super easy das kann jeder du brauchst ein befehl und du schreibst ach so übrigens
Wenn ihr keinen bock habt immer immer den socks proxy davor zu schreiben könnt ihr einfach einfach auch sagen export https proxy
Und dann kann man ganz normal die sachen dann auch so ausführen dann geht es immer über den socks proxy
Aber ich ansetze und dass ihr auch seht dass es am socks proxy liegt ich ansetze das mal und für das jetzt aus und funktioniert
es nicht
Oder ich exportiere das ich trenne die ssh verbindung für das aus und dann geht das nicht
So hier gibt es hier habe ich tatsächlich auch einen tipp zu
Also ist das auf der basis eines bastion host ja genau sowas ist das korrekt
So also hier kann ich auch was zu sagen also er fragt tipp wie man große datenmengen von einem server zum anderen transportiert
Mache zweimal erst von remote auf lokal
Und dann von lokal auf neues remote problem ist nur wenn lokal zu wenig platz ist also es gibt zwei varianten ich bilde mir ein
dass scp
mittlerweile
Standardmäßig
Ssh tunnel unterstützt also ssh tunnel
mit port weiterleitung so dass du quasi von haupt von remote auf
Remote post kopieren kann sich glaube scp kann mittlerweile sowas hier lob 1 1 1.1.1
Keckel txt auf gut 2.2.2 ding ich glaube scp kann mittlerweile sowas
Das geht aber nur solange
solange
Server 1
Connecten kann netzwerktechnisch auf server 2
Sonst funktioniert das nicht
So was du machen kannst ist wenn das nicht funktioniert
Du kannst selber tunneln also kannst das ja mal ausprobieren ob das ob das prinzip scp kann nicht differenzieren
Ne ist das das problem du hast das problem dass local zu wenig platz ist dann kopierst du ja nicht über local dann kopierst du
Direkt von remote auf remote da brauchst du lokal kein platz
Was du machen kannst und was du dann auch mit ersen benutzen kannst ist
Ssh fs ist eine sache die mir noch einfällt du kannst zum beispiel
Ich bräuchte jetzt mal irgendeine kiste wo ich ssh zugang drauf habe
Die nicht meine cloud kiste ist und cloud keine cloud kiste wo ich von extern drankommen
Ich mache mein raspberry pi kurz an
Ich zeige dir ich zeige dir da schnell ich hoffe ich hoffe im raspberry pie funktioniert da haben wir noch
Haben wir noch home assistant drauf und so das sollte eigentlich funktionieren
Ich zeige dir das mal schnell weil ich glaube das ist ein problem was viele haben
switch an
Ob das ein problem was viele haben deswegen
Machen wir das jetzt mal kurz
Vm champ regelt stimmt ich könnte vm aufbauen ja richtig
chat
hat das stream gerade gehängt
stream lag
Okay, also vm champ
Wie ging das jetzt vm champ run
blubb irgendwie so
Aber der vm champ vm champ beste leute ich sag's euch massive nice der vm champ
Wahrscheinlich ist er jetzt kaputt oder so
Nice nice okay vm champ regelt einfach
So ich habe mir lokal eine vm aufgebaut
Kann ich euch das mal zeigen also
Tim Tom ich glaube dass das dürfte für dich so eines der einfachsten sachen jetzt sein zu benutzen wie du es benutzen willst und zwar
Ssh fs das hier ist jetzt mein server in der cloud denkt denkt einfach mal das ist ein server in der cloud okay
Und ich habe jetzt hier einen ordner im kadir kecke und in der liegt ein
touch keck w.zip
So und ich möchte das jetzt von dem server auf einen anderen server transferieren
Eine sache die man immer empfehlen kann bei sowas ist ssh fs
Habe ich gar nicht installiert muss ich mal machen
Ssh fs ssh fs ist extremly pock und zwar ssh fs
User ad
Verzeichnis angeben kecke
Mounten nach ssh fs so und jetzt werdet ihr feststellen ich habe lokal einen ordner
mit dem inhalt
vom server
Das heißt es sieht jetzt für mein scp so aus
Als kopiere ich eine datei von lokal aber in wirklichkeit kopiere ich eine datei von diesem server
Und jetzt kannst du natürlich sagen scp keck w.zip root at cloud server
Oder ersung oder ersung das heißt du kannst es jetzt benutzen wie als wärst du als wäre die datei lokal bei dir
Also ssh fs ist immer eine sehr sehr praktische geschichte und braucht auch nichts auf dem server außer ssh
Also thom ich denke das ist was kannst du an der stelle benutzen
Du brauchst kein platz auf lokal an der stelle du hast nie was lokal liegen
Das ist nicht bei dir lokal das sieht nur so aus wie lokal das ist ein ssh f
Ssh fs auf dem server wie du auch hier siehst der ssh der ordner ist über ssh gemontet ja genau siehst du ja auch hier
Die nächste variante was du was du dann was du sonst noch machen könntest
wäre
Aber da wird es jetzt schon wird es jetzt schon ein bisschen abgedreht
Aber da wird es jetzt schon wird es jetzt schon ein bisschen abgedreht wie wäre es das hfs zu umständlich
Kannst du das auch kannst du das auch anders machen
Also ersüngst so ohne weiteres funktioniert ja nicht wenn er von dem einen system nicht an andere kommt
Es ist ja glaube ich das problem dass er vom einen system nicht richtig an das andere drankommt
Er kommt von seiner admin kiste dran an beide systeme aber er kommt nicht von einem ans andere system dran
So und um das zu fixen
Ja das kann ich jetzt nur theoretisch demonstrieren du kannst sagen ssh minus er
Das ist das andere ssh
Hab ich denn hier
Du kannst sagen ssh minus er
Keine ahnung port 2222
Willst du weiterleiten auf
Ssh
Ssh minus er
Keine ahnung port 2222 willst du weiterleiten auf
Keine ahnung mir fällt jetzt nichts ein
Localhost port 22 oder ich brauche mal irgendwas wo
Wo ssh läuft läuft bei mir localhost
ssh
Läuft
dort ein ssh
Keine ahnung ich
Ich bräuchte eine andere kiste wo man ich brauche einfach nur eine zweite vm auf
Ich brauche einfach nur eine zweite vm und der vm champ der vm champ regelt schon
So wir anmaunten das ganze jetzt erst mal hier anmaunt ssh fs
wieder weg
vm champ run plop 2
Machen wir einfach nur eine zweite vm geht ja zackig so und das ist jetzt für den fall der fälle du willst du willst
Eine verbindung herstellen von server a zu server b aber server a und server b können eigentlich nicht direkt miteinander kommunizieren
Dann gibt es auch einen trick den zeige ich dir jetzt wir haben jetzt server a und server b also das ist die kiste das ist die kiste
so und
Also das ist das ist dieses die ip hier nehmen wir die mal so also was jetzt machen kannst ist
Ssh
Minus r port 2222 ich erkläre jetzt ich erkläre gleich was es macht auf port 22 so netzt
Du wirst jetzt sehen du hast auf diesem system jetzt auf einmal port 2222 offen was dieser befehl jetzt macht ist folgendes
Der verbindet sich auf diesen server per ssh
macht dort port 2222 auf
Und alles was dort auf dem remote system das ist übrigens für remote das ganze geht auch mit l und local
alles was dort in diesen port rein
Geht netzwerktraffic mäßig wandert über den ssh tunnel und auf deinem host wo das wieder rauskommt also auf deiner kleinen kiste
Wird es dann von ssh weiter geroutet an diese ziel ip das bedeutet was du machen kannst hier ist ssh
Auf localhost port 2222 und dann kriegst du eine abfrage möchtest du dich per ssh connecten
Und wo du jetzt rauskommst ist auf dem ssh von blubb 2 auf dem ssh port von blubb 2
Bei dir funktioniert der vm-champion
Wir können ja passwd user machen current password was weiß ich denn keine ahnung
Keine pseudo passwd wir geben jetzt mal ein passwort 123456 guck mal
Shit es ist nur key authentifizierung
Es ist nur key authentifizierung erlaubt fields batman ok
Ssh ssh de konfig ich will einfach nur zeigen dass es prinzipiell funktioniert
Wie schaltet man wie schaltet man den kram denn aus
Fuck alle ssh konfig hier passwort authentifikation yes ok 10 zdl restart ssh de ich
hoffe das hat jetzt funktioniert
123456 zack und siehe da guck mal du connectest dich
per
localhost port
Auf eine andere kiste und kommst dann auf blubb 2 raus so und das funktioniert obwohl
Blubb und blubb 2 in komplett unterschiedlichen netzwerken stehen wichtig ist dass dein host von dem du diese ssh port weiterleitung gemacht hast
Auf beide zugreifen kann also das sind sachen die du wo du das problem mit lösen kannst das einfachste wäre in dem fall natürlich
Ssh fs ja
Das dürfte wahrscheinlich am einfachsten sein aber jetzt kannst du dir echt komplett überlegen wie das wie das machen willst weil jetzt jetzt jetzt
Weißt du eigentlich alles was man dazu wissen muss
Der vm champ ist mega nice das projekt zwar weitermachen so aber der ist freaker dankeschön für den sub
Wir waren ja eigentlich dabei cloud sachen zu professionieren ja wer macht denn auch sowas
ok also
Pfeilfeld kommen wir mal zurück
Kommen wir zurück zu unserer cloud geschichte
Wir haben kubernetes cluster und wir haben eine cloud datenbank postgres wir erlauben nur ssl connections das ist richtig so jetzt kommt
der trick
Ich habe mir nämlich
einen
blog post im vorfeld rausgesucht wo erklärt wird wie das ganze funktioniert und einen
Stack overflow post weiß ich aber nicht nicht mehr nach was ich gesucht habe
Wie sowas
fuck
das hätte ich mir vielleicht
Mal raus kopieren sollen das hätte ich mir vielleicht mal raus kopieren sollen ins der gaufer floh eintracht den ich da gefunden habe kurz was gucken
Vielleicht vielleicht finde ich das vielleicht finde ich das wieder also nur um das jetzt zusammenzufassen was wir jetzt probieren werden und zwar wir
haben eine datenbank in der cloud
die nur ssl verbindung erlaubt
Und wir haben einen kubernetes cluster so jetzt ist das ziel dass wir folgendes auf die reihe kriegen guck mal das da
Das da dass wir uns von einem cluster
Container im cluster verbinden können auf die datenbank ohne dass wir ein passwort brauchen
Und ohne dass wir einen connection string brauchen
Das ist das ist das das ist das ziel bei der ganzen geschichte und um auf die ursprüngliche frage einzugehen
Kann man das mit speziellen usern verbinden ja kann man man kann zum beispiel
Zeigt ihr das mal hier an der stelle ich habe ich habe man hat verschiedene user hier in bei google zum beispiel hat man auch
Einen den habe ich angelegt mit meinem kubernetes cluster zusammen und zwar habe ich einen user für meinen kubernetes cluster
Und standardmäßig alle sachen die in diesem kubernetes cluster laufen
Laufen unterhalb von diesem service account hier ich weiß nicht wer das wer das wer das gefragt hat
Wollte ob man das auch auf spezielle user ebene machen kann also kann man alle sachen die im kubernetes cluster laufen laufen zurzeit aktuell unter diesem service account hier
So das heißt was ich jetzt machen kann ist folgendes
Ich gebe diesem service account jetzt erst mal ein paar rechte
Warum steht das da 500 mal drinne
Gehen wir einfach mal von aus das reicht jetzt so
Das heißt das prinzipiell schon mal alle sachen die bei mir im kubernetes cluster laufen zugriff haben auf meine datenbank das ist noch nicht so tolle
Vielleicht ist das auch gar nicht so schlau man sollte das schon eher auf anwendungsebene machen aber das kann man prinzipiell erst mal einrichten
So und jetzt kommt der trick
Jetzt geht man bei der datenbank hin unter users
Und dann gibt es hier die
Datenbank und dann gibt es hier die
Datenbank und dann gibt es hier die
Und jetzt kommt der trick jetzt geht man bei der datenbank hin unter users
Fügt hier auch den kubernetes service accounts
Cloud ist sagt cloud am fügt ja auch den kubernetes account dazu und sagt add dann hofft man dass es funktioniert
Genau und jetzt werdet ihr sehen dass dieser service account
Cloud sql client rechte hat und cloud sql instance user rechte hat
Das heißt wenn sich jetzt jemand
Verbindet zu dieser datenbank der im kontext von diesem service account läuft dann kann der das ohne password machen
Wenn er so lange über den proxy geht so so weit so weit die theorie dahinter
Also sprich jetzt also zumindest habe ich das so in aus diesem aus diesem blog post hier heraus gelesen
Also sprich was wir jetzt schon haben ist dass man an dieser stelle wenn man sich verbinden möchte vom client über den proxy
Proxy über den
Sql proxy zur datenbank dass man schon mal kein password mehr braucht obwohl die datenbank mit password abgesichert ist also das schon mal
nett verkehrt
Und jetzt ist natürlich nur die frage wie installieren wir dann den ganzen klempel auf dem server
Und dafür ich mache erst mal wieder ein paar sachen zu und dafür schnappen wir uns jetzt das hier das ist ein
Kubernetes operator das ist im endeffekt ein hintergrund dienst den man zusätzlich im kubernetes installieren kann
Der überwacht verschiedene sachen die gestartet werden und wenn ich eine anwendung starte die die passenden tags hat dann injecte der automatisch
diesen sql proxy
Das sollte ich vielleicht auflassen
Der injectet
Automatisch diesen sql proxy in die anwendung quasi rein als zusätzlichen container und dann kann die anwendung auf die datenbank
zugreifen soweit soweit die
Soweit die theorie dahinter
Das werden wir jetzt mal installieren und gucken was passiert guckt ob das funktioniert
Das heißt ich klone mir jetzt mal dieses repo hier
Das machen wir vielleicht echt auf unserer cloud vm
Ein warum nicht
Wobei warum sollte man es auf unserer cloud vm machen wir können wir können wir können mein wackeliges tunnelskript verwenden und gucken ob das
funktioniert
Ich habe mir nämlich was ich habe mir nämlich mal was gebastelt und zwar
So einen vpn ohne einen vpn zu sein das würde ich aber nicht nicht empfehlen das zu benutzen
Wohingegen das was ich euch vorhin gezeigt habe zum connecten in die cloud mit dem sox proxy super stable und gut funktioniert ist das eher
So eine fragwürdige geschichte da würde ich schon echtes vpn bauen wenn ich da wenn ich da live was betreibe denn es dankeschön für den
sub zwölf monate pox subscription das ist extrem
Aber ich bin mal gespannt ob mein tunnel mein tunnel gedöns noch funktioniert was ich hier gebaut habe ok
Cube ztl get ports minus a easy funktioniert
nice
Mini vpn auf die stelle gebaut also das funktioniert übrigens auch
So ich zeige euch das mal kurz das ist wirklich ganz ganz eklige heck weil ich zu faul war
Den vpn in die cloud zu bauen was das hier macht ist folgendes
Genau also das baut muss ich alles erzählen dass es wartet aus irgendwelchen gründen erst mal fünf sekunden
Dann legt es ein neues netzwerk die weiß an gibt dem neue netzwerk die weißen ip fährt das hoch
Setzt routen auf meine zwei cloud netze das ist hardcoded das wird mit anderen netzen gar nicht funktionieren und ich habe glück dass ich diese netze
Zufälligerweise bei mir lokal nicht verwende dann starte ich ein tool was über einen sox proxy
Allen möglichen traffic tunneln kann und dann starte ich einen sox proxy über das was ich euch vorhin gezeigt habe also ganz furchtbar abartig
Aber es funktioniert also ich tunnele jetzt quasi meinen kompletten traffic über den ssh sox proxy
chat
Noted konnte man der ganzen sache noch folgen
5er time muss gerade noch mein letztes toastbrot fordern
Weil ja sind nicht ganz leer
Was habe ich mich getunnelt gut jetzt
Klonen ich mir mal diesen operator
Ihr checkt auch checke im git die letzte stable version aus
was
1.0.2 ist
Gehen den installer ordner und installiert das so was das install ist kripp macht ist relativ einfach gezeigt
das installiert search manager überhelm
Und dann er bleibt das eine jetzt haltet euch mal fest
dann er bleibt das eine
1657
1657 zeilen lange jammel konfig
Also das ist eine saumäßig lange jammel aber da muss ich mich ja nicht drum kümmern install
Gut das dauert jetzt kurz aber
Was ihr vielleicht schon seht ist wenn ich jetzt
Cube ztl mir aufliste werdet ihr sehen gleich erscheint dort
ein
hoffe ich mal
Gleich sollte dort zumindest ein neuer port erscheinen was ein neues deployment erscheinen
Okay für search manager ja
search manager ok
Und dann am ende allerdings für den sql proxy und das ist das um das ist jetzt hier heute eigentlich letztendlich auch geht
Okay
Ja, er kreiert irgendwelche dinger
Bei mir auf der arbeit würden die dich jetzt abführen
Nee, sie würden mich wahrscheinlich dafür bezahlen das zu machen warum sollten die mich abführen
Jetzt haben wir in unserem cluster den cloud sql proxy operator laufen den cloud sql proxy operator controller manager
Klingt ja fast ein bisschen wie eine java klasse oder
cloud sql proxy operator controller manager eine runde java klassen namen aber
Weiter ich wollte das emote mal benutzen habe ich schon ewig nicht mehr benutzt
Cli böses hexenwerk ja gut gibt es ja immer noch welche die der meinung sind
Kommandozeile terminal ist ganz krasser hacker mensch heiß weil ich jetzt kann man kurz gucken muss ist
Describe mal kurz was schauen
Deployment muss ich ja sagen
Genau ich will mal kurz gucken was die für image benutzen
Image
Okay, geht sie also die das image ist gehostet in auf github auf auf google
Hatte mal geht sie er geht sie er ist google google container registry
Mit 10 matrix habe ich das überhaupt installiert ja beste und weiß damit was 10 matrix noch nicer ist in verbindung mit lol cat
Dann ist richtig herrgerman modus angesagt
Als kappa breit herrgerman modus das ist für das jahr 2023 ist das trendiger
Toastbrot was machst du eigentlich mit deinem gehalt so als ledig ja das stimmt ich bin nicht verheiratet habe keine kinder und sonst was
Das stimmt ich gebe tatsächlich relativ wenig kohle aus
Ich hole mir zwar ab und zu also wenn ich mir was hole dann meist noch was gutes
Oder ab und zu halt auch mal schon was teurer ich habe mich nicht umsonst letztens in 5000 euro rechner gekauft aber halt alle fünf
Jahre kann man das mal machen was ich mache ich kaufe
Ich hau das eigentlich mehr oder weniger alles in stonks
Wobei stonks ist zu viel gesagt etf und da lasse ich es vergammeln bis ich irgendwann reich bin so der plan
Ob das jemals eintreten wird sei mal dahingestellt ja okay
Dafür sind die chancen dass es morgen weg ist auch nicht so hoch
Okay also weiter weiter im text
Wir haben wir haben diesen ganzen krempel jetzt installiert im cluster und jetzt testen wir mal
Was dieses
Beispiel von denen hier macht also von der idee her sollte jetzt folgendes passieren
Ich lade mir mal kurz die datei herunter
Da noch mal kurz die datei herunter und passt das an
Also was jetzt was jetzt passieren soll ist ich mache mal diesen ganzen diesen ganzen das ganze geschwätze hier weg das brauche alles nicht ja
Das alles secrets brauche ich auch nicht. Secrets sind overrated, outdated, shebaited. Das brauchen wir nicht
DB name und so brauchen wir auch alles nicht
DB user das setze ich gleich von hand zum testen
Connection sachen verbrauchen wir auch nicht wir sleepen einfach ein paar minuten
Beim starten des containers einen liveliness probe brauchen wir auch nicht. So das ist doch jetzt schon deutlich übersichtlicher
Okay, also was das also wenn das funktioniert was das ganze jetzt machen sollte ist folgendes
Das hier ist ein deployment wie man es kennt von kubernetes
Wer das so nicht gesehen hat im prinzip steht hier bloß drinne was kubernetes starten soll also man sagt ihm zum beispiel als
Leute wo ist denn das image
Wo ist denn das image bin ich ach da hier
Genau man sagt ihm was er für den image starten soll was er für ein image starten soll er soll das normale postgres image starten
also sprich da startet dann
Das ganz normale
Post auf official postgres image
Und dann was er darin ausführen sollen eigentlich soll er nichts ausführen außer starten und 3600 sekunden sleepen und das war's
das ist alles
Mehr gibt es nicht wir können hier oben vielleicht noch einschreiben
Replikas dass er nur ein ein
Container startet und ich bin mir immer nicht sicher wo ich das wo ich das ganze hinschreiben muss mit den replikas ich glaube hierhin
Ich glaube hier
Aber ich benutze normalerweise auto complete in visual studio code damit weiß ich aus dem komplett muss das sind ja genau doch ist richtig
replikas da muss es drunter
Na das heißt er startet diese diesen workload auch nur einmal und das war es und die eigentliche sache mit dem proxy
das ist das hier oben und zwar
ich habe jetzt ja hier im hintergrund diesen
Cloud sql proxy operator laufen so und der überwacht ob es
Konfigurationen gibt was er machen soll und das ist eine konfiguration für den das heißt sobald das hier angelegt wird
überwacht dieses teil hier
Automatisch
alle deployments
Mit diesem namen in dem fall halt nur dieses eine hier aber ich könnte hier auch reinschreiben
namespace oder label selector machen also quasi alles was getagt ist so und was da was dann passiert ist folgendes
Ich kann es ich kann es einfach zeigen wir gucken wir gucken uns jetzt einfach an ob das funktioniert also von der idee sollte folgendes
Passieren er startet diese demo app diese demo app im prinzip startet eine shell und sleep paar minuten das ist alles
Mehr macht das nicht allerdings
injectet dann dieser
sql proxy operator
zusätzlich in das deployment noch einen sql proxy
Über den ich mich zur datenbank verbinden kann nachdem das alles mit meinem kubernetes account funktioniert sollte das ohne
Passwort und alles funktionieren übrigens das hier brauche ich noch den connection string brauche ich noch
Einmal initial gesetzt und alle weiteren die diese datenbank verwenden wollen brauchen es nicht selbst konfigurieren in der regel wird das nämlich so laufen
Dieses ding ist das was einmalig von irgendwelchen infrastruktur administratoren im cluster hinterlegt wird und das hier ist das was
Letztendlich an anwendungen deployed wird das passiert nicht zwangsläufig von den gleichen leuten deswegen denke ich dass uns das auf der arbeit enorm helfen würde
Weil wir könnten einmalig sowas hier deployen in den cluster und alle die eine datenbank connection machen wollen würden einfach
Ganz normales deployment machen und könnten darauf zugreifen also soweit soweit die theorie wie kriege ich in diesen connection string
haben wir da irgendeinen guide
Proxy operator gibt es eigentlich ein sleeper docker compose ja genau so wie hier
Genauso wie hier einfach einfach einen container command reinschreiben
Docs
Nehme ich den quick start oder sowas hier irgendwie doch hier quick start hier
So kriegt man den name den connection string zur datenbank raus
Ich weiß nicht ob man die ob man das so genau versteht was der vorteil davon ist obwohl ich jetzt den connection spring brauche also
Der vorteil ist diesen connection string zur datenbank den brauche ich genau einmal
Pro datenbank und ich muss nicht pro up oder pro deployment
Mich jedes mal drum kümmern um welche datenbank welchen connection string welchen user welches passwort
macht das einmal
Und dann war es das und alle apps auf diesem kombiniertes cluster
Die eben hier unter diesen workload selektor fallen bekommen das injected und können das benutzen
Das das ist theoretisch ein riesen erleichterung für alle seiten
Wenn das wenn das denn gescheit funktioniert so also was muss ich jetzt ausführen dass da
Laut sql instances describe quick quick start instance nehmen eine datenbank heißt nicht quick start instance sondern prime sub broad
das brauche ich
beim sub broad
so
Dann habe ich im vorfeld schon mal nachgeguckt
weil ich eine
Nicht öffentliche datenbank bei google betreibe
Muss ich noch zusätzlich sachen angeben nämlich
Api documentation
Irgendwas mit private ip muss ich noch angeben
private
Ach private ip groß geschrieben private ip muss ich nur angeben true
so
Jetzt gucken wir mal wie weit wir kommen wenn wir das einrichten da bin ich jetzt mal gespannt so
Cube ctl apply minus f deploy postgres
okay ports
wird erstellt
container creating ja
Create mal den container running
okay nice
Dann exekten wir uns da mal rein in den container cube ctl das kann ich mir immer aus dem kopf habe ich da noch was in dem
Ich glaube ich glaube das reicht so
ja
Fuck cube ctl
Kann ich mir immer aus dem kopf nicht merken wie das funktioniert gerne shelter running container cube ctl exec
Nee da musst du noch hier das da das da cube ctl exec minus i minus t bla bla blub
Das das da
Ja minus i minus t
Jetzt haben wir eine shell im container gut
Und jetzt können wir das mal probieren guck mal meines environment rein man sieht aha aha fällt euch was auf
Der proxy hat schon injected in meinen workload
guck mal
Der hat injected db port auf 5000 und db host auf local host das ist genau das was er machen sollte
Und man wird jetzt auch sehen wenn wir uns jetzt mal die ports angucken es laufen auch nicht nur einer sondern zwei
Normalerweise laut dem deployment läuft ja nur ein
Container aber es läuft zwei und was läuft da es läuft einmal die normale anwendung und einmal der proxy der injected wurde
Können wir uns auch mal die logs angucken cube ctl logs
das da
Eine da muss man jetzt genau guck jetzt zeigt er dir das nämlich auch an
Der sagt okay von was soll ich denn die logs anzeigen es gibt einmal den container da drinne
Sql app da gibt es keine großartigen logs für oder es gibt ein
default proxy workload
Ja guck mal
Und und das ist er das ist der proxy der injected wurde
Das ist schon ziemlich praktisch was macht er denn wenn du die variable für den container schon gesetzt hättest ich habe die variable für den
Container gesetzt es kann keinen konflikt geben
Ich setze die variable für den container ich kann auch sein dass man das machen muss
Aber anscheinend anscheinend
Überschreibt er die dann also man kann hier quasi reinschreiben ich möchte diese variable setzen und ich vermute mal der match darauf ob set
Bei operator im value steht dann überschreibt er die beim injecten wie auch immer da das im hintergrund macht keine ahnung
Und jetzt ist natürlich nur die frage ob der ganze schritt auch funktioniert
Okay exact in den container rein jetzt brauchen wir mal ein beispiel
Hier docs
Docs
Examples postgres da stand doch da stand doch hier was drin hier psql host sleep bla bla bla
Okay, dann gucken wir uns die logs an hiervon
Ist minus w
Kann kubernetes standardmäßig logs zählen cube ztl oder ist es
Nicht will ich zählen ich will genau live logs zählen
das kubernetes
Minus f genau sowas wie minus f
Kann das auch minus f
Das kann das ist das wusste ich gar nicht dass das auch das kann das aber noch nicht lange
Also ich kann mich noch daran erinnern dass das früher
Nicht ging
Das ist ja nice okay da kann man sich live zugucken was passiert wenn ich darauf zugreife
Es funktioniert
Also ich meine ich bekomme eine anfrage und dass ich ein passwort eingeben muss ja das ist das ist noch nicht das ergebnis was ich
haben will aber der proxy
Funktioniert das schon mal mega nice guckt mal leute ich kann im endeffekt jetzt einfach hardcoded bei meiner anwendung das hier angeben
und das bei jeder anwendung dafür
Ich gebe jetzt einfach an
Datenbank connect also das könnte ihr nächst beliebige anwendung sein jetzt ist das postgres command line tool
Ich kann jetzt angeben host localhost port 5000 usernamen ja
da
Da beißt sich gerade noch ein bisschen ja und die b-namen ok die b-namen ist das einzige was ich angeben muss ja was ich haben
will
Okay jetzt fragt er mich natürlich nach dem passwort und das passwort kenne ich nicht das passwort
Ich überlege gerade ob ich das passwort einfach mal setze um zu gucken ob die verbindung
Prinzipiell funktionieren würde ich mein mein ziel ist es ja dass ich gar kein passwort mehr brauche
Wobei ich gebe einfach mal den kubernetes den service account an den ich hier den ich hier
Hier benutzt habe oder probieren wir das doch mal aus hier diesen service account probieren wir doch jetzt einfach mal ein username
Fuck
Moment da ist ein leerzeichen
Passwort shit
Wäre auch zu einfach gewesen wenn das jetzt funktioniert hätte ich habe ja was vergessen ich habe ja was ganz vergessen
Fällt mir gerade ein moment das stand wartet mal warte mal warte mal ich habe das gar nicht eingeschaltet mit dem automatisch authentifizieren
Moment moment moment hier api documentation
Private
Api
Man kann übrigens anstatt variablen namen auch in socket pass setzen auf der kiste und port fest
Encoden und alles hier das brauche ich
Theoretisch müsste dein postgres klein zu einer art sso machen ja das ist ja das geile
Das muss der postgres klein und die anwendung nicht machen das macht der proxy für mich
Das ist ja gerade das nice daran ich brauche eigentlich gar nichts außer den username mehr zu wissen bei für die anwendung dass sie
Funktioniert und sie ist trotzdem abgesichert über die benutzerverwaltung in der google cloud
Das ist ja gerade das richtig nice daran
Ich glaube ich habe das vergessen beim deployment hier
Cube ctl delete minus f löschen wir das ganze noch mal
Deployment
True true lul weh
Trotz minus a
warum läuft das noch
Weiß warum das noch warum das noch läuft weil ich weil ich die live in das probe rausgenommen hab
Jetzt jetzt checkt er nicht ob der container fertig terminiert ist oder nicht aber es müsste es müsste sich jetzt eigentlich gleich alles beendet haben
okay
Ich glaube jetzt passt das alles habe ich hier noch das in der historie drinstehen
Ja das muss ich mir mal kopieren weil das brauche ich gleich wieder lul okay apply
running
Um die logs was mit dieb l irgendwas was übersetzt ok
Exakt ja das heißt jetzt ja anders das ding habe ich ja auch nicht die logs geteilt wo ist das hin doch
By the way ich kann euch cube ctl autocomplete nur empfehlen sonst dreht man irgendwann durch
okay prege leute
Es funkt es geht alter ist das nice
Es funktioniert ich kann auf die datenbank zugreifen ohne dass ich passwörter brauche ohne dass ich connection strings brauche ohne dass ich irgendwas brauche
und das okay aktuell
Aktuell ist es natürlich immer ein bisschen blöd ich greife mit dem kubernetes service account zu auf das alles andere auch zugreift
Aber das würde ich natürlich wenn ich das produktiv betreibe nicht so machen da würde ich da kriegen die anwendung vielleicht einen eigenen
Datenbank account aber das ist guck mal hier unten in den proxy log sieht man es auch
Ja mega nice dass das ist richtig gut also ich glaube das könnte uns wirklich richtig was bringen auf der arbeit weil jetzt so mal jetzt
So mal zur erklärung warum warum das cool ist
also normalerweise
Stellt euch mal vor ich bin jetzt ein entwickler oder ein
Typ der eine anwendung in kubernetes deployed der zugriff auf den auf eine datenbank brauche
bräuchte bräuchte der müsste sich jedes mal darum kümmern
dass er den den richtigen host für die datenbank einträgt
den muss er irgendwo herbekommen public ip von der datenbank den datenbank port
den richtigen username und das passwort dafür
und das brauche alles nicht
das einzige was der jetzt braucht ist der muss seinen datenbank namen wissen ja gut und das würde ich von ihm erwarten dass er
weiß welche datenbank er benutzen möchte
wir können auch mal testen ob das mit der anderen datenbank
Datenbank funktioniert wir gehen einfach mal kurz rein sagen databases postgres ist halt einfach nur die default datenbank wir erstellen noch mal eine weitere
datenbank die heißt hier
ultra wichtig brot
Bester datenbank namen man darf sich übrigens jetzt hier nicht nicht verwirren lassen
weil man databases erstellt also was hier erstellt wurde
auch auch wenn es eine sql instance ist das ist quasi der
Das ist eine vm auf der eine datenbank läuft in dem fall postgres
Aber man muss natürlich in der post im postgres
Selbst noch datenbanken für die unterschiedlichen anwendungen anlegen
Also wir haben jetzt also wir haben jetzt nicht zwei datenbanken erstellt wir haben jetzt eine datenbank erstellt
Postgres postgres vm erstellt und darin jetzt eine datenbank erstellt die sich ultra wichtig brot nennt
Wo ich mir nicht ganz sicher bin ob dieser user standardmäßig zugriff hat auf diese datenbank
Und wenn nicht bin ich komplett unfähig
Datenbank queries zu machen um dem user rechte drauf zu geben
Aber probieren wir es mal wir wollen zugreifen auf
Ultraport wichtig geht mega pork das heißt der typ der jene anwendung deployed muss wirklich nur noch wissen
Wie seine datenbank heißt im endeffekt
Und und theoretischen user wobei ganz ehrlich den user den würde ich sogar vergeben nicht pro anwendung
Wenn ich es mir einfach machen würde sondern sagen wir mal pro
Ja
Security stufe vielleicht dass man sagen würde okay
Dieser user es gibt ein user für alle def daten datenbanken oder so was was glaube ich auch okay ist so und dadurch dass ich das jetzt
Über diesen user in der cloud mache dass das alles über meinen kubernetes service account geht
Hier
Kann ich auch die komplette user verwaltung in der google cloud benutzen also ich kann hier noch
Conditions hinzufügen dass ich ihm dann zum beispiel sagen sage hier keine ahnung du darfst
Ressourcen da und da das nicht benutzen und sowas in der richtung
Ressources service ist bla bla sonst was also ich kann ich kann jetzt wirklich ganz genau einschränken und zwar nicht
Irgendwie über irgendwelche komischen
Postgres secrets und sonst was das kann ich weil weil
Dieser service account benutzt wir kann ich ganz genau einschränken was die denn jetzt eigentlich machen dürfen
Das ist schon cool das hat wirklich was das ist das ist relativ sicher das kannst du besser absichern als theoretisch
Username password kombi noch mal weil es noch fein granularer machen kannst und die leute die anwendung darauf betreiben wollen
Die müssen gar nichts mehr können
Die müssen gar nichts wissen die müssen nur noch im prinzip ihre datenbank wissen wo sie hinwollen
Ja und wahrscheinlich könnten sie sogar eine neue datenbank erstellen mit dem user
Chat gewonnen ob das funktioniert da brauche ich aber mal jemand der sich mit postgres auskennt
Nämlich chat wie verbindet man sich
Wie verbindet man sich zu
Zu postgres ohne eine datenbank anzugeben wahrscheinlich gar nicht oder dann verbindet man sich nur zur default zur default datenbank
Und jetzt kann ich sagen create database keckel zum beispiel das darf ich nicht mit dem user okay
Warum darf ich das nicht mit dem user wahrscheinlich weil ich nur cloud sql client bin
und cloud sql instance user
Der operator darf nicht ausfallen ja gut der operator
der operator
Läuft auf dem kombiniertes cluster und hat drei notes dann heißt er läuft auch dreimal
Also da wünsche ich mir jetzt nicht so viel auch geht das auch mit zertifikat wie meinst du kleinen zertifikate oder was meinst du
oder wie oder was
also google cloud sql kann kleinen zertifikate
Aber wenn du das so wie ich hier machst mit dem proxy brauchst du ja gar keinen kleinen zertifikat mehr
also kleinen zertifikate gehen
Kann ich dir sogar zeigen wie das funktioniert das ist relativ simpel du gehst dir auf connections
Security und hier kannst du guck create kleinen zertifikat da sagst du ein blubb keck weh
Und dann hast du hier die ganzen sachen die du brauchst zum connecten ich hoffe ich habe jetzt alles schnell mitgetippt
Genau
So funktioniert das und kann ich das entlöschen another operation is in progress na gut
Kappa knaps dankeschön für den prime sub
Jetzt kann ich es löschen
Also so funktioniert das auch mit kleinen zertifikaten ja wenn du so machst wie ich mit dem proxy dann brauchst du ja gar keine kleinen zertifikate mehr
weil
Du connectest dich gegen local host dahinter ist prinzipiell alles verschlüsselt und es geht über das google
Im und die benutzerverwaltung in der cloud also da kannst du es ja sogar noch besser einstellen was wie wie wer wo wie was darf
Aber ja du kannst prinzipiell das auch mit kleinen zertifikaten machen zur zur authentifizierung habe ich sogar auf der arbeit schon gemacht das funktioniert auch wirklich
Ja der proxy ist ich weiß nicht wie lange schon im stream heute war es also der proxy macht mehr als nur proxy
Der proxy macht folgendes guck mal ich verbinde mich auf local host also ich bin hier auf meinem kubernetes container drauf
Der proxy verbindet also nein psql verbindet sich auf local host port 5000 mit einem google
Service account in wirklichkeit läuft hier drauf ein sql proxy
der wiederum
dann die authentifizierung mit diesem service account macht also sprich
Alles was dieser service account macht darfst du machen und was er nicht darf darfst du nicht machen also du musst gar nicht gar keine
großen gedanken mehr machen um
user in der datenbank oder irgendwelche
firewall regeln wer wohin darf werden nicht wohin darf es darf einfach gar keiner irgendwo hin außer er geht über den proxy
Vom proxy hinter den proxy ist eh alles verschlüsselt abgreifen kann das keiner weil das ding injected ist auf local host
und der proxy selbst
Macht dann die authentifizierung gegen das google zeug also das ist echt richtig geile kombination und
Erleichtert wenn es so willst allen allen die arbeit was ich jetzt noch nicht gecheckt habe ist wie ich das probieren wir jetzt mal aus
Wie ich diesem user hier rechte geben kann
Für
Dass ich datenbanken erstellen kann ich meine ich könnte dem sql admin geben
Das könnte vielleicht ein bisschen zu viel des guten sein aber schauen wir mal ob das funktioniert
Sql admin
Create
create database keckel
Okay
Das ist jetzt irgendwelche datenbank magic keine ahnung wie das funktioniert
Frag mich nicht ich habe keinen schimmer wie man das einrichten kann dass das funktioniert
Vielleicht vielleicht ist das auch eine sache die man hier irgendwie bei users einstellen muss oder so keiner kein plastenschimmer
Wie man also chat ihr habt ihr habt wie listet man user so nee postgres list user
Minus was minus die u
Ja
Ja gut der hat ja auch nix der hat ja auch keine berechtigung
Das heißt ich müsste ich müsste dem jetzt erst mal berechtigung geben da hört meine datenbank da hören meine
Datenbank skills auf kein kein plastenschimmer wie man das jetzt gescheit macht
Einer von euch chat seiner von euch richtig richtig higher q was datenbank angeht
Wie gebe ich dem user hier jetzt berechtigung daten create create data db
Ich meine ich kann googeln aber vielleicht ist ja der chat der chat muss auch mal glänzen heute
Kann ich meinen apple futtern in der zwischenzeit
kramt
Keine ahnung wie das funktioniert ich habe von ich habe von datenbanken keine ahnung
Funktioniert
Okay also was sagen die dazu
All privileges
Kann ich mir die rechten
Selbst kann ich mir die Rechte wahrscheinlich nicht geben, vermute ich jetzt einfach mal.
Ah, da kann man kein Ad benutzen, das ist natürlich auch ein Sack.
Vermission denied, ja logisch.
Da muss ich mich aber als Admin verbinden, wollte ich gerade sagen, das wäre ja bescheuert,
wenn das einfach so funktioniert, ne?
Okay, das heißt, ich verbinde mich jetzt als Postgres.
Postgres, aber da habe ich das Passwort nicht für.
Das heißt, ich gehe jetzt erstmal in meine Datenbank
und denke mir mal kurz auf die Schnelle ein Poggers highly secure Passwort aus,
was ich da jetzt reinpasten werde.
Change Passwort.
Was ihr nicht seht.
Okay.
User updated.
Okay, da sind wir am Start.
Ah, fuck, ich habe das Passwort geleakt, lul.
Macht aber nichts,
weil die Datenbank ist nicht öffentlich zugreifbar.
Alter User.
Okay.
Hat das jetzt funktioniert?
Muss ich jetzt irgendwie Save oder sowas machen?
Leute, ich habe echt keinen Plan von SQL-Syntax-Kram.
Okay.
Create database keckel.
Easy, funktioniert.
Drop.
Database keckel.
Jawohl.
Datenbank permissions.
Siehste, Premiere, da habe ich wieder was gelernt.
Easy.
So, und mit den Berechtigungen kannst du jetzt tatsächlich alles machen, was du willst.
Ich meine, ich würde es nicht unbedingt einem Kubernetes Service Account geben normalerweise,
die Berechtigung da drauf, ja.
Aber jetzt ist es halt nice.
Jetzt kann jeder auch sich eine eigene,
jede Anwendung sich auch eine eigene Datenbank erstellen,
wenn er das braucht.
Das ist cool.
So, eine Sache will ich noch ausprobieren.
Und zwar,
macht doch eher der DB-Admin.
Ja, mir geht es hauptsächlich auch um irgendwelche Entwickler-Bastelcluster.
Weil genau dafür ist es halt nice.
Da können die ihr eigenes Deployment machen, den Kubernetes.
Ich lege initial einmal die Config für den Operator an.
Und solange die ihr Deployment richtig taggen,
kriegen sie den Proxy injected in ihr Deployment
und können den Rest selbst machen.
Finde ich eigentlich sehr pog.
Es geht mir hier nur um Entwicklung.
Also sprich, die könnten jetzt natürlich auch jede Tabelle droppen von allen anderen Usern.
Das sollte natürlich nicht so sein.
Also eine Sache will ich noch ausprobieren.
Und zwar, ich lösche das Deployment mal wieder.
Und zwar, was wir jetzt mal machen ist,
ich öffne das mal in Visual Studio Code.
Ups.
Okay, was habe ich jetzt gemacht?
Ich öffne das mal.
Oh ne, ich muss mal kurz zumachen.
Noch mal aufmachen, neu aufmachen.
Ich öffne das mal in Visual Studio Code.
Und zwar haben wir doch jetzt hier diese Deployment Postgres Datei.
Nervt nicht rum.
Was wäre, das ist kein YAML.
Das ist, ähm, Kubernetes.
Äh, habe ich nicht.
Ist auch kein Helm-Template.
Missing Properties.
Ach, der will mich darauf hinweisen, dass ich irgendwie Mist gemacht habe.
Alter, jetzt sei mal nicht pepsiger als der Papst hier, Kubernetes-Plugin.
Also, es ist jetzt ja so,
dass es aktuell nur für dieses eine Deployment hier gilt.
So.
Und was ich jetzt mal ausprobieren will, ist folgendes.
Wir ändern das jetzt mal.
Wir nennen das hier nicht Deployment, sondern wir nennen das hier einfach mal,
keine Ahnung, wie heißt das da oben?
Ja.
Auth.
Work.
Load.
YAML.
So, Copy, Paste.
Und das hier nennen wir Postgres.
Oder hier App.
App.
App1.YAML.
Besser Name überhaupt.
So.
Hier schmeißen wir das raus.
Und hier schmeißen wir das raus.
Ah, da haben wir das schön einzeln.
Kommentare sind overrated, outdated, debated.
Niemand braucht Kommentare.
Ich finde es an der Stelle wirklich viel übersichtlicher.
So.
Und jetzt, und jetzt was ich ausprobieren will, ist folgendes.
Ich würde, dieses Ding würde ich einmalig als Admin einspielen.
Und es kann ja mehrere Deployments geben.
Mit unterschiedlichen Namen.
Das heißt, die Labels und Selectors funktionieren an der Stelle nicht.
Ich will jetzt mal gucken, ob ich hier einen Workload-Selector hinkriege,
der beliebig viele Deployments von dieser App automatisch injekten würde.
Versteht ihr, was ich meine?
Also mein aktuelles ist hardcoded.
Ein Workload für ein, für ein, für ein Deployment.
Was ich aber will ist, ein Workload, der auf beliebig viele Deployments geht,
solange sie die richtigen Labels haben.
Weil es gibt ja nicht nur ein Deployment.
Es gibt ja mehr.
Es gibt hier zum Beispiel, keine Ahnung, App 1 nennen wir das Ding jetzt mal hier.
Match Labels, App 1, App 1, App 1.
So.
Jetzt gibt es aber auch, jetzt gibt es aber auch noch App 2 zum Beispiel.
Brauchst du aber für jeden DB-Cluster einen Operator?
Ne.
Ich brauche für jeden Kubernetes-Cluster einen Operator.
Mit dem Datenbank-Cluster hat das nichts zu tun.
So.
Das ist, das ist App 2.
So und jetzt Match das, ich glaube jetzt sieht man das, jetzt sieht man das Problem.
Hier kann ich jetzt ja nur eintragen, App 1 oder App 2.
Aber ich will sowas haben im Endeffekt.
Doch.
Doch, es gibt eine, eine Entwicklungs-Datenbank.
Es gibt, Moment, Moment.
Ne, ne, ne, ne.
Nicht Datenbank.
Nicht Datenbank.
Ähm.
Also ich meine jetzt, ich meine die Postgres-Instanz.
Auf die dürfen beide zugreifen.
Datenbank darf sich jeder fälligst eine eigene anlegen.
Das ist richtig.
Ja.
Ja.
Wenn ich einmal.
Also.
Für jede.
Es ist egal, ob ich einmal Postgres und einmal MariaDB habe.
Für jede Datenbank-Instanz brauche ich einen neuen, äh, Auth-Workload.
Korrekt.
Du siehst ja, hier steht ja nicht mal der Datenbank-Typ drinne.
Also mal angenommen, du hättest jetzt, du hättest jetzt eine, äh.
Ups.
Du hättest jetzt, du hättest jetzt eine MariaDB.
Dann ist das hier vielleicht keine, dein Test, deine Test-Datenbank ist MariaDB.
Ja.
Aber das ist ja auch nicht schlimm.
Das würdest du halt einmalig anlegen, an wie viele Datenbanken hast du.
Wenn du natürlich eine Datenbank-Instanz pro Deployment, pro Cluster hast, dann bringt
dir das Ganze nix.
Aber wenn du beispielsweise eine Datenbank hast, auf die mehrere Anwendungen zugreifen,
also eine Postgres-Instanz, auf die mehrere Anwendungen zugreifen, um dort ihre Datenbanken
anzulegen, dann ist es sinnig.
Äh, heute stimmt übrigens nicht.
Kombiniert das YAML-File.
So, jetzt wollen wir das nämlich mal ausprobieren.
Wie baue ich einen Selector für Label?
Da bin ich komplett Noob.
Ja.
Ja, gut.
Okay, machen wir mal Labels.
Geben wir das schon mal an.
Direkt unter, direkt unter Metadata.
Deployment-Label.
Ich kann mir immer nicht merken, an was, an welche Stellen der Campbell kommt.
Hier.
Direkt, direkt unter Metadata.
So, Labels machen wir jetzt mal sowas wie, äh, keine Ahnung, SQL.
Äh, nee, SQL.
Wie funktioniert das mit Labels?
Ah, nee, App.
Ja, machen wir so.
Wobei das eigentlich egal ist, wie ich das nenne.
App, SQL oder so.
Ja.
So, Label, also das ist Key, das ist Value.
So, und jetzt brauche ich einen Selector auf alle Deployments, die, ja, sowas hier.
Alle Deployments, die das Label SQL enthalten.
Kannst du auch bestimmt ein Label DB-Type machen.
Ja, ja, ja, ja, ja, sowas in der Richtung.
Könnte man machen.
Ich mache es jetzt mal so, mit App, App-Type SQL.
Wie funktioniert das jetzt?
Node-Select, wie, einfach so?
Okay, das muss ich in die Hilfe, das muss ich mal in die Hilfe gucken.
Workload-Selector.
Okay.
Selector, Option, Select Resource using Labels.
See, Label-Selectors, Label-Selectors.
Label-Selector, ja, machen wir doch.
Also, von der Idee her, mache ich einfach Workload-Selector.
Nee.
Ach, Kind Deployment?
Wie muss denn das dann aussehen?
Nee, das habe ich, das checke ich jetzt gerade nicht.
Haben die da nicht, haben die irgendein ordentliches Beispiel für?
Workload-Spec, Describe, which, Describe, which, should be, must specify kind, ah, Name oder Selector.
Okay, Kind Deployment, das war doch ursprünglich ja auch so, ja.
Okay, Moment, Deployment.
Und dann muss ich unten drunter Selector machen.
Selector, Selector.
Und da drunter dann App gleich SQL.
So, okay.
Das müsste, das müsste funktionieren.
Ja.
Also, dann testen wir das doch mal.
Cube CTL, Apply, Minus F, Auth Workload.
Fuck.
Was?
Okay, nice, dann habe ich das falsch, falsch gemacht.
Irgendjemand eine Idee, wie man das richtig schreibt?
Must specify, was, App weg?
Nee.
Nee.
Das glaube ich nicht.
Nee, nee, das muss schon doppelt.
Ist vielleicht der Resource-Type anders?
Nee.
Selector.
Moment, mit welcher Version haben die das mit dem Selector eingeführt?
Nicht, dass das jetzt super krass Bleeding Edge ist.
Ich benutze V1.2.
Nee, das war da auch schon drinne.
Was ist, was ist hier dran falsch?
Field Selector.
Was passiert denn, wenn ich da sowas hinschreibe, was ja so nicht funktioniert?
Select Resources using Labels.
Siehste, ich habe das schon richtig gemacht.
Das muss so gehen.
Aber was hat er für Schmerzen?
Unknown Field.
API Version V1, das ist aber richtig.
Es gibt nur API Version V1.
Selector App SQL.
Meinst du, das muss man quoten?
Boah, man weiß ja nie.
Nee.
Okay.
Es gibt nur V1.
Okay.
Label Selector.
Das ist ja immer irgendein Beispiel.
Was ist der Unterschied zwischen Git-CMD und Git-Bash?
Ich würde sagen, das eine ist Git, was nur Bash mitbringt.
Und das andere ist nur Git, aber du musst es über Windows...
Nee, du musst es über Windows-CMD ausführen.
Ah, Moment.
Match Labels.
Was ist das?
Okay, wie?
Match Labels.
Gibt das jetzt Sinn?
Okay, Apply.
Ah.
Jetzt hat er es gefressen.
Gut.
Ich bin jetzt mal gespannt, ob das funktioniert.
So, kubectl.
Also, wir haben jetzt unseren Work.
Das wäre das, was ich als Admin mache.
Einmal Initial beim Server.
Beim Kubernetes-Cluster aufbauen.
Oder was heißt initial?
Pro Datenbank-Instanz.
Und jetzt kommt irgendeiner her und deployt eine neue Anwendung.
Nämlich App 1.
So, jetzt ist die Frage...
Jawohl!
Es wird injectet.
Funktioniert.
Exact.
App.
Ja.
psql.
Easy.
Nice.
Oh, das ist ja geil.
So, und jetzt haben wir...
Apply.
Jetzt deployt noch einer eine App.
Zack, kriegt es injectet.
App 2.
Funktioniert.
Okay, das ist extrem nice.
Das ist wirklich nice.
Jetzt können die Leute einfach hergehen.
Ihre Anwendung deployen.
Also, wir reden hier von einem Entwicklung- und Test-Cluster.
Ja.
Und können ihre Anwendung deployen.
Und können rumsauen, wie sie wollen.
Ohne mich nerven zu müssen.
Die können einfach deployen, was sie wollen.
Und haben sicheren Datenbank-Access.
Und aber auch nur, was der Account hergibt.
Ob man das für Nicht-GCP-Cluster auch verwenden kann?
Also, den SQL-Proxy im Prinzip wahrscheinlich schon.
Aber die ganzen anderen Sachen sind ja drum herum.
Aber du kannst auch sowas wie...
Wie das hier benutzen, ja?
Wenn du sowas ähnliches selbst bauen willst.
Als Proxy.
Kannst du mal das Repo linken?
Na, den...
Den hier wirst du nicht...
Also, den...
Den Proxy-Operator.
Den kannst du vergessen.
Der ist von Google explizit für Google.
Ja.
Den hast du explizit für Google gebaut.
Das wirst du nirgendwo anders gescheit benutzen können.
Gehe ich mal von aus.
Aber...
Die anderen Anbieter haben ähnliche Sachen.
Also, ich weiß, dass die...
Das Azure...
Azure hat irgendeinen Database-Gateway oder sowas.
Habe ich aber nicht verwendet.
Und AWS, weiß nicht, Chat?
Irgendjemand von euch meinte doch vorhin, dass AWS das auch hat.
Darkseid, was wir heute gemacht haben.
Zeig dir das mal.
Auf die Schnelle.
Also, guck mal.
Pass auf.
Obacht.
Pfeiffertime, Leute.
Wir erklären das jetzt mal dem Darkseid, was wir gemacht haben.
Siehst du?
Siehst du dieses Kubernetes-Deployment hier?
Das ist äußerst simpel.
Da passiert eigentlich so gut wie gar nichts.
Das startet ein Pod.
Das startet ein Pod.
Mit dem Default Postgres-Image.
Es könnte übrigens auch ein Debian-Image sein.
Ist vollkommen egal.
Das ist alles.
Mehr macht das nicht.
So.
Und jetzt halte dich fest.
Ich deploye jetzt diese App, die du hier siehst.
Wie viele Container würdest du erwarten, die starten?
Wie viele Container würdest du erwarten, die starten?
Wie viele Container würdest du erwarten, die starten?
In diesem Deployment.
Also, Replikas 1.
Aber wie viele Container hier in dem Pod starten?
Einer.
Korrekt.
Ich auch.
So.
Aber, wenn ich das deploye, wirst du gleich sehen.
Guck mal da.
Es sind ja 2.
Warum sind das denn 2?
Es sind 2,
weil
hier
Was macht denn Postgres hier für komische Dinge?
Ja, egal.
Es sind 2,
weil hier ein Postgres
beziehungsweise ein SQL-Proxy
injected wird.
Der auf
localhost
Port 5000 läuft.
Und das Coole ist jetzt,
ich kann mich jetzt verbinden
zu meiner Datenbank von diesem Container
über den injected Proxy
ohne,
dass ich den
Connection-String für die Datenbank brauche,
ohne, dass ich den Port wissen muss für die Datenbank
und ohne, dass ich
ein Passwort für die Datenbank brauche.
Und das Ganze passiert trotzdem komplett
geschlüsselt und anhand
des Google Cloud Benutzer
Managements. Also ich kann auch
nur das machen, was ich machen soll.
Das heißt, du kannst jetzt ganz viele Versionen von
dieser App deployen. Wir gehen jetzt davon aus,
das sind unterschiedliche Apps.
Und die Leute, die das
deployen, beziehungsweise Entwickler, die das
testen wollen, die müssen sich nicht
mehr um irgendwelche Connection-Strings und Datenbank
Kram kümmern. Das heißt, ich als
Admin richte das einmal initial ein
und alle weit, genau,
das ist wegen dem Proxy und alle weiteren
Deployments
kriegen diesen Proxy injected
und können dann mit einem Service-Account
auf die Datenbank zugreifen.
Der Service-Account ist vielleicht nicht so clever
gewählt, weil das alle Container
im Kubernetes-Cluster jetzt dürfen.
Genau, ich muss einmalig für diesen Cluster
diese Config einspielen
und er überwacht jetzt
alle Deployments, die getaggt sind
mit dem Label SQL.
Also, wir gehen jetzt...
Leute, geht davon aus,
das sind unterschiedliche Apps. Ja, geht davon aus,
das ist eine Node.js-App und das ist eine .NET-App.
Macht keinen Unterschied. Es funktioniert.
Das heißt, ich als Admin lege das nur einmal
an und alle können dann
darauf zugreifen, ohne dass sie sich groß Gedanken machen müssen.
Das ist extrem nice.
Extremly pog.
Guck, und das funktioniert
hiermit, weil der Proxy quasi
Authentifizierung macht mit dem Service-Account.
Allerdings geht das Ganze nur, wenn die
Anwendung selbst unter diesem Service-Account gestartet
wurde. Alles andere wäre ja
irgendwie fragwürdig.
Ja.
Und das finde ich richtig gut.
Das gefällt mir.
Das gefällt mir sehr, dass das so einfach...
Ich meine, wir haben fast drei Stunden am Start.
Aber wir haben ja auch links und rechts ein bisschen
geguckt. Aber das ist wirklich
extrem nice.
Das werde ich morgen auf der Arbeit gleich bauen.
Gerade für unsere Entwicklungs-Cluster ist das nice.
Da können die ganzen Entwickler
einfach hirnlos deployen.
Das klingt jetzt böse. Das meine ich gar nicht.
Die können einfach hirnlos deployen und brauchen
weder von mir Datenbank-User
noch Datenbank noch irgendwas.
Die können einfach deployen. Im Zweifelsfall können sie
sich zwar gegenseitig die Datenbanken
abschießen,
wenn sie sich wirklich connecten und sagen
Drop Database. Aber hey, ich meine,
das ist ein Entwicklungs-Cluster. Das soll ich mir nicht so anstellen.
Das finde ich wirklich
sehr, sehr pog.
Das gefällt mir.
Was ist bei Google möglich?
Bei Google weiß ich, dass es geht.
Ich denke mal, dass andere Cloud-Anbieter
auch ähnliche Sachen haben.
Also ich weiß, dass Azure
sowas wie Database Gateway hat.
Ja.
Aber das habe ich auch nie benutzt.
Das ist aber cool, oder?
Also, Chat, jetzt mal
eine Frage an euch. Nachdem ich jetzt ja erstmal
die letzten Viertelstunde extrem begeistert
war davon. Konnte man das
eigentlich, was wir bis jetzt gemacht haben,
alles soweit verstehen?
Und erkennt ihr,
oder versteht ihr, warum mich das so
freut, dass das funktioniert?
Also, dass das was wirklich cooles ist?
Oder sagt ihr, die Easy-Kram
habe ich in zwei Minuten selbst gescriptet?
Haha. Kann ja auch sein.
Ja.
Prompt.
Exzellent, Leute. Exzellent.
Chat ist einfach zu
schlau. Er versteht immer instant alles.
Also ich futter.
Ich futter seit irgendwie einer halben Stunde
noch an dem letzten
Stück Apple
und Pfirsich. Halber Apple,
halber Pfirsich.
Du hast jetzt impliziert, dass du das für Prod nicht nutzt.
Doch. Würde ich.
Würde ich. Aber ich würde es ein bisschen anders machen.
Also ich würde denen in Prod
zum Beispiel keine Rechte geben,
dass die andere
Datenbanken löschen dürfen.
Und ich würde
in Prod nicht den
globalen Kubernetes Service Account nehmen,
sondern beispielsweise einen Service Account
extra dafür anlegen.
Eventuell könnte man
sogar so weit gehen und sagen, wir legen
einen Service Account pro App an.
Allerdings wenn man so weit geht,
könnte man auch gleich Workload Identity
verwenden.
Dann kann man Kubernetes
Service Accounts mit Google Service Accounts
verknüpfen. Echt? Nice.
Hahaha.
Hahaha.
Und verschiedene
Namespaces.
Ja, gut, das stimmt. Die würde ich nicht alle
in den
Default Namespace klatschen.
Aber, auch das probieren wir
mal kurz aus.
Das sollte aber unabhängig von
Namespaces funktionieren.
Weil wir machen jetzt einfach mal hier den...
Och.
Wo muss der Namespace hin? Hier, oder?
Nee.
Doch, oder?
Namespace. Hey, kommt das direkt hier oben?
Warum habe ich hier kein ordentliches
Autocomplete? Was ist das?
Steht da kein Namespace?
Ähm.
Namespace Deployment.
Ich glaube, kommt das nicht in Metadata?
What?
Ich bilde mir auch ein, dass das hier
drunter kommt, ja? Hä?
Ich habe eben fünfmal Autocomplete
gedrückt, da kam nichts.
Naja. Okay, wir deployen
das jetzt in Namespace Kekl.
Wenn ich das jetzt deploye, wird der mir wahrscheinlich sagen,
dass der
Namespace nicht da ist.
Ja.
kubectl create ns
ging das nicht so hier?
Kekl.
Minus A.
Oh.
Warum erkennt der das nicht?
Der Operator?
Was ist da los?
Ich habe doch beim Operator
gar keinen Namespace eingestellt.
Muss man...
Also nicht, dass man das jetzt
deployt pro Namespace, aber da steht
überhaupt kein Namespace dabei.
Oder ist das wirklich nur pro Namespace?
Okay, das wäre shit.
Nee, das kann nicht pro Namespace sein.
Man kann hier sogar sagen, kein Namespace
und so.
Das würde eigentlich keinen Sinn machen.
Okay, schauen wir mal, wenn ich das jetzt
nochmal umstelle. Namespace.
Namespace.
Default.
Dann funktioniert es. Hä?
Das wäre aber
extrem hängen geblieben, wenn das
Namespaced wäre.
Warum sollte man das denn machen?
Man kann doch sogar,
hier steht doch sogar explizit drin,
dass man, mal hier API
Selector
Ach nee.
Man kann doch gar nicht
die Namespace...
Ah, da muss man das pro Namespace machen.
Okay, dann finde ich doch schon mal
wieder einen Teil weniger nice.
Ich meine, nicht wirklich so ein
richtiger, richtig
großes Problem, weil
meistens hält es sich doch gerade
stark in Grenzen, wie viele Namespaces
da... Aber
schon ein bisschen doof.
Ich hätte eigentlich gehofft, dass man das
lokal machen kann, also dass man das global
machen kann.
Kannst du sowas wie Target Namespace? Ja, ich kann
das wahrscheinlich einstellen.
Was ist das da? Workload...
Was ich wahrscheinlich machen kann, ist folgendes.
Wir machen das einfach mal so hier.
Dann ist es jetzt eben...
Machen wir hier nochmal das gleiche. Wahrscheinlich kann
ich jetzt hier unten auch sagen,
Namespace
Keckle, so.
Das müsste wahrscheinlich funktionieren
jetzt.
Ja, machen wir hier nochmal, dass es eindeutig ist.
Default, also das müsste jetzt
wahrscheinlich funktionieren.
Apply, minus F.
Ja.
Jetzt haben wir das zweimal drinnen.
Und jetzt haben wir Apply
von dieser zweiten Ressource.
Ports.
Okay.
Ups.
Delete.
Namespace.
Keckle.
Das funktioniert. Man muss den Kram
mehrfach, man muss den Kram pro
Namespace deployen.
Okay.
Ja, bisschen doof vielleicht, aber
nicht so schlimm.
Würde ich sagen.
Schade, dass es nichts Globales gibt.
Und ein Helmchart zum Installieren
wäre tatsächlich auch ganz nice, ja.
Das schlimmt wohl.
Chat, wie handhabt
ihr das mit
Namespaces? Macht ihr
pro...
Sagen wir mal angenommen, ihr installiert
mit Helm eine Anwendung.
Mr. Moogame, Dankeschön für den Sub.
Pog.
Angenommen, ihr installiert
mit Helm eine Anwendung.
Macht ihr dann pro
Deployment, oder
wie nennt man das?
Pro Release?
Pro Installation, sagen wir mal.
Einen eigenen Namespace?
Oder habt ihr sowas wie einen
Production Namespace,
wo dann die Anwendung reindeployed wird?
Und im Zweifelsfall,
wenn man die Anwendung mehrfach braucht,
macht man auch zwei Versionen davon in den gleichen Namespace.
Wobei das da halt wieder das Ding ist,
da musst du halt
aufpassen und die
Helmcharts
müssen gescheit programmiert sein,
dass es keine Konflikte bei Secrets
und sowas gibt.
Ja, meine Idee war halt,
meine Idee war halt,
dass die sich Namespaces
anlegen können, wie sie lustig sind.
Ja, irgendeiner
legt sich jetzt
ein Blub-Test
und kann da was reindeployen
und hat direkt Zugriff
auf die Datenbank dadurch, durch den Proxy.
Aber gut, ich mein, wenn's halt
nicht geht, dann geht's nicht.
Wobei, so einfach, also mit
geht nicht, gibt's nicht, ist es nicht.
Ich könnte auf ein
Kubernetes-Event reagieren.
Sobald Namespace angelegt wird,
triggere ich
einen Eintrag für diesen Namespace
für den Proxy-Injector.
Aber was
würdet ihr machen, wenn du die
gleiche Anwendung mehrfach deployen musst?
Ja, sagen wir jetzt mal,
ich mein jetzt nicht,
Replica ist hoch drin, ich mein, du musst jetzt
wirklich die gleiche Anwendung mehrfach
deployen. Zum Beispiel, du hast einen Cluster, wo du
testen willst, ja,
und dort
deployen halt, keine Ahnung,
zwei, drei Entwickler parallel
die gleiche Anwendung, um Sachen
auszuprobieren.
Da kommst du ja so nett
wirklich hin.
Oder sind eure Installer so gut
programmiert, dass sie keine Konflikte haben
bei Ressourcen wie Secrets und sowas.
Wie gesagt,
da kriegst du relativ schnell Konflikte,
wenn die Helmcharts nicht gescheit gemacht sind.
Create Namespace?
Ja gut, dann machst du rum wieder,
dann machst du eine eigene.
Dann machst du ja wieder einen eigenen Namespace.
Dann hast du da sowas wie Backend-Test 1,
Backend-Test 2 und sowas.
Bei uns ist pro Microservice
ein Namespace.
Ja, so ist das bei uns auch.
Das hier,
aber so,
nicht unbedingt,
aber in der Regel schon, ja.
Also so pro größere Anwendung,
also pro Anwendung ein Namespace.
Wir haben sogar eine Anwendung, die ist gesplittert
in zwei.
Ja, solange du halt selbst, solange du den Kram
selbst machst, geht das ja noch.
Hä? Die Pipeline programmiert aber keine
Helmcharts für dich.
Und wenn ein Hersteller dir eine Anwendung liefert
und das Helmchart halt nicht so ganz
optimal erstellt ist,
dass Secrets konflikten,
ja klar kannst du einen Bug-Report aufmachen, aber ist erst mal doof.
Also es ist zumindest
einfach, wenn du nicht aufpasst,
dass du konfliktende Sachen haben kannst in einem Helmchart.
Weil, wenn du im gleichen Namespace
mehrfach deployen willst,
dann muss das Helmchart
vor alle Ressourcen,
muss das noch
darauf achten, dass immer schön
Release-Name,
Release-Version und
alles mögliche noch davor gehängt
wird, sodass es sich
nicht konfliktet. Wenn du da an einer
Stelle nicht aufpasst, hast du irgendwelche Konflikte.
Ja, aber dann hast du
nicht das Problem, was ich jetzt beschrieben habe.
Und da bringt dir eine Pipeline
ja mal gar nichts.
Die können das ja, aber wenn das
Helmchart misstisch programmiert
ist, dann bringt dir...
Egal, worüber du das ausführst.
Das wirkt so, wie jetzt
hauptsache mal ein Wort gedroppt.
Ja, wie macht ihr das denn?
Habt ihr dann einen Namespace,
sowas wie Backend oder so?
Oder...
Frontend.
Ja, dann hast du automatisch
pro...
Installation einen eigenen Namespace.
Das ist ja das, was ich gerade wissen will, wie ihr das macht.
Ja, das ist klar.
Okay, also im Prinzip ist es...
Aber trotzdem, so schlimm ist es nicht,
dass das mit dem Proxy nicht funktioniert.
Übergreifend.
Namespace übergreifend.
Und wenn das in der Entwicklung
ein Problem ist,
dann kann ich immer noch auf Kubernetes Events
reagieren und das anlegen lassen.
Es gibt ja diesen, kennt ihr das Ding?
Kubernetes
Bash Operator
oder so heißt das Ding.
Shell Operator, genau.
Da kannst du
auf Kubernetes Events reagieren
und Shell Skripte ausführen.
Also du kannst...
Ich hab das dafür noch nie
benutzt, ja. Aber ich gehe
davon aus, man könnte damit
sagen, wenn ein Namespace
angelegt wird, dann
lege
automatisch den Proxy...
den Auth Eintrag
für diesen Namespace mit an. Das müsste funktionieren.
Wie lief es bisher? Es hat alles funktioniert,
Patrick, guck mal.
PSQL
hier, Connection auf
Localhost ohne Passwort.
Datenbankzugriff
funzt.
Alles funktioniert.
Dein CSS-Problem ist immer noch nicht gelöst.
Das ist ja wirklich...
Chat.
Haben wir irgendwelche high-end CSS-Leute?
Ich guck mal kurz Discord.
Ich mach mal kurz Discord auf.
Du hast das doch bestimmt irgendwo beschrieben.
Ich kopiere mal das Bild raus.
5-10 Minuten
Chatgear HighIQ.
Das wird jetzt gelöst.
Discord. Moment.
Discord.
Gucken wir jetzt mal rein.
Ähm...
Oh, SeriousMax, bist du noch da?
Ich hab grad erst deine Nachricht
hier auf Ploppen sehen im Discord. Ich hab gestern
da mal reingeguckt.
Es ging wahrscheinlich, ich hab's noch nicht angeklickt,
aber wahrscheinlich geht's um die DNS-Sache, oder?
Wie machen wir das
mit der DNS-Geschichte jetzt?
Soll ich irgendwelche Einträge
machen für dich, oder wie machen wir das am besten?
Hier.
Broggers.
Ihr CSS-Call-Problem.
In Blazer. Alter, jetzt geht's aber
ab hier.
Ich weiß nicht, wie ich das gescheit zeigen soll.
Ich bin nämlich nicht eingeloggt im Discord hier.
Okay. Chat.
Irgendwelche HighIQ-CSS-Leute am Start.
Wenn ja, dann guckt mal
im Discord in Broggers
mit Hilfe und schaut euch
mal das CSS-Call-Problem an.
Wär doch gelacht,
wenn bei so vielen Prime-Subs
kein HighIQ-CSS-Kenner...
Wo ist denn der Aus...
Ja, aber Sebarro, ich bin nicht eingeloggt.
Äh, Sebarro, Alter.
Max, ich bin nicht eingeloggt.
Genau, da kommt ihr direkt hin.
Wo ist denn der
Auskenn-Fuchs, wenn man ihn braucht?
Der war schon eine Weile nicht mehr da,
aber den Namen hab ich mir gemerkt im Zusammenhang mit
CSS. Der hat auch so einen
prägnanten Namen gehabt.
Was hat dich denn dazu gebracht,
eine Blazer-Anwendung zu machen, Patrick?
Das würde mich jetzt tatsächlich
noch mal brennend interessieren.
Und ist es eine Blazer-Server-Side
oder Blazer-Client-Side-Anwendung?
Blazer
an sich da schon...
Passt schon, ja.
Ich finde
die Client-Side-Sache
ein bisschen problematisch aktuell
noch, aber könnte durchaus was Gutes werden.
Okay, Leute, jetzt
zeige ich euch noch mal eine weitere
coole Sache von Terraform.
So zum Schluss.
Und zwar, passt mal auf,
wir haben doch jetzt hier unsere
Sachen angelegt im Kubernetes.
Wir haben den Kubernetes-Cluster
angelegt in der Google Cloud. Wir haben
Netzwerke und alles mögliche Zeug angelegt.
Und jetzt will ich das Ganze
wieder rückstandslos entfernen.
Also,
Terraform
Destroy. Und jetzt
wird Terraform rückstandslos wieder alles
löschen. Was ich selbst erstellt habe,
muss ich, by the way, auch selbst
löschen.
92 MB belegt.
Die Datenbank
lösche ich mal von Hand.
Und
ich hatte, glaube ich,
eine IP von
Hand reserviert.
Wow.
Nee, das ist
Kubernetes-Zeug.
Oder?
Okay.
So, und jetzt können wir
Terraform Sachen schmeißen, wieder alles weg.
Und Terraform schmeißt auch wieder alles weg.
Und ihr werdet es gleich sehen.
In, tja, 5-6 Minuten,
so lange wird es wahrscheinlich dauern, Terraform
ist nicht so schnell,
ist alles wieder rückstandslos
entfernt. Ach so, der Service-Account,
der ist noch da.
Das ist aber auch nicht schlimm, den lasse ich auch noch da.
Der kostet ja nix.
Jo.
Max Pogu.
Und wenn ich das nächste Mal im Stream,
mal angenommen, ich würde das nächste Mal an der Stelle weitermachen wollen,
würde ich einfach wieder sagen,
Terraform apply und es wäre wieder meine ganze
Infrastruktur da. Das ist schon, schon
sehr nice.
Bam Bam Buda hat subscribed vorhin, hab ich gar nicht gesehen.
Cringe, Max, ja.
Aber danke für den Sub.
Komplett an mir vorbeigegangen.
Bist du noch da?
War jetzt ein bisschen spät, aber ich hab's nicht übersehen.
Wahrscheinlich weg vor 2 Stunden,
aber irgendwann am Anfang des Streams.
Ach, du bist noch da? Nice.
Massive.
Nice.
Easy.
Easy.
Easy.
Easy.
So, das dauert jetzt ein bisschen,
weil Kubanetes Cluster erstellen und löschen
ist in Google Cloud immer
abfuck.
Yo, Jett, gibt's noch irgendwelche wichtigen Sachen?
Ich hab jetzt noch ungefähr 10 Minuten Zeit, bis das alles
gelöscht ist, so lange bleib ich noch on, dann hau ich ab.
Erzählt mal.
Hab ich irgendwas
Wichtiges verpasst? War irgendwelche
High IQ Dinger, die
an mir vorbeigegangen sind?
Was empfiehlt mir denn YouTube?
Hat YouTube vielleicht auf der Startseite irgendwas
Spannendes, wo ich sag, oh ja, das will ich
jetzt unbedingt noch gucken.
Wann ich Blazer mach? Ich glaube,
ich hab Blazer sogar
hier drinnen stehen, in meinem To-Do.
Weiß aber nicht, wann ich das mache.
Wieso haben Spiele keine Cheat Codes mehr?
Starting... Add is the biggest
line...
Yoshis Island ist so hart zu
emulieren, weil es diese SuperFX
Geschichte benutzt.
Why every programmer needs to
use this debug tool? Okay, gehen wir mal.
Es ist schon mal
reines Apple Zeug. Ach ne,
der Proxy, man.
Das ist im Prinzip sowas wie Postman,
was er hier am Start hat, oder? Ach ne,
der hat die
Development, irgendwelche Development Tools
für Google Zeug
auf. Ja, Clickbait-Gram.
Der Auskenn-Fuchs
schreibt im Discord. Moment.
Hat er jetzt gehört,
dass ich gesagt hab, der Auskenn-Fuchs kennt sich aus?
Weil im Stream?
Oder war das einfach nur Zufall?
Der kennt sich aus,
der Auskenn-Fuchs.
Der konnte mir sogar
erklären, wie man CSS-Grid richtig benutzt.
Und das ist wirklich schon mal auf ganz anderem
Level.
Auskenn-Fuchs, eh bester Name, ja.
Machst irgendwann mal wieder eine Homelab-Tour?
Ja, es fehlt eh noch eine komplette Tour.
Was haben wir denn hier?
ECMAScript 4, die verlorene Version.
ECMAScript 4?
Das muss ja vor 100 Jahren
gewesen sein.
Das ist irgendein Dashboard,
das braucht doch keiner.
Eine Battlefield-Trailer.
Wait a minute.
Road to Rome?
Da kann ich mich überhaupt nicht mehr dran erinnern.
Ach, das war ein Addon für Battlefield 2.
Ne, für Battlefield 1.
Zima-Board.
Ja, das kenn ich, aber da hab ich keinen Anwendungszweck für,
weil ich hab ja schon
eine ordentliche Kiste.
Als Homesurfer persönlich
bevorzuge ich mittlerweile Low-Power
x86-Hardware.
Das könnte sogar sein,
aber da hast du doch gar keinen Platz.
Kein scheiß Gehäuse und kriegst auch keine
PCI-Express-Sachen rein.
Also mit 10G ist
ja da nix.
Hab ich schon bei ein paar
Videos gesehen,
hat mich jetzt persönlich nicht so richtig überzeugt,
warum ich das haben will.
Außer, dass es schön klein ist, ja.
Aber ein bisschen größer schadet
ja auch nix.
Wir müssen reden. Hacken!
Jetzt geht's wieder los.
Keine digitalen Geräte.
Pass mal auf.
Mitten in Regensburg.
Überhaupt vernetzt in Deutschland.
Das ist aber schon
Hightech hier, was er am Start hat.
Also Hightech von vor
60 Jahren oder so.
Mit Schreibmaschine
und was ist denn das daneben?
Ein Funk-
Telegram-Ding oder
was bin ich hier sehend überhaupt?
Ich glaub letzter Stand war
2010.
Insgesamt
in Australien gibt's zwei,
in Japan gibt's welche.
Telegrammt der da rum oder?
Ganz nett.
Ach du Scheiße.
Was geht?
Echt? Ja.
Richtig oldschool, ja.
Warum nicht?
Warum nicht?
Im Prinzip ist das doch auch
eine Idee von ihm.
Der wird doch bestimmt auch mal ins Internet gehen.
Alte 90er-Jahre-Werbung.
Jawoll.
Das war so
cringy teilweise.
Ich dachte grad echt, das ist
Dings hier.
Als ich das gesehen hab,
hab ich gedacht, was macht denn,
also im Vorschau grade,
hab ich mir gedacht, was macht denn in den 90ern
der
ihr wisst wen ich meine, ne?
Aber
Hide the Pain.
Weiß gar nicht, wie der Typ richtig heißt.
Was macht der in den 90ern?
Was macht mein
Terraform? Ist es immer noch am Cluster
abbauen? Durchaus möglich,
ja. Hab ich schon gesehen,
ich hab den Titel gesehen,
ECMAScript 4,
hab ich gehört, das muss doch vor 100 Jahren gewesen sein.
Hamnett. Das hört sich nach
Amateurfunk oder sowas an.
Aus irgendwelchen Gründen
finde ich das damit. Klingt irgendwie so.
Was sagst du zum
Twitter-Rebranding? Boah, ich find's so
dämlich, Alter.
Ich hab die ganze Zeit mir immer noch gedacht,
okay, ich mein, er probiert jetzt
ein paar Sachen aus, die Sachen, die total
für'n Arsch sind, werden auch wieder rückgängig gemacht.
Aber ganz ehrlich,
so langsam aber sicher hab ich,
und ich bin übelst der Twitter-Fan eigentlich immer gewesen,
ich hab ja immer gesagt,
habt ihr öfters von mir in Streams gehört,
dass ich der Meinung bin, dass Twitter immer noch
das Beste ist, was es gibt,
im Social-Messaging-Bereich.
Aber so langsam,
ich weiß nicht.
Langsam vergeht mir auch der Bock auf Twitter.
Also, die letzten Änderungen
waren schon richtig hardcore dumm.
Vom Anmeldezwang, jetzt demnächst
sollen noch
Private Messages eingeschränkt
werden von Leuten, die nicht verifiziert sind.
Ich weiß nicht.
Also, dann wird immer
vorgeschoben, weil jetzt auf einmal
natürlich
das ein Riesenproblem ist und vorher nie ein Problem
war, ist klar.
Ich hab langsam immer weniger Bock auf Twitter.
Am Anfang dachte ich
ja auch noch, mal gucken,
vielleicht könnte das auch
nicht schlecht werden.
Aber langsam hab ich
immer weniger Bock drauf.
Ja.
x.com, Alter, wenn die Leute
mit x anfangen zu tippen und dann kommt
x.complete, es ist schon wieder Fail.
Ich mein,
es geht ja noch.
Ach, hier
ist es jetzt sogar schon wieder,
hier ist es jetzt schon x.
Heute Morgen bei mir war es noch Twitter, wenn man angemeldet war.
Jetzt ist es schon
durch x ersetzt, ja.
Was ist die Alternative?
Noch keine so richtig,
aber mal abwarten.
Es geht immer los
mit
einem gewissen
Unmut und kein Bock der Leute mehr
auf die Plattform. Das ist die
Grundvoraussetzung dafür, dass
es Alternativen überhaupt erfolgreich geben
kann. Das glaube ich ja immer noch nicht.
Immer sobald es
den Leuten zu sehr auf den Sack geht,
bietet
das Möglichkeiten, ja.
Aber mal gucken, mal gucken.
Mein Threads gibt es noch nicht
in
Europa, glaube ich, und ganz ehrlich,
ob ich jetzt so viel mehr auf den Zuck
habe, als auf Elon.
Ich kann mich gar nicht entscheiden,
auf wen ich weniger Bock
habe gerade. Auf Twitter,
so wie es jetzt immer mehr wird, oder
auf den Zuck und seine
neue Plattform. Nee, auf den habe ich
glaube ich. Dann bleibe ich lieber
dabei. Euch ist
der Zuck lieber, ja. Naja,
ich weiß nicht.
Das wäre ein guter
Name dafür. Da bin
ich auch skeptisch. Sie sind ja
kompatibel mit Mastodon, oder
sag mal, wie heißt das, Fediverse, oder
sowas. Aber ehrlich, da wäre
ich skeptisch, ob das nicht
die alte Microsoft-Taktik ist.
Ja, wir bandeln erst
so ein bisschen mit offenen Plattformen an
und
saugen darüber quasi
Leute ab zu unserer Plattform
und sagen, oh, wir sind ja so offen.
Und sobald es eine kritische Masse
erreicht hat, wird es möglichst inkompatibel
gemacht.
Fängt dann an mit Features, die nur auf der einen Seite
existieren und so. Ich weiß nicht,
ob das so eine tolle
Sache ist.
Das war die Microsoft-Taktik, ja.
Embrace, extend, extinguish.
Das sagst du jetzt.
Warte mal ab, bis du deine Firma
für zwei Milliarden verkauft hast. Dann
willst du das auch nicht mehr.
Dann wird es Zeit, dann muss der
Twitch-Chat als Consulting-Chat
angestellt werden.
Für noch mehr High IQ.
Ja, da ist schon was dran.
Das kann ja schon passieren, ja.
Okay, Leute. Reicht für heute.
Terraform und so hat zugeschlagen,
alles wieder abgebaut.
Ich glaube, wir haben wie viel? Zwei Euro ausgegeben
heute. Am Anfang hatten wir
13 oder 14 Euro und jetzt
15. Also wir haben
zwei Euro ausgegeben heute im Stream.
Also extremely, highly
expensive Stream.
Und
jetzt
gehe ich off.
See you. Bis dann.
Macht's gut.
