da bin ich leute heute ist es soweit kubornitis kubornitis stream
oder oder auch kubanitis oder kubanitis oder kubanitis oder was auch immer
wir sind cool wir sprechen ja auch ubuntu nicht ubuntu aus sondern jubantu also sagen wir natürlich
auch eindeutig auch kubanitis kubanitis das wird übrigens heute als es übrigens nicht
sponsort bei hetzen oder so wir machen heute die sachen noch lokal und es wird erstmal auch nur
horizontal skaliert heute ich weiß ich weiß das ist eigentlich nicht das performer mindset wie
heißt das doch performer mindset oder wie heißt das shit high performer halt das nicht das high
performer mindset es wird heute auch nicht der einzige stream sein dazu weil da gibt es einiges
das ist eine fass ohne boden und es ist jetzt auch nicht so als bin ich zum aktuellen zeitpunkt
der krasseste kubanitis experte den es auf diesem planeten gibt ich habe damit schon was gemacht ich
habe die letzten tage auch so ein bisschen noch um probiert und ich habe schon mal in die deployment
jammel gemacht und dann war es zum laufen gebracht und also ganz komplett ahnungslos bin ich nicht
aber ich bin jetzt nicht der der der krasseste profi ever jetzt jetzt aber was machen wir
ein bisschen ahnung haben verstehe nicht was ihr meint mit skalieren das wirst du dann im laufe des
streams sehen was mit skalieren gemeint ist da wird hyperscaled wird da da kann man dann richtig
schöne tolle cloud buzzwords draus machen die hyperscalenden cloud native container infrastructure
es keine ahnung ja fast jeden tag wenn ich nicht stream abends
mit den mit den gleichen leuten wieder näher ich bin auch am spiel ich habe gesehen du bist
nicht über level 11 rausgekommen nicht so ging nicht so weit gatschi roll
während der stream anläuft leute ich mache mal meine vm an wobei wir heute beim cool aussprechen
ich mache meine vm an und ich mache mal ein update bevor wir jetzt hier großen großen kubanete
stellt man ja also leute wir gucken uns das wir gucken uns das alles an also das wird jetzt nicht
also wenn ihr jetzt erwartet wir machen jetzt hier kubanetes tutorial wie sagt man so schön
from zero to hero wenn man cool sein will dann nennt man das sowas das machen wir nicht also ich
erkläre euch ein bisschen was und ich zeige euch auch ein bisschen was und wir probieren ein paar
sachen aus aber die sinne dieser streams ist ja auch einmal dass ich euch was zeigen kann und
auch dass ich selbst besser kann das ist ja immer so 11 ich meine ich mache meistens nicht sachen wo
ich komplett planlos bin aber wenn man die dann noch mal erklären muss dann ist natürlich immer
ein bisschen schwieriger versteht selbst besser war ein paar träg horizontal skalieren ist doch
mehrere maschinen hochfahren können zum skalieren oder vertikal ist mehrere leitungen freigeben
ich bin mir ehrlich gesagt gar nicht so sicher ich glaube horizontal skalieren ist mehrere
mehrere potts starten und vertikal skalieren ist mehrere notes hinzufügen
keine ahnung bin ich bin ich so im hyper hyper scale high performance mindset
ach du hast recht genau horizontal jaja ne ne stimmt doch mehr leistung mehr leistung ist ja
im prinzip mehrere notes hinzufügen wobei du auch du musst gleichzeitig du musst gleichzeitig
ein bisschen vertikal skalieren dass du besser horizontal skalieren kannst oder glaub da müssen
wir mal eben business coach fragen wir uns das erklärt wie das wie das richtig funktioniert
wir skalieren prinzipiell nur diagonal korrekt das ist richtig das haben wir schon vor eine
weile festgestellt dass für uns diagonal skalieren das beste ist dann musst du dich nicht mit mehr
mit so komischen noobkack abgeben wie ob das jetzt vertikal oder horizontal oder y-achse x-achse z-achse
wir wir machen naja wie es skalieren diagonal dreidimensional also in alle drei dimensionen
wird skaliert du brauchst mindestens fünf kuppernets cluster daheim dass du dass du
dem kerl auf youtube konkurrenz machen kannst wir skalieren sogar runter das ist richtig wir
skalieren tatsächlich heute auch runter wir skalieren mal container von 8 auf 4 zurück
und so was ich war mal kurz bevor es richtig los geht aber kurz den ganzen schitt hier zu
das haben wir hier noch swelt zeug alles weg ich war mal kurz ein update und dann starte ich mal
die vm neu dass es auch was wird hier dass wir top aktuelles kubernetes machen können
autokonale skalierung was kommt man was kommt dann als als nächstes parallelogramm skalierung
relativistische skalierung hätte ich noch zu bieten dann skalieren wir nicht nur in
alle raumdimensionen sondern auch zeitlich was was haltet denn davon dass man kann das
beck was wird moment was so warum kompiliert er gerade in den schitt was macht er da 7 zipp
ich habe was viel ich zeige euch mal kurz was bevor wir kubernetes anfangen ich habe
was was ein cooles projekt auf github gefunden wenn man keinen bock auf 7 7 zipp gedürnt
hat unter linux nenn sich pzip das ist das macht alle möglichen formate unter anderem auch 7 zipp
und und es hat ein gui dabei einfach 8 zipp nehmen ja das ist schon ganz schön 6 hat ich
habe ich ok leute ich ich muss mal kurz was zum ich muss mal kurz 7 zipp entfernen brauche ich
erinnert so und dann zeige ich euch mal was wir heute vor haben beziehungsweise was ansteht das
ist vielleicht nicht das alte 7 zipp näher so alt ist es nicht ist es last week geabdeut
updated oder doch was ist die letzte version 9.1 ist doch gut alles sogar für die ganzen cute
cutie chats chatter also ich wollte noch ein update machen gut lassen wir den erst mal
updaten also um was geht es heute ich versuche jetzt mal so ganz grob mal auszuholen ja erinnert
sich noch eine an zipp drives die hat mit zipp an sicher nichts zu tun das war eher so halt das
zipp so weiß gar nicht warum die so heißen vom geräusche oder so zipp drive ja iomega zipp
drive da wurde nichts gezippt immer eine 100 mb diskette war damals schon richtig krasser shit
wenn die normalen disketten hatten wie viel 1,44 mb oder 1,2 ich glaube es gab drei disketten 800k
1,2 und 1,44 oder so was gär war es gab war das nicht so ne 3,4 gab es nicht das ja gut vielleicht
später mal aber ich kenne also die 1,44 waren glaube ich die verbreiteten wie ist ja dass ich
mich da dass ich mir damals wieder krasse heckermann vorgekommen bin ich habe alte disketten vom
amiga genommen das waren ja auch so floppy floppy disk floppy disk und dann habe ich die in mein pc
laufwerk reingesteckt und dort unter windows rechts drauf geklickt und gesagt formatieren und dann
hatte ich auf einmal ganz viele leere disketten weil ich die amiga dinger recycelt habe und da
habe ich boah da habe ich mich richtig geil gesagt mann bin ich bin ich geiler hier heckermann ich
habe quasi disketten aus dem nichts erschaffen dabei waren das ja ganz normale floppy disk
halt für den amiga das habe ich nicht habe ich damals nicht gecheckt also ja amiga gescaled
genau so update ist durch update ist durch ich glaube es war ein kernel update dabei
deswegen reboote ich mal 5x dankeschön für den sub ich habe oben übrigens glaube ich noch
ein übersehen stripes dann wieder subscrib poggers danke für die subs leute so dann starten wir mal
das verdammte spiel und jetzt kann ich sag guck mal ne das war ja kein bock auf krasse giga chat
aussprache jetzt kann man damit anfangen das ketten war das stimmt das ketten war schon cool
dass sie der klick zu dieses klick dieses hatte schon was nutzt du zsh ja mache ich und wenn ja
welches theme ist das das ist gar kein theme das ist also du meinst jetzt mein termin oder
wirklich hier den prompt von der shell ich vermute mal weil du zell das was meinst du den prompt
also der prompt ist starship allerdings ein custom meister ein custom meister ein
custom meister starship prompt wenn du den prompt sehen willst gehst du hierhin auf
wuppe loss dot files config starship und da siehst du das ich habe den base prompt genommen von
starship du musst du noch sagen ob du wirklich shell oder terminale meinst weil terminale ist
anders so und ich habe dieses preset genommen von starship pastel powerline was wiederum selbst
auf m365 princess basiert das habe ich genommen und habe ein paar customized sachen angepasst ja
zum beispiel habe ich die schrift gemacht wie mein hintergrund ich habe hinzugefügt dass wenn
man in ein dotnet projekt geht die versionen da stehen und so was ich habe es auch zweizeilig
gemacht weil ich zweizeilige prompts persönlich viel besser finde als einseilige prompts ja aber
es ist etwas ist das hier aber angepasst und du kannst findest das hier ach du kacke das ist wild
ja das ist das ist aber wahrscheinlich noch neuer oder fast so alt wie unsere cobalt
geschichten die bei uns laufen wo ich mich auch immer frage wo finden die immer noch
leute die den kram können wir zeit wird zeit für linux upgrade und dann das ganze einfach in
free doors laufen lassen oder oder oder noch besser wine im docker container im container
weiß gar ob das gescheit funktioniert ja warum eigentlich nicht ja aber das will man ja
wahrscheinlich nicht weil man so altes zeug hat dass es stabil läuft ob das mit wine dann
also was machen wir heute
wo fange ich denn jetzt am besten an leute wo fangen wir am besten an
serverschrank 24 wieso klingt auch ganz normal anbieter hört sich halt bisschen
oldschool an aber warum warum ich klingt auch klingt auch ganz normal
berat uns doch erstmal ob kubernetes native stellt oder mini cube zum ausprobieren
reicht das lokal voll und ganz ach ja ich weiß wo ich anfangen ich weiß wo ich anfangen und zwar
dass wir es heute nicht der einzige kubernetes stream und zwar wir machen da mehrere ich weiß
nicht inwieweit da bin ich wieder unschuldig weiß ich inwieweit das alles so aufeinander
aufbauen wird wahrscheinlich kein raspberry pi cluster wahrscheinlich schon in gewisser
weise wir machen aber nicht immer so exakt die gleichen beispiel und zwar also wir brauchen
mehrere wir brauchen mehrere streams jena es hängt auch ein bisschen davon ab wie weit wir
aber es wird auf jeden fall auch aus praktischen gründen mehrere streams geben das erste ist
wir setzen uns damit lokal mal ein bisschen auseinander wir müssen nicht gleich in die
cloud in der cloud irgendwas bauen das nächste ist wir gucken uns google cloud kubernetes an
warum gucken uns google cloud kubernetes an weil dort wo ich am 1. april anfange zu arbeiten die
alle google cloud verwenden ich weiß nicht warum das sind die einzigen die ich kenne die google
cloud benutzen aktuell wo ich bin ist es ist es quasi fast nur ausschließlich azure ich
habe schon ein bisschen was mit aws ich fasse nicht schon ein bisschen was privat gemacht mit
google und mit aws würde ich sagen aber abstand am wenigsten aber ich kenne außerdem niemand der
im professionellen umfeld google cloud verwendet gibt es allerdings genug nur weil ich keine
kenne heißt das nix weil ganz einfach ich kenne nicht so viele läden von innen die
paar handvoll da die ich gesehen habe die haben keine google cloud verwendet gut es heißt ja
nichts erfolgreich ist es trotzdem und ich habe mir ein paar videos angeguckt und angeblich ist
dass dieses autopilot kubernetes management feature von der google cloud wohl über diesen
anwendungszweck am besten dann betreibst du nämlich gar kein kubernetes cluster mehr selbst in der
google cloud sondern kannst direkt pots deployen und die scaling und managen das für dich aber
natürlich machen wir damit nicht fangen wir damit nicht gleich an weil das ist ja langweilig
muss erst mal ein bisschen so die grundlagen uns angucken dass man weiß wie das funktioniert
weil nur was man macht von hand zumindest ich so ein bisschen selbst angeguckt hat blickt man
dann auch durch was man besser sein lassen sollte
ja deswegen gibt es mehrere streams wir machen wir wir gucken uns jetzt erst mal wir gucken uns jetzt
erst mal das ganze lokal an da machen wir mal so ein setup aus irgendwie so eine 5 5 pots als
application server mit einem load balancer und einem ssl zertifikat oder so mit ingress controller
davor wir holen uns auch echte let's encrypt zertifikate über let's encrypt also echte
echte ssl zertifikate über let's encrypt mit zert manager und was machen wir sonst noch wir
machen den lokalen registry für container images und konfigurieren halt das deployment und den
service gucken uns das alles mal ein bisschen an ist der moogame dankeschön für den snap
was hältst du von IT zertifikat kommt ein bisschen auf die zertifikate an aber allgemein gesagt nicht
ganz so viel ja ich würde sagen wir fangen mal relativ easy an ah ja und übrigens ich habe
schon ein bisschen was vorbereitet wo ich abgucken kann also das ist jetzt nicht fix und fertig aber
ich habe mir so ein paar kleine snippets raus kopiert falls ich jetzt im stream nicht direkt
drauf komme weil alles auf den kopf weiß ich da auch nicht was hältst du von lpix also das
was ich bisher gesehen habe sah sehr nach man pages aus wenn ich lerne aus aber kann auch kann
mich auch täuschen wir verwenden kein windows server doch klar ich mache immer windows server
windows server ist eindeutig die überlegene technologie deswegen läuft ja auch 90 prozent
des internets auf linux guck hier ja was sonst verstehe ich auch die frage gar nicht was denn
sonst gibt es noch was anderes windows server und powershell und es auf final auf was aber
finals ist gerade irgendwas ich habe überhaupt nichts mitgekriegt cs go ist gerade glaube ich
also wenn die windows server skalieren bist du nicht arm wenn die oracle datenbacken skalieren
dann bist du arm wobei ne ne das stimmt nicht wir können es anders machen wenn die windows
server skalieren bist du arm wenn die oracle datenbanken skalieren da kannst du gleich insolvenz
weil ich weiß was ich machen muss um das problem zu fixen jetzt ist nur die frage möchtest du auch
wissen wie man das problem fixt was muss man denn machen also die grundvoraussetzung ist schon mal
das ist schon mal essentiell und dann zeige ich dir auch dass du gtkmm oder wie das heißt installieren
musst das da musst du installieren und dann funktioniert probier mal aus das musst du
installieren und dann startet die kiste am besten mal neu oder oder den system d service neu starten
den hast ja bestimmt gestartet und so was aber das ding musste installieren diese library ist
pflicht sonst funktioniert copy und paste nicht warum das keine dependency ist und warum das
nirgendwo steht ich habe keine ahnung aber du brauchst diese library sonst geht copy und paste nicht
gtk mm3 warum weiß nur vmw so also wir uns jetzt mal hier das kubernetes kubernetes vielleicht
was sagen die denn was sagen die denn selbst ja das das trifft es eigentlich ganz gut ich
wollte sagen kubernetes ist ein tool zur container orchestrierung aber das sagen sie ja selbst also
für alle was genau wird heute mit kubernetes gemacht also erst mal erkläre ich kurz was
kubernetes ist kubernetes ist quasi so was wie docker nur geclustert und mit wie wir klären
das am besten es ist es ist so was wie docker nur verteilt über mehrere server ich glaube
das kann man eigentlich am besten glaube das umschreibt eigentlich am ehesten ne du kannst
auch einen server nehmen du kannst auch einen server nehmen aber für einen server macht es
halt wenig sinn hochverfügbares docker ja ich glaube ich glaube dass das trifft eigentlich
ganz gut sie sagen ja selbst sie sind ein ein orchestrierungstool für container infrastruktur
also du kannst damit deine container in deine container verwalten du kannst damit zum beispiel
einstellen dass du für einen ich nenne es mal service auch wenn die kubernetes service was
anderes ist das wird eine pains champ reihe nur so so schlimm so schlimm ist es auch das einzige
problem an kubernetes ist so zumindest wie ich das sehe also was vom lernen her dass es ein fass
ohne boden ist es gibt 30 milliarden tools fünf tools für die gleichen sachen jede woche spawn
irgendein neues tool die einfachsten sachen werden teilweise super krass verkompliziert
aber insgesamt ist es an sich an sich ist das doch eine coole sache ja also was du das meinst ja
also was du damit zum beispiel machen kannst mal ganz simpler use case ja du hast drei server
und möchtest also du willst ein webservice anbieten willst webservice anbieten und du willst dass das
ganze möglichst verfügbar ist und du willst dass das ding im laufenden betrieb geupdatet werden
kann und du willst dass das auch je nachdem wie viel user gerade drauf sind ordentlich performed
oder eben auch skaliert wie man so schön nennt dann ist kubernetes genau das richtige weil du
kannst kubernetes nehmen stellst dir verschiedene notes hin heißt das bei kubernetes also verschiedene
server notes sind bei kubernetes in der regel die unterschiedlichen server in einem cluster also
cluster member sind quasi notes bei kubernetes das muss ich zwangsläufig eine hardware kiste
sein das können auch vor ems sein der neueste schrei ist sowas wie kubernetes auf firecracker
vor ems wenn man das jetzt mal hört und jemand weiß nicht was es ist er denkt jetzt erst mal was
zum teufel will er von uns das machen wir heute nicht ich weiß nicht ob wir es überhaupt im
stream machen ist auch was ganz ganz ab abgedrehtes das sind minimal vms firecracker das ist glaube
ich von glaube das ist von amazon ich bin mir nicht ganz sicher ich glaube von amazon so
eine minimal vm kubernetes selbst ist für container workload und der kubernetes cluster besteht
aus unterschiedlichen notes in der regel ist es halt ein server jeder note das kann natürlich
auch ein server sein worauf dann mehrere vm sind kann es kann es quasi auch sein kubernetes cluster
in mehreren vmst auf einem eskserver laufen betreiben was auch immer oder theoretisch kannst
das ding auch über mehrere cloud anbieter spannen wie dem auch sei da bist du sind ja
deine kreativität keine grenzen gesetzt wie du das ganze aufbauen willst zumindest hast du dann
den vorteil dass du so schöne sachen machen kannst wie es gibt ein das machen wir übrigens heute wenn
wir so weit kommen du hast eine neue anwendungsversion und möchtest jetzt was deine anwendung läuft zur
zeit auf version 1 und du willst jetzt auf version 2 und dann kannst du den config file editieren du
kannst darüber kommandos teile machen aber in der regel macht man über config jammels dann
ich will jetzt die version 2 von diesem moment ist an der tür
hat mich abgelenkt also wenn du keine ahnung davon hast und wenn euer online shop so funktioniert
dass nur ein service ist da brauchst wahrscheinlich kein kubernetes cluster wie gesagt man muss es
man muss es auch nicht übertreiben manchmal tut es ohne probleme 123 vms und reverse proxy
für ssl davor also es muss nicht sein da ist schon da ist schon ihr werdet wahrscheinlich
so im lauf des streams ein bisschen an an klingen sehen da ist schon auch wenn es erstmal easy
aussieht eine gehörige portion komplexität drinne gar nicht so sehr in den reinen basis funktionen
von kubernetes sondern das gesamte ökosystem drum herum was es gibt ja wo bin ich jetzt stehengeblieben
genau also du willst du hast ein service laufen du willst den service jetzt abqueren wessen von
version 1 auf version 2 normalerweise wird es dann auf dich und vm einloggen neu pullen vm den service
wieder starten was auch immer mit komponiert das geht es relativ einfach du gehst in den jammel
feil machen wir heute auch alles jammel feil trägt die neue container image version ein das image
bauste vorher irgendwo entweder lokal mit docker oder über jenkins oder github action so wie
irgendwelche continues pipeline geschiss bauste dann image und pusht das in registry rein und
dann trägst du dann im jammel feil ein ich will jetzt auf version 2 dann applies du diese konfig
machen wir jetzt gleich alles dann applies diese konfig auf deinen kubernetes cluster und es
skaliert dann automatisch also der reihe nach deine einzelnen container hoch also nicht skaliert
der upgrade an der reihe nach deine einzelnen container ja richtig stripes genau so dass der
service nicht ausfällt was ist der unterschied zwischen k8s und k3s ich glaube das eine ist
irgendwie super leicht gewichtiges komponiert gibt es ein paar sachen es gibt ein paar sachen wenn
man das ist zum beispiel was was du eher auf dem respiratory pie laufen lassen kann kannst
das ist aber glaube ich soweit ich weiß 100 prozent api kompatibel zum großen kubernetes
es gibt verschiedenste sachen für minimal kubernetes es gibt es gibt das originale kubernetes
oftmals mit k8s abgekürzt gibt es auch null ks es gibt kind es gibt mini cube es gibt alle
möglichen dinger total total viel sachen mini schiff feier cue war es auch immer alles wir
nehmen heute mini cube wir nehmen heute mini cube weil es am einfachsten ist für mich mit
mini cube lokal ein bisschen rum zu basteln so mini cube ist nahezu 100 prozent api kompatibel mit
es kann halt einige sachen nicht ich kann euch aber nicht aus dem kopf sagen was es aber zum
größten teil api kompatibel mit kubernetes und du kannst auch die ganz normalen kubernetes tools
nehmen für für mini cube um damit lokal was auszuprobieren ist halt hauptsächlich gedacht
für auf einer kiste lernen und üben mini cube wir machen jetzt mal ein eigenes wir machen jetzt
mal ein eigenes verzeichnis dafür repose mk dir nennen wir es einfach mal sogar du brauchst
noch cube ctl ne brauche ich nicht weil guck mal da ist es das ist mittlerweile bei mini cube
dabei also was heißt dabei der lädt es im hintergrund runter aber trotzdem ich installier
es trotzdem weil das braucht man normalerweise hast du schon recht
plan der mission lernen ja also wie gesagt meine streams sind ja immer so so ein ding also ich
mache meistens sachen wo ich selbst ein bisschen schon von ahnung habe aber nicht so krass den
durchblick und dadurch dass ich das euch zeige und ein bisschen was erklären muss lernt man selbst
besser das ist immer ganz gute kombination so sieht es aus jetzt können wir anfangen es ist
relativ easy zu starten mit mini cube und zwar ihr braucht keine vm ihr braucht kein kubernetes
installation und nix ihr sagt einfach mini cube start und jetzt macht ihr eine sache falls ihr
das auch ausprobieren wollt macht ihr eine sache man muss mal kurz nachgucken insecure oder mir ist
das insecure registry machte jetzt mini cube start ins insecure registry werdet gleich sehen warum
jetzt leider kobe ne das geht uns runter und direkt best practice ist lokal es ist lokal
übungs practice chat ihr werdet gedisst gerade im chat also quasi aber du bist auch teil des
chats kommt eigentlich ein video zu dem mobil funk anbieter suchen was ich euch da erzählen soll
so ach ja es gibt verschiedene nummer so der vollständigkeit vollständigkeit halber erwähnt
es gibt verschiedene möglichkeiten mini cube zu betreiben die standard variante ist über
irgendeinen virtualisierungs provider also meistens kvm also wenn ihr mini cube startet dann legt es
normalerweise unter der haupe eine neue vm an wenn man keine vm anlegen möchte kann man das ganze
auch selbst als container in docker laufen lassen ist ja kein ding ich mein kubernetes ist ja
letztendlich tool zur container verwaltung warum sollte man das nicht auch selbst in
dem container laufen lassen können also ihr seht ja hier ich habe keine vm installiert also ich
habe hier keine virtualisierungsmöglichkeiten in der vm drin das heißt er lässt jetzt das back
end einfach in einem eigenen docker container laufen also es ist jetzt quasi kubernetes in
docker womit man eine weitere container verwalten gab es ist egal letztendlich muss man sich damit
nicht beschäftigen das ist ja zum üben und die api und wie man das anspricht und so ist überhaupt
kein unterschied also diese lokale lokale so entwicklungsumgebung mit mini cube können
die genauso benutzen wie also die du brauchst keine extra sündung so ist quasi genau das
gleiche wie fürs große kuppernet ist nur dass es lokal bei einem auf dem rechner läuft sagen
mal logien halbist du irgendwie besoffen oder so ich kann dir nicht folgen was du für komisches
teuch im chat schreibst die ganze zeit was was soll was soll uns das sagen lokal geschützt
von meter alles klar written in rust container runtime nie kenne ich nicht ich kann nicht jede
rust software kennen ich schreibe über mastadon schreibst du das einfach nur so oder schreibst du
mit jemand ich glaube ich glaube du machst aktuell die taktik was ich auch manchmal mache alles was
einem in den kopf fällt in irgendein text einkommen in irgendein text eingabe fällt tippen und enter
drücken aber mach nur ich beschwer mich nicht alles interactions auf twitch wobei das war youtube
wo das so wichtig ist ach ja und wir brauchen tatsächlich anscheinend doch nachher noch potman
und so gucken wir uns an also wir haben mini cube gestartet wir können jetzt mal sowas machen wie
cube ctl get ach nee ha sekunde leute lasst lasst euch nicht jebaden von irgendwelchen youtube
tutorials oder sowas ich zeige euch jetzt mal wie das die ganzen youtube tutorial dudes machen und
dann zeige ich euch wie man es richtig macht ok also die ganzen youtube nicht alle es gibt
ein gut es gibt gute tutorials das beste deutschsprachige tutorial auf youtube was ich
kenne dazu kubernetes ist also für leute die ein bisschen ahnung von linux und sich nicht
vor kommando zeilen scheuen und relativ relativ ja schon ein bisschen bisschen background was
container angeht haben das ist das beste also wenn wenn sich einmal wirklich in zwei stunden
in zwei stunden gut strukturiert das kubernetes tutorial angucken will finde ich das persönlich
auf deutsch finde ich das persönlich am besten ich könnte natürlich auch einfach dabei bleiben
weil ich wir werden ja wahrscheinlich nicht alles machen was er im video macht aber in großteil und
ihr könnt ja live auch noch was dazu beitragen und wir machen auch ein paar sachen die er so
glaube ich nicht im video zeigt ich glaube es ist selbstwertig für karte über letzten
krippen macht er im video gar nicht aber wenn mal einer sich in ruhe und tutorial angucken will
ich finde das ist das beste so ja genau also ich zeige euch jetzt mal wie das die ganzen
tutorial duz auf youtube und auch teilweise auf jude me und so machen wenn die kubanets
kommandos oder generell wenn die kommando zeilen tools verwenden dann machen die so was hier guck
jupe ctl get pots oder da machen sie so get events und solche dinger du siehst die typen
in tutorial videos zum kurz ich drücke schon ins den ganzen krempel immer fünf mal tippen so
nicht so nicht leute das ist das ist mist auch wenn man das in allen möglichen tutorials sieht das
erste was man braucht ist und jeder linux admin wird wissen das erste was man braucht ist
shell completion leute jetzt nicht unbedingt für minicube für minicube ist das relativ egal dann
müssen wir nicht so viel machen aber für kubectl brauchen wir best completion mir hört das ist
aktuell noch nicht der fall das geht noch nicht und wir wollen nicht nur einfach tab completion
haben sondern wir wollen auch quasi ja kontext sensitive tab completion haben also wenn ich zum
beispiel sage hier irgendwie describe potts oder ne pot genau describe nee nee quatsch nee das
klappe kann ich so die ressource hinten dran schreiben blabla blub so und dann will ich dass
das auto completed so und dazu gibt es folgendes kubectl jetzt muss ich mal überlegen wie das war
completion zsh genau so kubectl bringt nämlich eine eigene completion definition für bash zsh
und was noch
best und zsh wahrscheinlich mit richtig nice so und das kann man dann in seine
basher z eintragen die dann folgendermaßen aus muss bloß mal kurz seine zhsh wie auch immer
shell konfig ich muss mal kurz gucken wo habe ich denn meine ach da da ist es doch muss doch
unten irgendwie sein source und wie machen das jetzt so geht das einfach so bin ich gerade
ein bisschen ich glaube ich glaube wir müssen es redirecten ich bin mir nicht ganz sicher ob
das so funktioniert nein aber ich habe ich habe dings brauche ich nicht genau so ist gut
ja genau und jetzt habe ich kubectl und guck mal tab tab jetzt habe ich autocomplete ja und
ihr seht autocomplete hier endpoints autocomplete und der autocomplete jetzt quasi auch kontext
sensitive infos so an der stelle gibt es halt einen endpoint der kubernetes heißt und den kann
ich da eintragen jetzt kann ich zum beispiel describe irgendwie sowas wie hier da gibt es
halt pots gibt es halt noch kein man kann auch sagen all namespaces dann zeigt er dann alle pots
an die es gibt mal mal get pots dann erzähle ich mal ein bisschen so was zur zur benahmung wie
kubernetes denkt dass man dinger nennen soll also das hier sind jetzt die laufenden container die
wir zur zeit haben in unserem kubernetes cluster wobei das nicht stimmt wobei das nicht ganz
richtig ist ich muss das ich muss das anders erklären also kubernetes ist zwar ein orchestrierung
stuhl für container aber kubernetes arbeitet gar nicht auf container basis das klingt jetzt
erst mal verwirrend aber wenn ich euch das ein bisschen genauer erklären wird es hoffentlich
klarer und zwar das was somit kubernetes verwaltet sind zwar unter der haube container aber container
werden in kubernetes zusammengefasst zu pots ein pot ist quasi so eine logische einheit wieviel
du meinst wie viele notes mein cluster hat einen lokale vm gerade so also was wollte ich jetzt sagen
genau kubernetes das kleinste mit dem kubernetes hantiert sind pots pots ist so die kleinste logische
einheit die man die man mit kubernetes verwalten kann in der regel könnte man sagen dass ein pot
so was wie ein container ist wobei das nicht stimmt ein pot ist quasi also ist quasi so der
container für die container oder so dass so ist so die so die der rahmen oder so die kiste um die
container klingt jetzt bescheuert kann man kann man echt schlecht beschreiben also ich erkläre
ich mal zum beispiel warum man das braucht ich erkläre ich mal warum man das braucht und zwar
mal angenommen du hast jetzt eine anwendung in die net anwendung die verpackst du in container
image und die lässt du dann als pot laufen dann ist der pot genau ein container drin aber du
könntest jetzt ja in diesem pot zum beispiel noch einen container für metriken haben oder noch
ein container für secrets oder noch ein container für reverse proxy oder so was also könntest
ja du könntest ja quasi damit die anwendung von als einheit funktioniert also ein docker
compose file ist ein pot ja das kommt ungefähr hin wobei man sagen muss in so einem docker
compose file definierst du ja auch mehrere logische services die du miteinander verbindest
du kannst jetzt mit docker compose file auch eine datenbank reinschreiben ein application server
und die dann miteinander verbinden das wird schon in einzelne pots machen das du würdest
quasi nur sachen die logisch zusammengehören in ein pot packen ja also zum beispiel ein container
für connection zu deinem secret store oder so was in der richtung also werd mal angenommen
deine deine anwendung braucht api keys und sonstige geschichten die hast du nicht in
einem kubernetes cluster sondern irgendwo extern liegen und du willst es auch nicht in kubernetes
cluster integrieren dann kannst du dir noch einen zweiten container rein passen rein packen der
nur dafür da ist diese secrets zeig mal wie ist denn dieses bild
ja
ja
genau also das ganze nennt sich übrigens seit k wenn man noch mehrere container rein
packt in so einen pot genau so was hier das ist das ist ein schönes beispiel das ist das
ist ein schönes schönes beispiel ja aber aber chat gpt erklärt er nicht warum das ist ein
schönes beispiel ja du hast zum beispiel deine anwendung die schreibt logs und jetzt willst
du diese log files allerdings zu einem zentralen logserver schicken und die anwendung selbst kann
kein syslog und hat auch keinen bock sich irgendwie mit logs am einsammeln dingern zu
beschäftigen dann würdest du einen pot erstellen der enthält die anwendung und noch einen zweiten
container der dafür da ist die logs einzusammeln und an irgendein zentrales log management system
zu schicken das ist ein gutes beispiel ja du könntest zum beispiel noch einen dritten container
dabei machen der metriken bereitstellt für prometheus monitoring oder so was hast du quasi eine logische
einheit also das hier wäre dann quasi dein application server pot allerdings enthält er
eben alle container in diesem pot die die anwendung braucht um ebenso als logische einheit
gestartet werden zu können und das zu machen was sie machen soll eine datenbank wäre wiederum ein
zweiter pot das ist eigentlich gar nicht so verkehrt was was ein bisschen doof ist an kuba
die haben halt für alles irgendwelche gewöhnungsbedürftige bezeichnung ja container
sind pots was schon irgendwie klar ist weil ein pot mehrere container enthalten kann du hast
deployments da versteht jeder eigentlich was anderes darunter als irgendwelche komischen
yaml files die pots definieren aber gut da muss man sich ein bisschen dran gewöhnen
was phippe goes to the zoo cloud native computing foundation hat es kuba neta story moment
jetzt lernen wir was ok pots hier hier werden pots erklärt
ich verstehe den zusammenhang kann ich so genau
ich verstehe den zusammenhang zwischen diesem bild und und potz nicht
wie dem auch sei wir machen jetzt wir machen jetzt mal weiter man muss sich zumindest ein
bisschen dran gewöhnen dass sie alles irgendwie irgendwie anders nennen
und zwar ist es zum beispiel bei kuba neta ist auch so die nennen dort wo der traffic reingeht also
quasi das was jeder normale mensch irgendwie reverse proxy nennt das nennen die ingress zum
beispiel und das gegenteil von ingress also da wo der traffic quasi reingeht ist nicht etwa
outgress sondern egress weil ist halt so
und da gibt wie gesagt gibt gibt gibt noch mehr sachen wo ganz komisch benannt sind wo man sich
einfach dran gewöhnen muss was genau ist minikub minikub ist ein tool wo du lokal
bei dir kuba netas laufen lassen kannst zum üben also wir haben das ganze noch nicht gestartet doch
also nachdem minikub installiert ist es ganz einfach über package manager oder als single
binary runterladen es ist glaube ich auch in go programmiert als single binary runterladen
starten dann startet ihr minikub am besten dass ihr noch hinten dran wenn ihr lokale
container registry haben wollt und gut ist dann habt ihr minikub gestartet euer kuba netas läuft
irgendwann mal läuft es dann
und dann könnt ihr auch schon kommandos an euren kuba netas schicken und das ganze machen mit
kubectl kubectl kubectl get pods zum beispiel so und man sieht hier schon folgendes das ist das wo
ich gerade am wo ich gerade am erzählen gewesen bin ein port ist die kleinste logische einheit die
kuba netas verwaltet kuba netas selbst oder in dem fall minikub selbst wenn du startest kommt
schon mit ein paar vorinstallierten pods um die musst du dich nicht kümmern das ist es ja auch
hier das ist im name space kube system und dort sind interne sind interne pods die man die das
braucht dass es funktioniert was zum beispiel hier sowas wie core dns das ist das ist wichtig
dafür dass die pods sich untereinander beziehungsweise auch die services aufgelöst
werden können und im cluster selbst die dienste per namen angesprochen werden können und so was
da muss man sich jetzt nicht so viel gedanken drüber machen aber damit kommt das halt also
sprich man sieht hier laufen schon ein paar container was man hier auch schon sieht das
brauchen wir später noch hier sieht man dass manche pods ready sind es ist so in kuba netas
dass ein also in docker ist es so du startest das ding so und entweder es krascht oder es läuft
aber so wirklich großartig wissen wann das jetzt ready ist und wann nicht tust du nicht
ja du kannst den docker zwar einstellen dass er restarten soll wenn es krascht aber
wann die webanwendung da drin gestartet ist und ich weiß nicht so und nachdem es in kuba netas
ja unter anderem darum geht dass das ganze möglichst ausfallfrei läuft haben container
oder pods muss man sagen sind da sind da keine container
haben container verschiedene möglichkeiten zu überprüfen ob sie bereit sind da gibt es
nämlich sowas was der andreas gerade schreibt es gibt so was wie readiness und leifnis da kann
man dann wirklich health checks auf die container machen auf die pods machen und erst wenn die
wirklich ready sind funktionieren also in dem fall dass ein web response web request durchgeht
bei einer anwendung erst dann kommen die quasi in den ready state und der interne load balancer
in kuba netas würde die dann ansteuern genau kompost kann auch so was in der richtung ja ich
finde hier ist das jetzt das schöner gemacht so also mit was ich überlege gerade mit was wir
anfangen wir machen uns erst mal eine leere datei nennen wir das einfach mal hier touch
keine ahnung cute punkt jammel und machen wir wishell studio code auf ja wir
trasten cute wir trasten nicht cute punkt jammel nope so jetzt können wir als erstes
mal die kuba netas extension installieren ja ja reload mal die kuba netas extension ist
nicht so dolle also ist ehrlich gesagt das einzige was ich von der kuba netas extension
benutze ist das hier die janta jammel das jammel synthax autocomplete für kuba netas files so
das nächste ist ein config file für kuba netas also so ein jammelfile hier das nennt sich wenn
ich nicht ganz falsch liege manifest warum weil config datei zu dumm ist weil die das immer gerne
ein bisschen fancy nennen was kuba netas angeht also ein jammel konfig datei für kuba netas
nennt sich manifest und in so einem manifest kann man fast beliebig viele dinge reinschreiben die
man konfigurieren will für seinen kuba netas cluster man kann wie gesagt man kann mehr als
eins reinschreiben allerdings muss man sich immer überlegen man kann zwar jetzt auch gleich man
kann diese datei immer nur im gesamten einlesen lassen von kuba netas also wenn ich da jetzt 20
sachen drinne definiere und ich will dass kuba netas den kram übernimmt dann immer nur alles auf
eimer wenn alles in einer datei drin steht also es macht durchaus sinn sachen die zusammengehören
zusammen zu definieren also man könnte jetzt zum beispiel wobei da schreiten sich ja die geister
darüber was man wie aufsplitten sollte in config files und ob man wie man es nennt und ob man für
jeden dings in unterordner macht und dann ein eigenes jammelfile für service deployment was auch
immer wir schreiben das jetzt erst einmal sinnvoll zum zum üben schreiben wir das jetzt erstmal
alles in ein jammelfile also wir brauchen erstmal eine testanwendung würde ich sagen oder wir haben
hier keine testanwendung wir machen man wir machen mal eine minimal dotnet testanwendung wobei da
müssen wir einen container bauen und sowas hello world wir nehmen den hello world container da
seht ihr auch schon mal gleich dass wie das aussieht wenn ein container crashed wir machen
hello world hello world container der beendet sich nämlich da werdet ihr gleich sehen als kuba netas
auch sagt das ding ist das ding läuft nicht mehr also deployment so sieht ein kuba netas deployment
aus ich mache mal kurz die schriftgrößen ticken in ticken größer 18 aber wir waren sogar 20
kommen dass man gescheit was sieht wunderbar also so sieht in deployment in kuba netas aus das ist
das das ist das template was hier die studio add-on dabei hat also in deployment ist in kuba
netas eine config die kuba netas sagt welche container es starten soll ganz platt gesagt
leute ich glaube euch im chat dass ihr die super krassen kuba netas checker seid wahrscheinlich
mehr als ich aber es hat keinen sinn wenn wir jetzt alle 800.000 kuba netas tools die es gibt
immer wild durcheinander im chat schmeißen wie gesagt das ist ein unüberschaubare landscape an
tools und sachen man könnte es auch man könnte man könnte auch gar kein manifest schreiben und
man kann das manifest in python generieren das gibt es nämlich auch also wo wir gerade dabei
sind hier man kann auch so was verwenden guck wenn man keinen wenn man keinen bock auf jammel hat
kann man auch das komplett erstellen mit jeder x beliebigen programmiersprache was was haben
die denn ich glaube python java und noch was aber das ist einfach zu viel auf einmal
deswegen war jetzt erstmal jammel files und gucken uns das ganze an so also was gibt es
denn so in einem deployment zu sehen erstmal in unseren namen ausdenken cute app super toll
ich mache noch mal deployment cute app dann haben wir hier so sachen wie metadata das ist
erstmal nicht so wild metadata kann man alles möglich reinschreiben es gibt übrigens auch
noch annotations schwachsinn es gibt labels es gibt labels und es gibt annotations ich habe
noch keine ahnung beziehungsweise ich habe ich habe noch nicht gecheckt wozu man annotations
überhaupt braucht ehrlich gesagt außer dass manche ja nennen wir es mal third party tools
gerne annotations benutzen normalerweise kommt man eigentlich mit labels mehr oder weniger aus
kannst du den programm kurz kurz erklären es gibt noch gar kein programm code das ist das
template was visual studio macht wenn ich deployment wenn ich deployment hinzufüge meiner
kombiniertes config mehr gibt es da noch nicht also metadata das nennen wir mal cute app also
quasi wie diese ressource ressource nennt sich das übrigens was angelegt wird also diese ganze
datei nennt sich manifest und was hier angelegt wird ist glaube ich eine ressource und der typ
der ressource ist in dem fall deployment damit eure jammel files auch garantiert immer funktionieren
gibt es hier oben eine api version also das heißt mal angenommen die bringen version 2 irgendwann
raus was viel viel mehr sachen unterstützt und hier oben immer noch api version 1 angegeben habt
solange die version 1 weiter unterstützen funktioniert euer manifest auch weiter
api version gibt es übrigens für für nahezu alle verschiedenen ressource typen
so wir machen jetzt mal wir machen jetzt mal ein bisschen zackig da kannst du noch selektor
und labels und so anlegen das ist wird gleich das wird gleich relevanter wenn wir da noch
notbalancer und so was und so was da vorhängt so template metadata labels können wir auch so
lassen cute app manifest v2 und v3 kann das war das in chrome ja sondern hier schreiben wir
unser docker image rein beziehungsweise unser container image also immer einfach mal hello
world dass du diese hello docker container dann kann man noch limits eintragen wie viel ram und
cpu das verwenden darf ich kann euch ehrlich gesagt nicht genau sagen in welcher einheit die cpu ist
das ist irgendwas irgendwas super super spezielles das ist nicht einfach nur anteile von einem cpu
kern das sind irgendwelche megahertz sind nicht höchstwahrscheinlich nicht irgendwie irgendwie
irgendwie cpu zeit oder sowas was auch immer das habe ich nicht so genau gecheckt was das jetzt für
eine einheit ist zumindest ram ist relativ klar und man sollte auch limits angeben das ist sinnvoll
weil wenn ihr meine anwendung habt mit memory leak dann frisst ihr euch im zweifelsfall euren
kompletten note an ram voll wenn ihr da keine limits angegeben habt das heißt man sollte immer
man kann durchaus großzügige limits angeben muss ja gar nicht sein aber ganz ohne limits ist meistens
doof weil man kann das auch so einstellen beziehungsweise macht es automatisch man
angenommen ihr habt memory leak und die anwendung wird immer größer immer größer immer größer und
irgendwann nach einem gigabyte ram gerät es ans limit und kackt ab dann startet kuba netis
die neu und dann läuft das ding wieder eine woche oder so was auch immer bis es wieder abkackt
wegen memory leaks aber ganz ohne limits ist doof so container port tja geben wir einfach mal
container port 80 ein wir haben kein container port weil dieses image kein port aufmacht so
jetzt sagen wir mal kubectl deploy apply nicht deploy apply minus f cute wir machen hier unten
mal was auf watch kubectl get pots ihr seht es gibt noch keine pots aber jetzt gibt es einen
pot gibt es nämlich einen cute app pot und ihr seht das ding ist gleich wieder abgekackt
weil es ist kein pot also das ist der standard docker hello world pot den ich hier gestartet
habe der macht nichts anderes wie hello world ausgeben kuck docker run hello world der macht
nichts anderes wie hello world ausgeben sich wieder zu beenden deswegen da hier guck hier
deswegen funktioniert das natürlich nicht kuba neta sieht aha anwendung startet anwendung
krascht kuba netas denkt die anwendung krascht weil die läuft ja nicht mehr und jetzt versucht
er die neu zu starten und das krascht immer wieder doch doch der hat gepullt das geht das
geht nur relativ relativ zackig das ist ja auch nichts nix dabei sind das docker image
wofür muss man docker auch installiert sein nein du brauchst docker nicht installiert haben ich
habe einfach bei mir lokal docker installiert und das sind streng genommen es sind docker images ja
aber streng genommen sind docker images ja gar keine docker images mehr sondern sind oci images
oder wie dieser kram jetzt heißt open container images also das ist was heißt ein oci open
container image open container initiative image alles klar wäre auch zu einfach gewesen also das
ist eine spezifikation von container images die auch docker verwendet aber mittlerweile auch ganz
viele andere container tools aus dem container ökosystem also es muss kein docker image in
dem sinn sein aber bietet sich jetzt in dem fall an so jetzt haben wir ein hello world container
der niemals ready wird weil er immer krascht wie gesagt logisch weil naja macht ja macht ja auch
nix der beendet sich auch einfach wieder so bevor wir ein netzwerk container starten können wir ja
machen gut im eich traffic container traffic kurmei kommen wir mal starten wir bauen gleich noch eine
kleine eigene dotnet anwendung das dauert zwei minuten doch jetzt sehen wir mal hier das zum
beispiel traffic kurmei das ist was mit einem webserver wir applyen die datei wieder ihr erkennt
ein gewisses muster wenn ihr schon mal beispielsweise euch den terraform stream
angeguckt habt von mir das war ja oder generell wenn die terraform oder solche
infrastructure management tools verwendet habt ihr erkennt ein gewisses muster es gibt
eine config datei dessen state dann applied wird wobei man sagen muss terraform ist da etwas
als die reinen kopernet des manifestes weil da werden teilweise nicht die states getrackt also
wenn ich das hier jetzt umbenenne da kann es durchaus sein dass der pot weiter läuft
so mal gucken zumindest jetzt starten wir mal anderen container so und wir sehen schon der
alte container wurde gestartet und dann der neue container wurde gestartet der alte container wurde
gestoppt ich nenne mal container es ist eigentlich ein pot steht man auch hier oben aber irgendwie
kommt mir container einfacher von den lippen wurde gestartet und der scheint jetzt auch zu
funktionieren denn da ist running der ist ab des abend running und das passt ja eigentlich so weit
ganz gut jetzt muss man sich natürlich überlegen ok ich bin übrigens gar nicht sicher ob das
ding standardmäßig auf pot 80 läuft das ist eine gute frage doch kann man probieren mal aus
weiß ich gar nicht was macht das standardmäßig pot 80 ok alles klar dann ups na geil jetzt
ha eine sache wo ich nicht weiß wie das in meinem neuen terminal geht wie switche ich die
terminals jetzt lull einfach gar nicht aber irgendwie geht das ich war noch nie in der
dass ich musste das noch nie ausprobieren so jetzt ist natürlich die sache gut wir haben
wir haben jetzt ein pot laufen mit einem service drin auf pot 80 wir kommen da allerdings nicht
dran also selbstverständlich mal karl lokal host oder so da geht nichts ich kann mir mal zum
beispiel die mini cube ip angucken und dann kann ich sagen karl ip auf mini cube geht aber auch
nett also der läuft zwar und wir wissen auch dass da was auf pot das wird funktionieren ja
wir können wir können auch mini cube tunnel und so gedöns machen kann man alles machen aber man
sieht der container ist nicht so wirklich erreichbar damit ein container erreichbar ist
müssen wir erst einen service davor bauen einen service kann man sich so als art ja
nie kann man nicht wirklich laut balancer kann man nicht so als eingang kann man nicht so als
eingang zu diesem zu diesem zu diesen pots vorstellen so und jetzt kommt das was ich am
anfang gesagt habe man kann in so einen kubernetes manifest nahezu beliebig viele ressourcen
definieren und wir machen das jetzt zu übungszwecken so dass wir den service für dieses deployment also
im prinzip für die anwendung hier unten drunter definieren ich finde das ich finde das an der
stelle nicht verkehrt das gehört hier auch direkt zusammen das kann man kann man finde ich schon
machen an der stelle da streiten sich tatsächlich da jetzt die geister dran wie man das macht und
auch wie man das benennt ja ich kenne leute die machen ordner also gut ordner ist prinzipiell
für einzelne anwendung nicht verkehrt machen ordner machen da drunter dann immer so was wie
deployment extra service sonst wie manche machen auch eine datei mit dem namen von dem jeweiligen
jeweilige anwendung dieser drin laufen lassen wollen und schreiben dann deployments und service
in eine datei allerdings ingress in der anderen ist ein bisschen ist die musik zu laut wirklich
passt doch eigentlich oder bin ich zu leise
ich glaube die ist an sich einfach nur kratten bisschen sehr intensiv
ok komm wir machen dass alle happy sind so jetzt ist es minimal leiser aber immer noch gut
so also damit diese ports verfügbar sind oder wahrscheinlich müsste man eher sagen
dass die pots aus diesem deployment verfügbar sind also nicht nur innerhalb des clusters sondern
auch von außen muss man da ein service davon und service ist quasi so der eingang zu einem
deployment denkt das kann man ganz gut sagen es gibt verschiedene möglichkeiten wie man
services definieren kann also verschiedene typen von von services der in dem fall jetzt ganz
praktische service wäre so was wie den load balancer zum beispiel weil wir machen auch gleich
noch mehrere mehrere pots hier aktuell ist es ja nur ein potter läuft so also sagen wir jetzt hier
mal service jetzt muss ich mal kurz überlegen meta meta metadata kann das gleiche sein das ist
übrigens auch da streiten sich auch die geister dran ob das hier nicht irgendwie app heißen soll
und das irgendwie service da kann man sich da kann man sich auch darüber streiten wie man das machen
will so port port muss rein wo ich möchte dass dieser service erreichbar ist von außen in dem
fall sagen wir auch mal pot 80 und taget port ist auch 80 kann man im kubernetes manifest auch
ja klar warum nicht das ist ja ganz normal textart ganz normales jammel so das heißt wir legen
jetzt ein service an auf port 80 der auf diesen service ich nenne es mal balance balance an der
stelle oder nicht so und hier ist das entscheidende hier im selektor entscheidet man jetzt wohin dieser
service seine requests weiter leitet also nur weil das in der gleichen datei drinne steht
bedeutet es nicht automatisch dass das zusammen gehört also hier wo ich den selektor angebe
selektor ab cute ab und ihr seht hier das hier ist ich vermute mal das hier ist das relevante
zumindest hier drauf match der also der guckt danach was es für deployments gibt was es für
pots gibt mit diesem passenden tag dazu und dann balance der da drauf also sprich ist es egal in
welchen dateien die stehen also wir sagen wir wollen alle cute so und jetzt damit das
ganze hier testweise funktioniert müssen wir noch ein typ angeben man sieht es gibt mehrere typ es
gibt cluster ip ich glaube cluster ip ist der default wenn ich nicht ganz falsch liege
so mal gucken ob ich das aus dem kopf halbwegs hinkriege also external name weiß ich jetzt gar
nicht was heißt cluster ip hat heißt dieser service kriegt eine ip aus dem cluster zugewiesen
also irgendeine ip aus der aus der cluster range not port bedeutet auf dem jeweiligen cluster knoten
wo der container gerade läuft kriegt er kriegt er was zugewiesen und also random port zwischen
30.000 und 35.000 oder so und in dem fall will ich load balance haben und jetzt applyen wir das
ganze mal und dann hoffe ich dass ich nichts vergessen habe und der kram funktioniert
so jetzt können wir zum beispiel hier unten mal sagen kubectl get service und man sieht da
aha gucke mal da wir haben ein load balancer angelegt mit dieser cluster ip per external
ip pending kann ruhig pendeln soviel es will und im port mapping das heißt wenn ich jetzt
einen curl mache mini cube ip können wir uns merken wenn ich jetzt einen curl drauf mache
da hätte ich jetzt eigentlich gedacht dass es funktioniert
keck wait
das geht mit mini cube ich habe das selbst so mit mini cube schon gemacht
da hat ja auch eine klasse ne ne die klasse die klasse ip da müsstest du dich tunnen
ne ne ne ne ne das funktioniert so glaube ich oder das ist immer jetzt jetzt jetzt lernen wir
was okay wir probieren mal was aus braucht der lb nicht noch eine externe ip
ne daten garten port mapping das sollte eigentlich
ich meine wir könnten jetzt weiter gehen und noch noch den ingress davor machen aber
sollte das nicht einfach so gehen jetzt
ok ok also übrigens ich zeige mal dass hier das hier funktioniert an der stelle nicht ja
die du kannst die dinger nicht erreichen du kannst aber zum beispiel sagen mini cube ssh
und dann müsste es da drinne wahrscheinlich jetzt auch nicht
ne ne ne ich brauche kein ingress wenn ich das hier ok mal gucken wir das mit cluster ip ist
ich hätte jetzt eigentlich wecken können das funktioniert so egal probieren wir mal aus apply
ja guck mal mal hier unten was er macht cluster ip das das wird das wird so natürlich auch
nicht funktionieren ich bin mir das muss das muss mit laut balancer noch funktionieren
ja not port können wir auch ausprobieren dass in dem fall ja immer immer das gleiche
in dem fall macht es ja keinen unterschied ist ja immer der gleiche note
mal irgendwas habe ich irgendwas habe ich verkehrt gemacht irgendwas ergibt gerade keinen sinn
ich habe wir können weitermachen und den und den reverse proxy davor pappen
ach ich weiß was ich mache was ich falsch mache ich benutze es doch auch falsch ich benutze es
ich habe alles richtig gemacht ich habe alles richtig gemacht ich bin bescheuert also apply
ist es stimmt alles passt mal auf es stimmt alles ich habe das nur falsch gemacht so
natürlich die cluster ip ist ja nicht erreichbar intern deswegen muss ich jetzt folgendes machen
mini cube service cute app und siehe da das service funktioniert da hätte ich drauf
gemusst ich hätte ja auf die gemäbte auf den gemäbten port gehen müssen guck auf den port
hätte ich gehen müssen der map der port 30.000 430 466 auf port 80 von dem von dem container
so so ist richtig jetzt funktioniert so das ist das ist mein service der hier läuft
das ist dieser hallo welt container von von traffic das ist der mini cube ip mit dem
porter weitergeleitet wird ne load balance hast recht wahrscheinlich bräuchte ich das bräuchte
das nicht wir können zwar wir können es mal weglassen und gucken ob es dann funktioniert
nope siehst du funktioniert nicht notport würde funktionieren notport würde in dem
fall wahrscheinlich auch funktionieren hallo mein gottes auto komplett wieder buggy ups
ja das funktioniert auch also laut balancer braucht man an der stelle nicht wirklich
und der service type notport auch externer ja das müssen wie gesagt ich will es ja da gar
so zumindest man sieht das service funktioniert damit was man jetzt ja schon sieht was ein
bisschen doof ist ich meine wer kann hier wer hantiert damit den dinger wer kann damit rum
hantieren mit den ports und und so also ich meine woher will jetzt zum beispiel jemand der auf
mein service zugreift woher will der wissen dass er das über port 3 2 2 5 9 machen muss das kann
er nicht wissen so was man jetzt machen könnte ist man stellt das hier auf typ load balancer
und mit einer wirklich externen erreichbaren ip dann müsstest du aber die jedes mal wenn
du das über den cloud anbieter machst da müsste es müsste sich quasi über jedes mal müsstest du
dann eine externe ip ressource anlegen in deiner cloud und hast dann am ende ganz viele externe
viel sinnvoller ist es an der stelle so was wie ein reverse proxy davor zu pappen was wir auch
schon gemacht haben mit docker compose mit docker mit zeug haben wir im stream schon öfters gemacht
und zwar ein reverse proxy der dann auch am besten mit einem gültigen let's encrypt zertifikat
ausgestattet ist und der über port 80 und 443 erreichbar ist das heißt neben dieser
definition von den pots und dem service brauchen wir jetzt noch was für eingehenden traffic und
das nennt sich bei kubernetes ingress das gegenteil von ingress ist egress nicht outgress so da
gibt es verschiedene programme die man verwenden kann man kann traffic verwenden man kann engine
x verwenden oder proxy oder sowas wir verwenden jetzt bei engine x aus dem einzigen grund weil
bei mini cube schon in engine x addon für ingress dabei ist das macht man folgendermaßen also wenn
ihr eine richtig fette kubernetes installation habt die bei jedem cloud anbieter läuft oder so da
könnt ihr natürlich daneben was ihr wollt aber mini cube bringt verschiedene addons mit und da
ist zum beispiel dabei sowas wie ein ingress und das ist in dem fall engine x das hat noch
mehrere praktische addons dabei zum beispiel registry die benutzen wir auch gleich noch wir
machen nämlich eine eigene dotnet anwendung die wir dann deployen hier über zu der lokalen
lokalen container registry ich muss noch mal kurz überlegen in welcher reihenfolge wir das machen
also ich würde sagen wir machen jetzt als erstes mal
wir machen das in zwei stufen wir machen als erstes den ingress dann machen wir die dotnet an
das drei zeilen dort netter es dauert nicht lang die dotnet anwendung und eine lokale registry
und dann machen wir gültige let's encrypt zertifikate für den ingress ich glaube das
ist eine gute eine gute reinfolge das so zu machen ok das heißt als erstes enable wir mal
unseren engine x addons enable ingress so und jetzt muss das muss ich ein bisschen
abgucken leute das kriege ich nämlich aus dem kopf nicht gebacken so also wir haben unsere
pots bei der gelegenheit ihr seht hier vielleicht kommt mal mal im watch ihr seht hier wir haben
aktuell nur einen pot laufen also quasi einen pot mit einem container drin das ist natürlich
jetzt nicht sonderlich ausfallsicher man kann sagen das ist natürlich eh nicht ausfallsicher
weil das alles auf meiner vm läuft aber geben wir mal von aus es wäre nicht so ich habe im
anfang gesagt eigentlich das kombiniert ist dafür da um mehrere instanzen so von containern für
uns zu verwalten deswegen kann man auch sagen man möchte mehrere davon laufen haben da geht
man hier hinten den moment wo muss man da hin templates ach fuck ich kann mir das immer nicht
merken in spex spex muss man das irgendwo muss man replica reinschreiben man alter wo muss
denn das wo muss denn das hin das muss doch unter spex oder ja das muss doch unter spex
bin im deployment oder nicht
ach da in die spex meine güte mal ja genau ja ich bin großer jammel fan was das angeht also da
kann man jetzt eingeben wie viele pots standardmäßig laufen sollen sagen wir mal zum beispiel fünf
ja komm vier wenn ich das jetzt noch mal apply werdet ihr feststellen auf einmal hoch guck mal da
damit ja vier container das heißt unsere anwendung läuft jetzt vier mal und wenn ich jetzt hier
minikube service aufmach und funktioniert das auch kein ding aber es gibt noch mehr möglichkeiten
der chrome kecht ja scheint so wir können das ganze auch noch mal stimmt aber machen wir das
guckt ihr seht jetzt auch die ip ändert sich immer seht ihr das guck 12 6 12 10 11 also ihr
seht die ip ändert sich immer ich komme immer auf unterschiedlichen pots raus guck mal 69 pots
machen wir jetzt mal jetzt wird hyperscaled hier apply ich hoffe das geht überhaupt in meiner
fremden gescheit bämm jetzt haben wir die anwendung 69 mal laufen wenn ich jetzt in köln mache wir
müssen kurz warten bis alles erstellt wurde das ist leute ist das high performer mindset
jetzt habe ich
so guckt ich lande jetzt jedes mal auf einem anderen oder fast jedes mal auf
einem anderen pot jetzt hier an der ip oben so und jetzt guckt mal was wo man jetzt schon mal
sieht dass es sehr praktisch ist so ein container orchestrierungstool zu verwenden es gibt natürlich
auch möglichkeiten das automatisch zu skalieren anhand der last der ram auslastung und sonst was
das machen wir heute nicht das nächste mal geben wir auf was realistisches runter ich sag jetzt mal
vier jetzt sage ich apply und passt auf es wird automatisch runter skaliert auf nur vier laufende
pots warum ich linux verwende weil man gerade so netzwerk und technische sachen viel besser
unter linux machen kann minikube unter windows geht auch dann macht er unter der haube glaube
wie vm in der dann aber höchstwahrscheinlich linux läuft weil letztendlich sind es ja alles
linux container und ich finde so sachen unter linux zu machen tausendmal angenehmer als unter
windows allein schon dass man ein gescheites terminal hat ja das neue terminal unter windows
ist halbwegs erträglich aber nix gegen ordentlich ordentliche linux umgebung so jetzt habt ihr
gesehen man kann den kram hier auch ordentlich rauf und runter und runter skalieren wie man will
am besten ist natürlich später man macht das automatisch aber das gucken wir uns mal in einem
anderen stream an da habe ich auch gerade gesagt vor zwei minuten so soll das mal überlegen was
wollte ich als nächstes machen genau also wir machen jetzt wir machen jetzt den ingress controller
also es ist immer noch das problem dass ich hier in köln machen muss mit so einem komischen port
normalerweise will man ja dass jemand so drauf zugreifen am besten noch mit dem dns namen ja
darauf zugreifen kann also gar nicht gar nicht mal mit einem dns vor allem aber auf jeden fall über
port 80 und dann auf dem richtigen service rauskommt das heißt wir brauchen jetzt noch
irgendein service der das ob dessen ingress ingress template hat ja wir brauchen das noch
irgendein service der eben am eingang sitzt das entgegen nimmt und dann weiter leitet an
den service wiederum an die pots das ganze nennt sich mal kubernetes nennt sich das ingress also
nennen wir das hier mal cute app ingress weiß ja nicht ob es minus in ingress wir können es
nennen es aber wieder cute so wobei das tatsächlich sinnvoll ist das vielleicht ja anderweitig zu
bedenken weil es könnte ja mehrere eingänge geben aber wir machen es jetzt einfach mal so so host
da können wir jetzt in dns name eintragen was auch sinnvoll ist ja dann nehmen wir jetzt nehmen
wir jetzt zum beispiel mal kackel punkt keck w punkt services prefix alles service bei service
kommt jetzt der name rein das service ist was wir hier oben definiert haben das ist cute app und
bei port port 80 so und da muss man jetzt und da muss man jetzt ein bisschen gucken hier geht
es drum um also um den target service nicht nicht hier irgendwie vom vom ingress controller dann
brauchen wir noch ein paar andere sachen damit das ganze funktioniert das ist so magic kubernetes
zeug und das muss ich jetzt abgucken weil das kriege ich aus dem kopf nicht hin wir verwenden
als eingangs proxy engine x das heißt ich muss das wie gesagt das gucke ich ab das war ich aus
dem kopf nicht ingress class name muss ich eintragen nämlich engine x warum weil es
nicht funktioniert jammel brauchste ultra wide screen monitore so und wenn ich jetzt alles
richtig gemacht habe was ich mal hoffe dann sollten wir jetzt den ingress bekommen der
sich für diese domain zuständig fühlt und dahin weiter leitet apply ok cube ctl get ingress
what the fuck ingress ja haben wir host kackel punkt keck w services port 80 damit das damit
das ganze funktioniert lokal müssen wir folgendes machen und zwar in die host datei dieses ding hier
mal eintragen also kacke punkt services aus dem kopf ip ist zuerst ja ip ist zuerst genau
ip ist zuerst einer ip mit mehreren amt punkt 49 punkt 2 ist glaube ich die mini cube ip ok
guck mal mal pink pink ok karl moment der wahrheit es funktioniert chrome was nein chrome und siehe
da kackel kacke punkt services ist verfügbar unter der domain und wir kommen auf unseren
verschiedenen verschiedenen pots raus also der der traffic fluss ist jetzt so ich muss den namen
auflösen in dem fall hier kackel punkt keck w punkt services da kommt die ip von meinem kubanet
ist klasse da raus 1 2 1 6 8 4 9 punkt 2 dann geht das hier in den engine x ingress controller
rein der leitet es weiter auf dieses backer der leitet wohlgemerkt alles weiter man kann auch
sagen ich möchte bloß ab hier weiter leiten und sowas er leitet alles weiter an dieses backer mit
dem namen cute app auf port 80 also auf den service cute app port 80 den service haben wir
hier definiert target port port das ist das worauf der ingress controller das ganze weiter
leitet und das service selbst verteilt das dann wieder auf alle möglichen pots so heißt im
endeffekt es funktioniert auch immer noch wenn ich hier reinschreibe 69 pots machen wir es
mal apply damit skaliert das ganze hoch diagonales 5 hat hyperskalierungs cloud native high IQ zeug
wie jetzt hoch skaliert und wenn ich jetzt wieder ein köln mache auf keck w punkt services sehen
wir kriegen fast immer eine andere ip und wir landen jetzt auf einem von 96 69 verschiedenen
pots kann euch das sogar zeigen dass das relativ viel viel ab kann was jetzt kein wunder ist wir
können mal einen htp benchmark starten können man hatte tp benchmark starten sowas wie hey für
eine minuten
warum geht altpunkt nicht was sind das z mal zehn sekunden zehn sekunden volle pulle und ihr seht
guck mal meine cpu last hier oben ist jetzt einfach mal ist jetzt einfach mal 100% oh ja
habe ich hatte tp vergessen
ihr seht auch meine laut geht übelst hoch ja und wir haben 195.000 request geschickt alle hatten
hatte tp status 200 hat wohl funktioniert ich bin mir jetzt gerade aus dem kopf nicht sicher wie
man sich kommando zeilen mäßig die auslastung anzeigen lassen kann gibt es kubectl top oder
so dinge also man kann zusatztool sowas wie lenz und sowas verwenden aber mal gucken ob kann man
kubectl top gibt sowas hot node node minikube matrix api not verfügbar ok
minikube add-ons enable matrix server ist das so aber
ok ok
wo ich das restarten oder so das könnte jetzt in dem minikube geschichte sein dass das nicht will
matrix server ist enabled
der ram ist voll quatsch
glaube ich nicht ach so ja doch das könnte tatsächlich sein ich war mal kurz vier aber
ich glaube nicht dass da voll ist weil so dieser container braucht ja nix ich glaube da hat keine
schmerzen so und wir sehen hier ist autocomplete das ok naja ich war mir können einfach mal
minikube können das ding mal neu starten moment moment insecure konti registries
ich glaube dann einfach probleme mit der matrix api wir starten wir starten das ding mal neu
vielleicht geht es dann muss man manchmal machen ich hatte schon öfters das minikube
lokal manche sachen ich wollte da muss man das neu starten oder funktioniert
dass wir das mal neu starten dann gucken so weil als nächstes gucken wir uns mal an wie man das
mit lokaler image registry macht weil aktuell verwenden wir hier öffentliche public verfügbare
docker images das ist ja meistens nicht der fall also wenn man eigene anwendung laufen lassen
will da will man in der regel nicht diese anwendung public in einem docker container
beziehungsweise in container image ins internet stellen zumindest viele wollen das nicht jetzt geht's
in nebel
ok minikube hat keinen bock
minikube not found ok
kann ich sowas machen wie get node also minikube wie dem auch sei pot ich kann
mir anzeigen lassen kann man das so watchen lassen oder muss man das von hand machen wir
führen jetzt noch mal den kram hier aus also moment ne wobei es doch eigentlich ok
keine ahnung na gut die selbst können ja gar nicht so viel sachen hier abkommen dass ich
das sehe bin ich ein bisschen doof dass es nicht geht aber
ach jetzt funktioniert not minikube auf einmal ok alles klar nice gut zu wissen
hat wahrscheinlich einfach ein bisschen gedauert bis es gestartet ist und sagt
jetzt würde ich eigentlich erwarten dass der ein bisschen mehr ausgelastet ist ist er nicht
hatte aber kein bock drauf denkt sich nope was was interessieren mich 128.000 naja gut machen
wir mal machen wir einfach mal mehr potts ist ja apply
kubectl get potts haben wieder jede menge potts am start das ding ist hat einfach nur
eine krasse krasse verzirkt ne wobei das ist jetzt jetzt pot erstellen so und jetzt
nochmal attp benchmark mein ganzer rechner ist voll man es könnte auch sein dass das
irgendwie richtig funktioniert weil das im container läuft keine ahnung weiß eh nicht
wie man sich das gescheit auf kommando zeile anzeigen lässt anscheinend so aber wirklich
tut es ja nicht wirklich ja cpu 15 prozent na gut durchaus möglich dass es nicht mehr sein kann
als 15 prozent weil ich ja nur in zwei kerne docker container habe für mein minikube ach guck
jetzt geht es ein bisschen hoch also wirklich wirklich wirklich toll zur übersicht ist das ist
gut aber jetzt war mal wieder mit dem was gescheites jetzt machen wir eine lokale container
registry normalerweise ist es ja so wenn ihr anwendungen programmiert habt oder wenn ihr
in einem unternehmen seid das der anwendung entwickelt hat und das auf kubanetis deployed
dann ist das ja keine open source anwendung die irgendwo im internet verfügbar ist ja das
kenne ich das kenne ich habe ich aber noch nicht benutzt ich kenne das ich habe ich habe erst
gestern mir ein paar kubanetis frontends angeguckt
so und dementsprechend willst du ja auch keine container images bauen mit deiner
close source super secret versicherungs banken anwendung und hier auf docker hab
öffentlich ins internet pushen so was du natürlich machen kannst ist wenn die firma in
der cloud ist und in einem cloud anbieter vertraut kann man eine container registry verwenden also
ich sag mal ihr kennt docker hab wahrscheinlich docker hab ist so die älteste container registry
die es gibt docker hab ist nicht die einzige github hat beispielsweise auch eine eigene
docker hab kennen die meisten aber so docker hab ist halt public oder man meldet sich an und
kriegt da auch ein private account aber es ist immer noch in der cloud das ist im internet also
vielleicht möchte man nicht seine anwendung oder die das unternehmen die anwendung ins internet
stellen entweder benutzt man dann irgendeine registry wie docker hab allerdings bloß angemeldet
und private oder github private registry oder man hostet sich eine container registry selber ich
persönlich würde eher dazu tendieren die container registry nicht selber zu hosten sondern die von
jeweiligen cloud anbieter zu nehmen also wenn man zum beispiel bei amazon ist bei azure oder bei
google oder geben wir mal bei google wenn ihr gcp google cloud kunde seid dann könnt ihr auch da
eine container registry verwenden für unseren fall werden wir jetzt eine lokale container registry
mit mit einem add-on was im minikube eingebaut ist verwenden das ist ganz praktisch dann muss
ich mich hier nirgendswo anmelden docker hab technisch sondern kann das hier alles lokal machen
dann machen wir eine kleine dotnet anwendung und die packen wir dann anstelle hier von who am i
traffic container packen wir in einen docker container bzw. bauen container image und pushen
das zu unserer lokalen container registry und bei der gelegenheit gucken wir uns dann auch noch
ein paar einheiten an damit man so was updaten kann ohne dass die anwendung dabei ausfällt
so wir machen jetzt erstmal hier in den ordner nennen wir mal app so dotnet habe ich überhaupt
habe ich überhaupt asp dotnet runtime installiert asp habe ich gar nicht null dachte mir noch
irgendwie ich gehe mal kurz durch den chat durch was was da so gekommen ist ich habe wieder die
hälfte nicht gelesen wenn firmenleute mit kubernetes erfahrung suchen wo ist dann in dem
job genau die schwierigkeit dass die firmen wahrscheinlich gar nicht wissen was sie wollen
ich glaube viele denken sie wollen kubernetes weil man das kennt und damit ja automatisch alles
agil wird und skaliert automatisch und alles super verfügbar ist das ist aber ein trugschluss also
man ist wahrscheinlich mit bekannter technologie mit leuten die sich damit auskennen besser als
wenn man jetzt übers kniepricht kubernetes für irgendeinen anwendungszweck wo es vielleicht
noch gar nicht mal großartig sinnvoll ist ja sie juzu dankeschön für den sub also ich glaube die
größte schwierigkeit ist dass die firmen wahrscheinlich nicht so genau wissen was sie
wollen und ansonsten das für mich komplizierteste was kubernetes angeht ist eindeutig in dem
ökosystem den überblick zu behalten wie gesagt ich habe es am anfang gesagt ich bin auch nicht
die pot sind running ich bin auch nicht das super krasse kubernetes checker ja und das
ökosystem ist wirklich unglaublich komplex es gibt für es gibt für alles acht verschiedene
lösungen allein schon allein schon wie speichert man apk und passwörter in kubernetes da gibt es
fünf sechs verschiedene varianten von einfach bis super von ein bisschen einfacher und super
kompliziert ne habe ich nicht da als secrets stores die besser nicht weil als secrets steht
das im klartext in dein jammel files drinnen das kann man machen aber sobald du den jammel
files ins git einchecks stehen deine secrets im klartext drinnen so da gibt es verschiedene
möglichkeiten es gibt so sachen wie siehe secrets dann speichert man das ganze verschlüsselt
verschlüsselt im git und entsperrt das quasi per key beim kubernetes cluster start dann gibt
es irgendwas komisches von mozilla was quasi irgendwie so ein makro für jammel files ist
dann gibt es sowas wie wollt und so da wird es aber schon langsam richtig kompliziert also
gibt es unglaublich viel geschiss drumherum also gibt es ganz viel also da die ich glaube es
gibt keinen den überblick behält ja da gibt es so sachen wie helm wo dran steht es ist ein
paket ein package manager für kubernetes und du guckst dir mal helm chart definitionen an
und musst erst mal kotzen wenn du die dateien siehst also da gibt es dann ja auch es ist auch
nicht das einzige was es gibt gibt es auch wieder drei verschiedene sachen dann kannst du im
zweifelsfall auch einfach sagen auch ich scheiß auf jammel und kannst es direkt über terraform
kubernetes provider und das ist also dadurch zu blicken ist tatsächlich für mich für mich
das schwierigste ich blicke da auch nicht durch soll ich ganz ehrlich also es gibt es gibt so
viele sachen wo ich keine ahnung von hab an sich tools was es für möglichkeiten gibt und
und später wenn es dann richtung service mesh und solche geschichten geht habe ich mich auch
nur am rande mit beschäftigt da wird sein ganz abgedreht also muss sagen so die basic funktion
von kubernetes sowas wie das was wir gemacht haben das ist tatsächlich gar nicht so schwer
wenn man sich ein bisschen an die namen gewöhnt hat wie die den kram nennen aber das was damit
dann noch zusätzlich kommt macht es kompliziert eine sache werden wir vielleicht gleich noch
sehen mit manager und und zertifikate anlegen damit dann schon wieder ein bisschen komplizierter so
wir bauen jetzt mal eine eigene net anwendung die wir benutzen als application application
wie gesagt leute kein dotnet programmier stream das wird was ganz kleines was im
prinzip nur aus drei zeilen oder so besteht also dort net new web
so eine neue net anwendung und verwendest du das wim plugin wischl zu kontinue wenn ich
wimm aufmache ist es der reale wimm noch nicht mal neowimm tatsächlich da stinkt normale wimm
das ok ja ich traste traste alles hier voller trust
dollen anwendung am start ja das habe ich da habe ich da habe ich jetzt gar nicht dran
gedacht leute ja die ganzen cluster und storage möglichkeiten gibt es ja auch noch du musst ja
das müssen wir uns ja auch noch angucken hier nicht heute im stream aber an der nächsten
stein guckt mal meine anwendungen hier sind ja komplett stateless aktuell es sollen sie im
besten fall auch sein in kuba jedes ja aber irgendwo müssen die daten ja hin der einfachste fall ist
es gibt irgendwo den datenbank service und du connectest dich dahin liest und schreibst ein
gutes aber manchmal brauchst du auch persistente dateien oder config files oder config einträge
mit environment variable und sowas also aber spätestens bei dateien fängt es dann so an
wo wie bekommst du wie bekommst du falls in den container da gibt es auch 1000 varianten von
clusterfile system bis s3 du kannst darüber s3 machen gibt es 1000 varianten und gerade diese
vielfalt und dann die auswahl aus dieser vielfalt was lohnt sich denn jetzt für den jeweiligen
anwendungsfall anwendungsfall ja das ist das ist moment ist glaube ich nicht die landkarte die
ich kenne doch das ist die landkarte ich kenne ja die ist wirklich nice ja und das ist beim
weitem nicht alles was da drin steht wenn ich reingucke gibt es viele sagen es ist vieles
weil ich noch nie davon gehört habe und auch einiges was hier noch fehlt also da den überblick zu
behalten was es alles gibt und dann das passende auszuwählen für den anwendungsfall den man hat
das ist fast das schwierigste an der ganzen kubanides geschichte und was man ehrlicherweise
auch sagen muss was auch schwieriger ist als mit vms ist so ich meine ich habe jetzt hier
drei pots laufen alles schön und gut aber wenn dann mal irgendwas nicht läuft in so einem
kubanides cluster rauszufinden warum da jetzt also mal so eine anwendung zu debuggen in so einem
kubanides cluster ist gar nicht mal so einfach im prinzip könnt ihr eigentlich nur folgendes
machen logs für den container könnt ihr euch angucken so viel mehr dbug möglichkeiten habt
ihr nicht es gibt noch die möglichkeit sich rein zu connecten in den container das können wir uns
können wir uns auch gleich angucken also man kann ja mit docker was ist docker exek minus it
und bin wäsche also wir machen das mal docker beispiel ja ich krieg das immer nicht aus dem
kopf hin was habe ich verkehrt gemacht docker exek und wenn er schon läuft docker exek wenn
er schon läuft docker exek kann man sich ja in lokale docker container rein verbinden das
gleiche gibt es auch gibt es auch cube ctl exek oder kann man sich versuchen in weiß ich aber aus
dem kopf überhaupt nicht wird es funktionieren kann man sich versuchen rein zu connecten in die
container wenn es da zum beispiel eine shell gibt und sowas
es minus minus kommandok die haben aber die haben aber aktuell keine shell aber nicht dass du
trotz ist es trotzdem schwierig so was so was zu dbuggen also da muss ich sagen das ist immer noch
wenn du so eine vm hast wurde dich rein connecten kannst und da dann rum wurschteln
kannst drinne angenehmer so wirklich rauszufinden wo ist der fehler zu gucken ok warum funktioniert
jetzt die namensauflösung nicht und so was also so ein container deployment zu dbuggen finde ich
persönlich eine ganze ecke anspruchsvoller ich habe das leider wieder zugemacht anspruchsvoller
als eine vm wo was drinne läuft heißt die frage wo kommen deine locks raus deine locks sind ja
wahrscheinlich da nicht lokal in dem container sondern auf irgendeiner lock aggregierungs loki
oder irgendwas oder lock sammel plattform oder elastix und was gibt es denn da alles mir fällt
es muss loki ein von dem was ich verwenden würde kibana gibt es da noch und und zeugs
jenkins nicht jenkins ist kein lock lock sammel plattform das ist das falsche was ich hier auf
mache das ist nicht gecheckt dass ich hier moment ich mache das writer ist wieder zu
pepega ok hat es hat es wieder nicht gecheckt hier max nepos minikube ja trust ok wir machen
anwendung wo ich noch ein paar Sachen zeigen kann hatten wir hier noch nie rider offen auf
der neuen vm ich glaube nicht ich glaube das ist neu ok sekunde da müssen wir erst mal was
einstellen file settings short cuts ja fast fast ein action braucht wieder den standard
short cuts ok ja ja remove und editor font ja mal wegen jet planes mono soll mir recht sein ok
so jetzt jetzt sieht man ja hier was ach ja und sie pass mal auf leute flashbang
ich war noch ein bisschen größer so also wir machen jetzt wirklich eine ganz simple minimale
dotnet anwendung also hello world wollen wir nicht wir wollen return cute chatter
so und dann müssen wir noch noch einstellen hier war name gleich wir machen das auch gleich mit
environment variablen dass man auch was weiteres lernen kann environment variablen get so wunderbar
reicht gut das ist unser unsere minimal dotnet web anwendung das reicht auch mehr brauchen wir
zum testen an der stelle auch nicht reicht voll und ganz aus wir machen jetzt noch zwei sachen oder
besser gesagt eine sache die sehr nützlich ist und zwar sagen wir noch ich glaube bilder
bilder ad health checks nee service ad health checks und dann bei ad ad nee ach fuck wie war
das map map health checks und zwar das ganze unter slash helft wisst ihr warum helft und
weil aus irgendwelchen gründen die kubanete leute sich gedacht haben es ist eine tolle idee
das mit z hinten dran zu schreiben wahrscheinlich weil das andere schon zu oft belegt war oder so
keine ahnung worum das herkommt aber die finden es cooler dass das mit slash helft vielleicht
weiß das deck overflow auch warum das so ist historisch die it comes from google internal best
practices ok leute ihr habt es gehört helft ist google best practice excellent danke google so
das ist unsere dotnet anwendung das war es auch schon mehr brauchen wir nicht was wir jetzt machen
müssen ist ein image bauen für diese dotnet anwendung und das mache ich ganz einfach ich
klaue mir den image weil habe ich nämlich schon vorbereitet kioko dankeschön für den sub und
sorry falls ich irgendjemanden übersehen habe mit subs subscriptions ad docker support linux docker
file das kommt alles weg weil das rider template kacke ist und jetzt bärm soll ich das noch mal
kurz erklären oder wollen wir das docker feil einfach zur kenntnis nehmen und nicht mehr
reingucken kann ich den stream als arbeits- oder weiterbildungszeit absetzen ich würde sagen schon
wir machen hier schon wichtige wichtige dinge so weil mit diesem docker feil kann ich jetzt aus
meiner dotnet anwendung ein container bauen und diesen image bauen und dieses image kann ich in
eine container registry pushen und auf diese container registry kann ich dann an der stelle
hier von kubernetes drauf zugreifen und meine eigene anwendung aus meiner eigenen container
registry ziehen und nicht mehr aus einer öffentlichen container registry im internet ja so sieht es aus
wir können mal kurz schauen ob mein bild funktioniert docker bild punkt
ich spreche mal kurz ab docker bild minus t cute app
schauen wir mal
irgendwann
ist das dann auch fertig gebaut
so docker run it's minus minus m cute app
jawoll da sind wir port 80 karl localhost
achso ich habe keinen ports weitergeleitet lull pk 80 80 cute chatter gibt es nicht guck mal
keiner unsere anwendung hatten back wir brauchen noch wenn wenn die environment variable nicht
gesetzt ist brauchen wir noch default value excellent ok cute app noch mal bilden keine cute
chatters bekannt ok run cute app also wunderbar ok das ist unsere absolut high IQs maximum IQ
also bessere web anwendung geht nicht mehr und wenn ich jetzt slash health mache dann
kommt healthy zurück und wenn ich weglasse kommt nichts weil bei google sagt da muss
ein z hinten dran gut das ist unsere web anwendung fertig aus das war es mit c sharp für heute
demnächst wieder mehr hier test machen das nächste mal wobei man keine tests braucht
wenn man immer fehlerfreien code schreibt dann braucht man keine doku keine tests
und keine kommentare weil es geht ja eh also sagen wir unsere unsere unsere unsere anwendung
und jetzt müssen wir diese anwendung pushen in unsere lokale container registry ich habe
hier schon mal in weißer voraussicht mein kubanete ist gestartet mit insecure registries
weil naja von meiner container registries kein gültiges SSL zertifikat als erstes
mal enable registry und irgendwann ist es dann durch ich kann euch auch mal zeichnen cube ctl
get ports for all namespaces und da seht ihr hier kommt mal da cube system code s etcd bla bla bla
und hier ist die container registry also die addons sind unter der haube auch nur container
warum nicht pots tja muss man mal google fragen wie das sein kann gut und jetzt müssen wir in
diese lokale container registry unsere app pushen das machen wir nicht mit docker ich kann euch
auch sagen warum wir das nicht mit docker machen weil docker es nicht mag wenn die registry kein
gültiges SSL zertifikat hat das muss man das kann man irgendwie konfigurieren bei docker fragt
mich nicht wo also von der idee her würde man würde man das bilden und dann würde man sagen
docker push und dann die registry ja man muss in irgendeine konfig feier kann man es reinschreiben
aber wir nehmen einfach potman weil potman hat eine konfig option dafür potman ist quasi
ein docker klon von rett hat mit ein paar sachen die docker nicht kann und umgedreht
so weil jetzt kann man sagen potman bild und jetzt kommt es darauf an wie man das
image nennt damit das ganze funktioniert warum nicht pot woman fragt mal twitter
heute ist heute ist equal payday weißt du das eigentlich leute
equal payday ist heute jetzt da sollte man schon mal potman in pot woman wenigstens mal
zumindest für heute umbenennen so also damit das ganze funktioniert damit man sein sein image in
die lokale container registry pushen kann muss man das taggen und zwar richtig taggen und zwar
mit der ip und mit der ip beziehungsweise dem namen von der container registry und mit dem
image wie das wie das ganze wie das ganze heißen also ich muss mal sagen wie potman bild wie
gesagt mit docker geht das auch wenn es gültiges zertifikat vor der registry hat also potman
bild 192 wobei wir machen es anders wir machen das wir machen wir machen den script kommen wir
sind wir sind mal super ordentlich wir machen bild.sh bin bash registry gleich hoffe ich schreibe
das ist jetzt richtig registry gleich mini cube ip auf port 5000 läuft die registry das weiß ich
weil ich nachgeguckt habe und wir können noch so was wie einen tag hinten angeben vielleicht
vielleicht gar nicht so blöd wenn wir tag hinten angeben so und jetzt kommt das was wir an potman
kommandos ausführen ist nämlich potman bild minus t registry also in dem fall die ip und
der port und der port name von der app und jetzt können wir noch einen tag hinten dran machen
so und wenn das fertig ist können wir sagen potman push und das muss ich mir jetzt kopieren weil
ich das aus dem kopf nicht weiß minus minus tls verify gleich falls und dann funktioniert das
auch alles über htp beziehungsweise auch mit ungültigen zertifikaten und jetzt hier den
gleichen krempel ich habe übrigens auch einen punkt vergessen so wenn ich das script jetzt
richtig gebaut habe dann sollte der uns jetzt einen container image bilden und in die registry
pushen ok was habe ich denn verkehrt gemacht potman bild minus t registry ah ich habe den
tag vergessen anzugeben ok ja also 1.0.0 hrq app ok jetzt ok er baut und ihr seht es sieht fast
aus wie bei docker nur dass jetzt potman ist wieso der code war richtig funktioniert ohne
jegliche änderung so image ist gepusht nice und was ich jetzt machen kann ist folgendes ich
trage jetzt an der stelle einfach ein localhost ich kann an der stelle jetzt localhost verwenden
weil die registry innerhalb des kubanier des clusters läuft es funktioniert an der stelle
localhost 5000 slash cute app doppelpunkt versionsnummer 1.0.0 und jetzt werdet ihr
feststellen ich zeige jetzt mal watch mein karl keckel
ihr seht hier das ist der aktuelle service der da läuft das ist noch der hallo welt service das
ist noch nicht noch nicht unsere web anwendung was ist köln minus s glaube ich für weniger
output genau so das ist noch nicht unser unser web anwendung ich habe jetzt in dem fall hier in
unserer in unserem manifest unserem kubanier das manifest das image ausgetauscht was ich als
anwendung verwenden will vorher hatte ich hier diese traffic hello world ab und jetzt habe ich
unsere eigene anwendung da rein gepackt die wir die wir vorher als container image verpackt haben
und in diese registry gepusht haben und wenn jetzt alles funktioniert ich hoffe es mal wir
machen hier wir machen hier parallel noch mal ein get pods dass wir nämlich sehen wenn es fehler
gibt studio muss mal kurz weg und jetzt sage ich apply und vorher immer raus apply bär so alte
container werden neue container werden gestartet alte container werden gestattet cute chat eier
zack ich habe jetzt quasi neue anwendung deployed ohne das request kaputt gegangen sind zwischendurch
wie euch vielleicht aufgefallen ist das natürlich schon nice gelb
machen wir das mal weg also wir wissen jetzt dass mit dem image funktioniert so jetzt haben wir
hier unsere eigene anwendung drauf laufen jetzt brauchen wir noch ein paar andere geschichten
dass das ordentlich funktioniert weil aktuell ist es so und um euch das mal zu demonstrieren
beziehungsweise dass man ich zeige es auch mal dass man sich besser vorstellen kann machen wir mal
sexo machen wir mal 69 container
ihr werdet feststellen gleich gibt es wieder jede menge container
während das aufbauen wir machen mal eine ein ein dirty hack in unserem build script den sehe ich
hier nehme ich gerade drüben dass ich das auch aus anderen verzeichnissen ausführen kann so
abbild und jetzt machen wir mal eine neue versionsnummer von der app ja also zum
beispiel okay ich ändere ich ändere der form halber auch noch was ja es gibt ja west version
1.0.1 von dieser app und zwar ist es cute chatter ja ich will ich will hier wobei irgendwas
ist es jetzt okay schreibt man das überhaupt so ist es jetzt noch noch mehr alles und das will
ich jetzt einchecken also ich baue neues image draus aus der anwendung mit diesem mit diesem fix
image version 1.0.1 pusht das wieder in die registry so und jetzt apply ich das und was
wird jetzt passieren leute es wird nix passieren es wird nix passieren weil es hat sich ja nix
geändert es hat sich ja nix geändert warum sind meine pots eigentlich alle pending da unten
ich glaube ich habe zu viele kann es sein dass ich mit den ressourcen am limit bin dass das meine
dass ich zu viele pots habe okay moment wir skalieren es mal runter auf was sinnvolles auf
10 oder so also wenn ich das jetzt applye und wieder curl mache werdet ihr vielleicht
feststellen es ist immer noch die alte message warum na ja weil die versionsnummer die hier
drin ist immer noch 1.0 ist ich will ja 1.0.1 haben so und jetzt wird euch gleich ein problem
auffallen wenn ich das jetzt applye dann wird er updaten dann wird er updaten von dieser von
dem tag 1.0.0 auf 1.0.1 und wenn ihr mal genau guckt was er hier unten macht wird euch vielleicht
was auffallen der startet neue container und lässt dann die alten container löst dann die
alten container aber euch wird auffallen das zeug ist relativ schnell ready das zeug ist relativ
schnell ready das komisch und das ist aber auch doof weil wenn jetzt im falschen momenten ein
request rankommt könnte es ja theoretisch sogar sein dass der request auf dem container landet
der noch gar nicht richtig gestartet ist das heißt wir müssen jetzt nicht nur den container
starten sondern wir müssen auch checken ob der container bereit ist ob der container bereit ist
machen wir mit den health checks hier drinnen wenn du eine fehlerhafte version deploys
der ist ja quasi ach so jaja jaja ach das ist eine gute idee das kann ich auch zeigen das kann
ich auch zeigen guckt mal ich skaliere das mal ein bisschen runter auf sechs stück erst mal
wir werfen keine exception ich trage einfach eine tag ein den es nicht gibt also ich gehe
mal kurz runter auf sechs das sieht man also mal angenommen ich sage jetzt hier nehm mal
image version 1.0 2 die es noch nicht gibt und ich applye das jetzt dann werdet ihr feststellen
der versucht es zu applyen aber er image pull oder macht nicht weiter und die alten laufen weiter
das heißt ich habe obwohl ich eine fehlerhafte konfig haben das ist wirklich auch eine coole
obwohl ich eine fehlerhafte konfig habe ein weiterhin funktionierenden service zwar die
alte version aber egal ich meine besser als kaputt kaputt wäre glaube ich das blödeste
was was an der stelle passieren könnte so wenn ich das als wieder rückgängig mache mal wieder
version 1 rein sache play dann checkt er das ganze auch und er geht wieder auf sechs replikas hoch
also ich habe angeheben ich möchte sechs davon laufen lassen und das ist wirklich cool und das
im großen stil ist eigentlich der grund schlechthin also dieses solche features in der richtung ist
nicht explizit dieses ist der grund schlechthin warum kuba netis sich überhaupt so durchgesetzt
hat du kannst halt wunderbar deinen ganzen workload über mehrere notes skalieren und du
kannst relativ gut ausfallfrei deine software managen damit das ist eigentlich der hauptsächliche
grund warum warum kuba netis so beliebt ist oder sich auch so durchgesetzt hat gab ja noch ein
paar andere andere dinge es gab dann zwischenzeitlich mal docker swarm was ja immer noch gibt kaum
jemand benutzt da gibt es noch ein paar andere geschichten wo mir grad nichts ein gibt es noch
nomad gibt es noch das ist aber glaube ich auch noch mehr mit vms dabei fällt jemand nehmen eine
gute kuba netis alternative ein hat der canonical nicht auch mal den versuch mit lxd gestartet
irgendwie sowas zu bauen was keiner haben wollte
mesos mesos gibt es noch richtig apache war das apache openshift wobei ist openshift noch
deutlich mehr nicht noch deutlich mehr dabei dass du da auch ne moment das ist nicht openshift das
ist openshift also openshift ist die telekom cloud das weiß ich die telekom cloud ist
openshift aber das heißt ja nicht dass es das heißt ja nicht dass es schlecht sein muss wie
heißt das andere wo noch vms und so dabei sind open stack meine ich ich meine open stack und
die telekom cloud ist open stack darum war das nicht openshift open stack meine ich genau
ja richtig richtig so sieht es aus so was wollte ich was wollte ich denn jetzt noch machen ja also
ihr habt jetzt ja gesehen es sind jetzt ganz viele services neu gestartet worden aber die
dinge waren sofort ready das will man ja nicht das heißt wir haben ja hier einen health check
definiert service fabric okay mir fällt schon außer kuba netis gar nicht gar nicht mehr so viel
ein so man kann jetzt an der stelle sagen hier wo man wo man replikas einträgt kann ich auch noch
sagen strategy type rolling ich glaube rolling update glaube ich ist sogar der default da bin
ich mir aber nicht ganz sicher rolling update und dann kann man das braucht man eigentlich gar
nicht ja da kann man dann noch so was sagen wie max unavailable 1 und max max search 1 oder man
kann auch 2 in dem fall so kann man jetzt einstellen wie er updates machen soll also
rolling update ist glaube ich relativ selbsterklärend und wobei das ja noch nicht alles ist was wir
machen müssen und hier kann man jetzt auswählen wie er vorgehen soll beim rolling upgrade also von
diesen sechs replikas wie viele dürfen nicht erreichbar sein während dem update und wie
viele dürfen mehr da sein als target also mit diesen settings würde folgendes passieren er
könnte zum beispiel einen neuen container erzeugen schon im vorfeld bevor er den alten
stoppt und dann können alten stoppen so dass kurzzeitig fünf nur laufen und das zwischenzeitlich
kurz auch mal sieben laufen können was ja wichtig ist weil bei einem update müssen ja neue container
gestartet werden alte container gestoppt werden ist halt die frage wie man das macht man kann
natürlich auch hier mehr eintragen wenn man damit dacor ist dass auch mal von diesen replikas weniger
laufen hiermit kann man das quasi ein bisschen feintunen wie man dieses update wie man dieses
update durchführen will wenn ich jetzt wenn ich jetzt sag wie ging das jetzt die deployment
cube cube rollout cube ctl rollout restart wobei ich brauche ich gar nicht ich kann es einfach
machen doch anscheinend ja ok cube ctl rollout restart deployment das sieht man jetzt macht
er das halt entsprechend dieser policy das maximum einer eben hier immer abgecreated wird aber wenn
ich jetzt hier zum version runter runter gehe auf version eins sach apply dann seht ihr ok
der erzeugt zwei neue und er stoppt immer kann auch immer ein zwei austauschen immer ein mehr
und ein weniger kann man das ein bisschen feintunen was er was er machen darf so was aber viel
wichtiger ist wir brauchen noch health checks weil ihr seht jedes mal wenn der container
gestartet ist er sofort ready das stimmt ja gar nicht der container ist gar nicht sofort ready
der muss ja auch erst mal starten die web anwendung muss starten ich mein das geht schnell ja mein
potman run cute cute app ach so das hieß ja irgendwie anders was weiß ich
so ihr seht so ein container startet schnell ist mal exemplarisch lokal bei mir mit docker
der startet schnell aber es ist trotzdem eine halbe sekunde wo der container gestartet ist aber noch
nicht bereit ist requests anzunehmen und es könnte ja auch durchaus länger dauern ok keine frage
so und dafür gibt es solche sachen wie ready probe und lifeboard oder life nes probe und
readiness probe das muss man das muss man abgucken wo das hin muss unter unter ports
muss unterhalb von ports also dahin muss das an der stelle
als wer cringe das kann ich dir nicht erzählen habe ich keine große erfahrung drinne
ich würde mal sagen mit datenbank migrations aber du willst die postgres version updaten
oder was also willst du nicht deine datenbank intern die struktur updaten du willst die
datenbank version updaten oder wie das eigentlich erwarten dass deine anwendung sowohl mit der
alten als auch mit der neuen version funktioniert weil ansonsten ansonsten wäre das easy du
updatest zuerst die datenbank wenn du die datenbank version updaten willst du updatest zuerst die
datenbank dann die anwendung und dann ist gut das schema ok du willst so was wie eine datenbank
migration oder so haben das ist eine gute frage habe ich keine erfahrung mit wie man das gescheit
synchronisiert jetzt bestimmt irgendwelche super tollen best practice sachen für aber ich kann
da nichts sinnvolles zu sagen ich kann jetzt höchstens was zusammen reiben was mir da so
auf dem stegreif einfällt aber ich wenn du das schema updatest dann erweiterst du das schema
ja in der regel oder machst du das schema incompatibel also geht die alte anwendung
noch mit der neuen schema version oder nicht wahrscheinlich nicht
wenn das so wenn das so voneinander abhängt müsste ich mir gedanken zu machen kann ich dir so
vielleicht an der chat ahnung wir haben hier viele 5 hat cloud native kubernetes 6 herz vielleicht
fällt da jemand was zu ein wahrscheinlich kommen die leute jetzt wahrscheinlich kommen die leute
jetzt an und sagen ha ha null gar keine sql datenbanken mehr verwenden sondern einfach nur
noch cloud native data basis wobei das halt nicht realistisch ist das ist dann wenn du die
falschen leute was sie kommen dann immer mit so was so ja warum verwendest du auch nicht
klaut technologie in kürze bescheuern wer definiert was klaut technologie sachen ist und was nicht
also das ist das ist was du hast zwerggründe ist ein sehr praktischer und realer anwendungsfall
und darauf gibt es bestimmt auch eine gute lösung habe ich aber keine erfahrung mit kann
ich dir gerade nicht sagen zu also das naheliegendste ist natürlich du musst sicherstellen dass die alte
anwendung auch mit dem neuen schema funktioniert also dass du kannst das schema zwar erweitern aber
dass es nicht incompatibel zur alten anwendung machen dann funktioniert es dann ist easy dann
kannst du zuerst die datenbank updaten und dann die anwendung und wenn das nicht so ist fällt
jetzt so spontan nicht so viel ein weil da müsstest du ja sicherstellen dass du irgendwie so einen
rolling update machst so die datenbank updaten dann wobei es halt je nach datenbank auch so ist
dass du gar keine unterschiedlichen datenbank anspricht sondern alle datenbanken in dem cluster
über halt ein connection string wenn du so willst dass du gar nicht explizit sagen kannst ich will
jetzt nur auf diese tja da gibt es bestimmt coole möglichkeiten zu bis jetzt hatte ich das muss
ich mich mit diesem problem noch nicht beschäftigen wenn es soweit ist sag ich dir bescheid
ich würde einfach sagen ist job der dba es kümmert dich nicht drum dass sie das machen
sag einfach nicht mein problem easy
ja aber kommen wir mal zur container geschichte zurück
damit ich mitbekomme wann meine anwendung wirklich gestartet ist gibt es readiness probes und es
gibt dieses autocomplete alter ist es schlecht man leifnis probe gibt es das eine ist wenn
der container ready also wenn der container gestartet ist zum ersten mal und das zweite
ist ob der container noch weiterhin funktioniert und ich copy paste mir das jetzt hieraus aus
dem beispiel weil ich keinen bock habe das nochmal alles zu tippen so sieht das ganze
dann aus aber gibt sogar eine hilfe dazu der guckt ob der ob der container ready ist und
der guckt ob der container noch am leben ist und wenn diese das ist der unterschied wenn
diese leifnis probe fehlschlägt dann restartet kubernetes den container kann auch sehr praktisch
sein falls die anwendung nicht komplett krascht sondern intern bloß in so einem
zustand gerät dass sie nicht mehr richtig funktioniert also leifnis probe startet
kubernetes im zweifelsfall den container neu und hier kann unter anderem dieser ready check
entscheiden wann das denn in den load balancer aufgenommen wird es gibt auch startup probe ja
aber das braucht man in der regel nicht genau so und wenn ich das jetzt apply dann werdet ihr
vielleicht gleich was feststellen guckt mal das geht jetzt deutlich langsamer seht ihr das
das das geht jetzt deutlich langsamer alles und warum weil er halt immer fünf sekunden wartet
bis das ding auch wirklich am leben ist also der wartet fünf sekunden macht dann diesen health
check ob es am leben seht es dauert deutlich länger aber jetzt haben wir den großen vorteil
jetzt gehen keine requests mehr keine neuen requests mehr verloren also wenn ihr einen ganz
ungünstigen moment erwischt dass ihr gerade weiter geleitet worden seid auf einen server und der
wird gerade weg gestartet oder so dann kann es sein dass man immer noch einen fehler kriegt aber
es verschwindet gering und das kann ich euch jetzt auch zeigen ich mache mal einen ich mache mal
den benchmark ok ich mache ich mache eine neue version wir gehen wieder zurück zu cute cute
chatter ich mache ich mache eine neue version 1.0.2 von unserem container pusht das in die
registry update die container version und jetzt passt mal auf ich mache einen benchmark
hey haben wir waren 30 sekunden dann war mal länger eine minute aber eine minute eine minute
holle pulle requests auf diesen service ich fange jetzt an und jetzt mache ich das update apply
wir können wir können nebenbei nebenbei zugucken cute
pots ja ihr seht die pots werden neu gestartet und werden hinzugenommen und alles
latest funktioniert nicht apply läuft immer nur dann wenn sich das manifest geändert hat latest
funktioniert nicht es gibt tricks dass es mit latest funktioniert aber das stammt mich funktioniert
das mit latest nicht so unser rolling update ist fertig und jetzt bin ich mal gespannt ob
requests verloren gegangen sind das läuft noch ok irgendwie das zum irgendwie spackt es rum wir
warten mal kurz die minute ab es spämt es spämt immer noch heftig so requests und guck mal wir
haben eine millionen requests gemacht und nur und jetzt halt euch mal von einer millionen requests
sind nur während diesem rolling update 39 oder 40 requests mal als nicht erreichbar zurückgekommen
von einer millionen request 40 und wir haben unsere anwendung geupdatet im hintergrund ich
weiß wir hatten mal so einen krassen manager dude der gesagt hätte jetzt 40 requests dann sollten
wir uns jetzt mal auf die konzentrieren die nicht funktioniert haben haben wir vielleicht logs wo
wir die bangen können warum diese requests fehlgeschlagen sind aber ich glaube das ist
eine ganz gute ausbeute von einer millionen requests 40 requests fehlgeschlagen und das
während wir unsere anwendung geupdatet haben also das ist schwierig hinzukriegen anderweitig
hättest du 100 prozent wenn du kein crawling ab du meinst in rolling update machen würdest
die rolling update ist das beste was man machen kann du hast als du hast als auswahl sollst du
recreate ich bin den haus gebrauche ist das nix es gibt so verrückte leute auf youtube die
haben drei kubernetes cluster daheim ist unsinnig und was man an der stelle auch noch mal dazu sagen
muss wir haben jetzt ja ihren kubernetes cluster selbst erstellt und verwalten den kubernetes
cluster selbst normalerweise musst du dich mit so grundlegenden sachen wie skalierung und so gar
nicht großartig auseinandersetzen wenn du ein managed cluster also nicht einfach nur ein managed
cluster sondern so wenn du den autopilot cluster von google beispielsweise wenn es da brauchst du
nur noch deployments machen damit müssen wir uns auch noch beschäftigen die nächsten tage
oder versions updates versions updates von kubernetes und solche geschichte da musste
dich nicht mit beschäftigen wenn du managed cluster verwenden also vieles von diesen basic
sachen musst du gar nicht selbst machen zumal ich meine wenn du den benchmark jetzt ausführst sind
dann alle 100 prozent kann schauen wir mal ich lasse noch mal laufen kann durchaus sein dass die
meine cpu ist ja auch voll am anschlag dass die ein oder anderen requests einfach nicht nicht
richtig durchgehen also managed cluster kümmern sich um versions updates von kubernetes und so
was schon da hat man viel arbeit nicht mehr was aber eigentlich auch ganz gut ist weil ganz ehrlich
da hängt halt sehr viel so lowlevel kram dran wo es schwierig ist das alles das alles richtig
zu machen und was auch ein gewisses tiefgreifendes know-how erfordert alle staub
ja das waren die control set ich habe kein control set gemacht ich habe terminal auf und zu gemacht
ja jetzt habe ich eine millionen responses und zwar alles 200 ja also wir hatten tatsächlich
40 requests verlust in unserem upgrade gibt schlimmeres oder von eine millionen requests
ok chat wie hat es euch bis jetzt gefallen kubernetes stells
wie gesagt ich bin ich ich bin selbst nicht ich bin ja selbst nicht das super super
oberkombiniertes checker aber ich glaube so mit lokaler registry und so was hier das war
schon ganz cool dann lasst uns doch jetzt noch mal kurz eine viertelstunde überlegen was wir
als nächstes machen also als nächstes eine sache die mir eingefallen ist ja environment
variablen genau n so volume secrets cert manager das will ich unbedingt zeichen mit
let's encrypt lokal dns challenge na service mesh das ist jetzt schon ein
bisschen zu etwas dann vielleicht irgendwann noch mal ja und ends backends traffic gibt
naja bisschen ja ok
geht aber ich finde den namen so dass es da hat man eigentlich was recht logisches also was
naheliegendes so nach dem motto man checkt seine config in geht ein wieder super cool benannt
dazu kommt da natürlich aber auch noch so dinger wie automatische tests und also man könnte man
zum beispiel sogar solche dinger machen wie man ganz abgedreht weiterspinnen man könnte ja zum
beispiel sagen ok man hat noch eine test suite für diese test suite fürs jetzt super krasse
dort net anwendung und man lässt es dann irgendwie automatisch noch bilden und lässt die tests
durchlaufen und lässt sich dinger machen dann automatisch noch auf irgendeinem ce server das
image bauen dass man das nicht lokal machen muss so was in der richtung gibt ja gibt ja viele
viele dinger man kann ganz abgedrehte sachen machen ja also irgendwann was wir uns auf jeden
fall noch angucken ist das finde ich persönlich eine coole sache weil du damit weil du hiermit
kannst du solche manifest erstellen in pyson zum beispiel finde ich persönlich eine super
geschichte ist eigentlich overkill und komplett unsinnig für vieles aber ich persönlich finde es
sehr nice weil man halt zum beispiel so sachen definieren kann guck hier hier hier kann man zum
beispiel sagen hier cube service load balancer cube deployment also das was wir eben im manifest
definiert haben kann man hier drin der ja ich weiß man kann auch hellen und so was verwenden
ich persönlich würde dann aber fast sagen mir persönlich ist das hier finde ich den ansatz hier
cooler weil man dann vollständige programmier sprache und ich mache halt lieber das im source
code als irgendwelche jamme files und description files und so bauen also das ist cool ja hellen
müssen müssen wir uns aber der vollständigkeit halber auf jeden fall angucken weil fast jedes
zweite tutorial heißt ja in hellen repo enden und ausführen zum beispiel secret manager secret
manager sagt das auch customize habe ich keine ahnung von kein plan vielleicht können wir uns
irgendwann auch mal terraform noch in kombination mit dem kubernetes provider angucken habe ich
jetzt auch noch nicht gemacht dann gucken wir uns natürlich noch google cloud managed kubernetes
und auto autopilot an das ist der eigentliche grund warum ich mich in den letzten tagen wieder
ein bisschen mehr damit beschäftigt habe weil ich weiß dass bei meinem neuen arbeitgeber google
cloud mit wahrscheinlich managed kubernetes oder autopilot cluster vielleicht darf sogar ich
mir aussuchen was ich haben will einsetzen wer das heißt da muss ich ein bisschen gucken
metal lb ich habe keine ahnung was das ist ich kenne kong kong ist auch so ein
lautballon kein lautballon so ein api gateway ist das harambe
ich habe keine ahnung was es mir sagen soll ehrlich gesagt netwerk lautballon
was ja selbstverständlich da habe ich ja ganz vergessen das müssen wir noch mal hier
matrix ja matrix auch natürlich da müssen wir uns noch sidecar container angucken für so
monitoring und logs also ihr seht schon die einfache die bild in kubernetes sachen die
sind an sich recht easy ja kommt man recht schnell mit aber das ist ein loch ohne boden was da alles
dran hängt dann ja volumes volumes ja haben wir ja schon
und das was da dran ist wirklich ein fast ohne boden so bild in sachen den kubernetes jammel
eintragen apply ja kein ding aber dieses ganze zeug was hier noch dabei kommt das ist halt
extrem viel was es da gibt ja autodiscovery ja das sollten wir uns auch mal angucken ja ja genau
ne traffic prominent engine ich bin ich bin team engine ich habe traffic selbst auch schon
verwendet ich muss sagen ganz im ernst ich bleibe bei engine ich benutze kadi wenn super simpel
sein muss traffic von hand konfigurieren ist eh abfakt und traffic macht halt in so einem
umfeld hier schon irgendwie sinn weil es auch viele service discovery funktionen ganz ehrlich
aber es ist so easy in engine x ingress zu machen warum soll ich ja traffic verwenden
glaubt glaube ich einen bogen erst mal drum machen
ja
schreiben wir nochmal
dass wir uns das dann auch grafisch angucken können dahinter wenn euch noch was einfällt
könnt ihr ruhig auch im nächsten stream schreiben da können wir uns das noch angucken also wir
machen jetzt auf jeden fall erst mal weiter mit zert manager und environments und volumes und so
was im nächsten stream ist
ach du scheiße das ist nicht nice so nice jetzt fängt dieses wortling scheiße schon in deutschland
an oder was hat er seine adresse geleakt oder oder was war da mega für ein arsch man
ok leute ich wann machst du tiktok sein ja ich macht ich werd krasser kubernetes cloud native
influencer auf auf tiktok leute es ist fast 22 ich muss jetzt eh mal ins bett außerdem muss ich
mal ganz dringend kacken also das wird eine serie ja nicht unbedingt am stück nicht unbedingt am
stück jetzt kubernetes jeden stream bis wir mit allem durch den immer mal wieder machen wir machen
wir ja ok leute wir sehen uns dann bis denn zu
