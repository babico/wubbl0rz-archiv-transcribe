1
00:00:30,000 --> 00:00:58,560
da bin ich leute heute ist es soweit kubornitis kubornitis stream

2
00:00:58,560 --> 00:01:09,480
oder oder auch kubanitis oder kubanitis oder kubanitis oder was auch immer

3
00:01:15,480 --> 00:01:22,440
wir sind cool wir sprechen ja auch ubuntu nicht ubuntu aus sondern jubantu also sagen wir natürlich

4
00:01:22,440 --> 00:01:38,280
auch eindeutig auch kubanitis kubanitis das wird übrigens heute als es übrigens nicht

5
00:01:38,280 --> 00:01:45,720
sponsort bei hetzen oder so wir machen heute die sachen noch lokal und es wird erstmal auch nur

6
00:01:45,720 --> 00:01:51,760
horizontal skaliert heute ich weiß ich weiß das ist eigentlich nicht das performer mindset wie

7
00:01:51,760 --> 00:01:58,160
heißt das doch performer mindset oder wie heißt das shit high performer halt das nicht das high

8
00:01:58,160 --> 00:02:10,960
performer mindset es wird heute auch nicht der einzige stream sein dazu weil da gibt es einiges

9
00:02:10,960 --> 00:02:17,400
das ist eine fass ohne boden und es ist jetzt auch nicht so als bin ich zum aktuellen zeitpunkt

10
00:02:17,880 --> 00:02:25,000
der krasseste kubanitis experte den es auf diesem planeten gibt ich habe damit schon was gemacht ich

11
00:02:25,000 --> 00:02:30,120
habe die letzten tage auch so ein bisschen noch um probiert und ich habe schon mal in die deployment

12
00:02:30,120 --> 00:02:37,600
jammel gemacht und dann war es zum laufen gebracht und also ganz komplett ahnungslos bin ich nicht

13
00:02:37,600 --> 00:02:47,560
aber ich bin jetzt nicht der der der krasseste profi ever jetzt jetzt aber was machen wir

14
00:02:47,560 --> 00:02:57,920
ein bisschen ahnung haben verstehe nicht was ihr meint mit skalieren das wirst du dann im laufe des

15
00:02:57,920 --> 00:03:05,160
streams sehen was mit skalieren gemeint ist da wird hyperscaled wird da da kann man dann richtig

16
00:03:05,160 --> 00:03:21,160
schöne tolle cloud buzzwords draus machen die hyperscalenden cloud native container infrastructure

17
00:03:21,160 --> 00:03:31,640
es keine ahnung ja fast jeden tag wenn ich nicht stream abends

18
00:03:31,640 --> 00:03:39,280
mit den mit den gleichen leuten wieder näher ich bin auch am spiel ich habe gesehen du bist

19
00:03:39,280 --> 00:03:45,440
nicht über level 11 rausgekommen nicht so ging nicht so weit gatschi roll

20
00:03:45,440 --> 00:03:53,920
während der stream anläuft leute ich mache mal meine vm an wobei wir heute beim cool aussprechen

21
00:03:53,920 --> 00:04:01,200
ich mache meine vm an und ich mache mal ein update bevor wir jetzt hier großen großen kubanete

22
00:04:01,200 --> 00:04:06,200
stellt man ja also leute wir gucken uns das wir gucken uns das alles an also das wird jetzt nicht

23
00:04:06,200 --> 00:04:10,920
also wenn ihr jetzt erwartet wir machen jetzt hier kubanetes tutorial wie sagt man so schön

24
00:04:10,920 --> 00:04:19,600
from zero to hero wenn man cool sein will dann nennt man das sowas das machen wir nicht also ich

25
00:04:19,600 --> 00:04:22,840
erkläre euch ein bisschen was und ich zeige euch auch ein bisschen was und wir probieren ein paar

26
00:04:22,840 --> 00:04:29,160
sachen aus aber die sinne dieser streams ist ja auch einmal dass ich euch was zeigen kann und

27
00:04:29,160 --> 00:04:34,800
auch dass ich selbst besser kann das ist ja immer so 11 ich meine ich mache meistens nicht sachen wo

28
00:04:34,800 --> 00:04:39,760
ich komplett planlos bin aber wenn man die dann noch mal erklären muss dann ist natürlich immer

29
00:04:39,760 --> 00:04:44,360
ein bisschen schwieriger versteht selbst besser war ein paar träg horizontal skalieren ist doch

30
00:04:44,360 --> 00:04:48,160
mehrere maschinen hochfahren können zum skalieren oder vertikal ist mehrere leitungen freigeben

31
00:04:48,160 --> 00:04:55,920
ich bin mir ehrlich gesagt gar nicht so sicher ich glaube horizontal skalieren ist mehrere

32
00:04:55,920 --> 00:05:02,120
mehrere potts starten und vertikal skalieren ist mehrere notes hinzufügen

33
00:05:02,120 --> 00:05:12,280
keine ahnung bin ich bin ich so im hyper hyper scale high performance mindset

34
00:05:18,760 --> 00:05:28,680
ach du hast recht genau horizontal jaja ne ne stimmt doch mehr leistung mehr leistung ist ja

35
00:05:28,680 --> 00:05:34,240
im prinzip mehrere notes hinzufügen wobei du auch du musst gleichzeitig du musst gleichzeitig

36
00:05:34,240 --> 00:05:41,880
ein bisschen vertikal skalieren dass du besser horizontal skalieren kannst oder glaub da müssen

37
00:05:41,880 --> 00:05:45,520
wir mal eben business coach fragen wir uns das erklärt wie das wie das richtig funktioniert

38
00:05:49,160 --> 00:05:58,040
wir skalieren prinzipiell nur diagonal korrekt das ist richtig das haben wir schon vor eine

39
00:05:58,040 --> 00:06:03,160
weile festgestellt dass für uns diagonal skalieren das beste ist dann musst du dich nicht mit mehr

40
00:06:03,160 --> 00:06:13,440
mit so komischen noobkack abgeben wie ob das jetzt vertikal oder horizontal oder y-achse x-achse z-achse

41
00:06:13,440 --> 00:06:21,360
wir wir machen naja wie es skalieren diagonal dreidimensional also in alle drei dimensionen

42
00:06:21,360 --> 00:06:37,480
wird skaliert du brauchst mindestens fünf kuppernets cluster daheim dass du dass du

43
00:06:37,480 --> 00:06:45,560
dem kerl auf youtube konkurrenz machen kannst wir skalieren sogar runter das ist richtig wir

44
00:06:45,560 --> 00:06:49,720
skalieren tatsächlich heute auch runter wir skalieren mal container von 8 auf 4 zurück

45
00:06:49,720 --> 00:06:57,920
und so was ich war mal kurz bevor es richtig los geht aber kurz den ganzen schitt hier zu

46
00:06:57,920 --> 00:07:04,800
das haben wir hier noch swelt zeug alles weg ich war mal kurz ein update und dann starte ich mal

47
00:07:04,800 --> 00:07:12,240
die vm neu dass es auch was wird hier dass wir top aktuelles kubernetes machen können

48
00:07:12,240 --> 00:07:24,640
autokonale skalierung was kommt man was kommt dann als als nächstes parallelogramm skalierung

49
00:07:24,640 --> 00:07:35,440
relativistische skalierung hätte ich noch zu bieten dann skalieren wir nicht nur in

50
00:07:35,440 --> 00:07:43,560
alle raumdimensionen sondern auch zeitlich was was haltet denn davon dass man kann das

51
00:07:43,560 --> 00:07:50,400
beck was wird moment was so warum kompiliert er gerade in den schitt was macht er da 7 zipp

52
00:07:50,400 --> 00:07:59,000
ich habe was viel ich zeige euch mal kurz was bevor wir kubernetes anfangen ich habe

53
00:07:59,000 --> 00:08:04,360
was was ein cooles projekt auf github gefunden wenn man keinen bock auf 7 7 zipp gedürnt

54
00:08:04,360 --> 00:08:17,200
hat unter linux nenn sich pzip das ist das macht alle möglichen formate unter anderem auch 7 zipp

55
00:08:17,200 --> 00:08:26,560
und und es hat ein gui dabei einfach 8 zipp nehmen ja das ist schon ganz schön 6 hat ich

56
00:08:26,560 --> 00:08:37,400
habe ich ok leute ich ich muss mal kurz was zum ich muss mal kurz 7 zipp entfernen brauche ich

57
00:08:37,400 --> 00:08:44,720
erinnert so und dann zeige ich euch mal was wir heute vor haben beziehungsweise was ansteht das

58
00:08:44,720 --> 00:08:53,240
ist vielleicht nicht das alte 7 zipp näher so alt ist es nicht ist es last week geabdeut

59
00:08:53,240 --> 00:09:04,200
updated oder doch was ist die letzte version 9.1 ist doch gut alles sogar für die ganzen cute

60
00:09:04,200 --> 00:09:17,240
cutie chats chatter also ich wollte noch ein update machen gut lassen wir den erst mal

61
00:09:17,240 --> 00:09:28,560
updaten also um was geht es heute ich versuche jetzt mal so ganz grob mal auszuholen ja erinnert

62
00:09:28,560 --> 00:09:35,800
sich noch eine an zipp drives die hat mit zipp an sicher nichts zu tun das war eher so halt das

63
00:09:35,800 --> 00:09:43,680
zipp so weiß gar nicht warum die so heißen vom geräusche oder so zipp drive ja iomega zipp

64
00:09:43,680 --> 00:09:51,880
drive da wurde nichts gezippt immer eine 100 mb diskette war damals schon richtig krasser shit

65
00:09:51,880 --> 00:09:59,200
wenn die normalen disketten hatten wie viel 1,44 mb oder 1,2 ich glaube es gab drei disketten 800k

66
00:09:59,200 --> 00:10:08,360
1,2 und 1,44 oder so was gär war es gab war das nicht so ne 3,4 gab es nicht das ja gut vielleicht

67
00:10:08,360 --> 00:10:15,840
später mal aber ich kenne also die 1,44 waren glaube ich die verbreiteten wie ist ja dass ich

68
00:10:15,840 --> 00:10:20,360
mich da dass ich mir damals wieder krasse heckermann vorgekommen bin ich habe alte disketten vom

69
00:10:20,360 --> 00:10:27,800
amiga genommen das waren ja auch so floppy floppy disk floppy disk und dann habe ich die in mein pc

70
00:10:27,800 --> 00:10:33,320
laufwerk reingesteckt und dort unter windows rechts drauf geklickt und gesagt formatieren und dann

71
00:10:33,320 --> 00:10:38,400
hatte ich auf einmal ganz viele leere disketten weil ich die amiga dinger recycelt habe und da

72
00:10:38,400 --> 00:10:43,680
habe ich boah da habe ich mich richtig geil gesagt mann bin ich bin ich geiler hier heckermann ich

73
00:10:43,680 --> 00:10:51,240
habe quasi disketten aus dem nichts erschaffen dabei waren das ja ganz normale floppy disk

74
00:10:51,240 --> 00:10:57,240
halt für den amiga das habe ich nicht habe ich damals nicht gecheckt also ja amiga gescaled

75
00:10:57,240 --> 00:11:12,000
genau so update ist durch update ist durch ich glaube es war ein kernel update dabei

76
00:11:12,000 --> 00:11:20,840
deswegen reboote ich mal 5x dankeschön für den sub ich habe oben übrigens glaube ich noch

77
00:11:20,840 --> 00:11:31,240
ein übersehen stripes dann wieder subscrib poggers danke für die subs leute so dann starten wir mal

78
00:11:31,240 --> 00:11:54,520
das verdammte spiel und jetzt kann ich sag guck mal ne das war ja kein bock auf krasse giga chat

79
00:11:54,520 --> 00:12:05,640
aussprache jetzt kann man damit anfangen das ketten war das stimmt das ketten war schon cool

80
00:12:05,640 --> 00:12:17,480
dass sie der klick zu dieses klick dieses hatte schon was nutzt du zsh ja mache ich und wenn ja

81
00:12:17,480 --> 00:12:29,120
welches theme ist das das ist gar kein theme das ist also du meinst jetzt mein termin oder

82
00:12:29,120 --> 00:12:35,560
wirklich hier den prompt von der shell ich vermute mal weil du zell das was meinst du den prompt

83
00:12:35,560 --> 00:12:43,960
also der prompt ist starship allerdings ein custom meister ein custom meister ein

84
00:12:43,960 --> 00:12:49,600
custom meister starship prompt wenn du den prompt sehen willst gehst du hierhin auf

85
00:12:49,600 --> 00:12:59,280
wuppe loss dot files config starship und da siehst du das ich habe den base prompt genommen von

86
00:12:59,280 --> 00:13:06,360
starship du musst du noch sagen ob du wirklich shell oder terminale meinst weil terminale ist

87
00:13:06,360 --> 00:13:17,920
anders so und ich habe dieses preset genommen von starship pastel powerline was wiederum selbst

88
00:13:17,920 --> 00:13:25,280
auf m365 princess basiert das habe ich genommen und habe ein paar customized sachen angepasst ja

89
00:13:25,280 --> 00:13:30,720
zum beispiel habe ich die schrift gemacht wie mein hintergrund ich habe hinzugefügt dass wenn

90
00:13:30,720 --> 00:13:37,560
man in ein dotnet projekt geht die versionen da stehen und so was ich habe es auch zweizeilig

91
00:13:37,560 --> 00:13:43,680
gemacht weil ich zweizeilige prompts persönlich viel besser finde als einseilige prompts ja aber

92
00:13:43,680 --> 00:13:54,600
es ist etwas ist das hier aber angepasst und du kannst findest das hier ach du kacke das ist wild

93
00:13:54,600 --> 00:14:02,120
ja das ist das ist aber wahrscheinlich noch neuer oder fast so alt wie unsere cobalt

94
00:14:02,120 --> 00:14:09,840
geschichten die bei uns laufen wo ich mich auch immer frage wo finden die immer noch

95
00:14:09,840 --> 00:14:28,200
leute die den kram können wir zeit wird zeit für linux upgrade und dann das ganze einfach in

96
00:14:28,200 --> 00:14:40,480
free doors laufen lassen oder oder oder noch besser wine im docker container im container

97
00:14:40,480 --> 00:14:46,720
weiß gar ob das gescheit funktioniert ja warum eigentlich nicht ja aber das will man ja

98
00:14:46,720 --> 00:14:50,880
wahrscheinlich nicht weil man so altes zeug hat dass es stabil läuft ob das mit wine dann

99
00:14:51,480 --> 00:14:56,800
also was machen wir heute

100
00:14:56,800 --> 00:15:07,800
wo fange ich denn jetzt am besten an leute wo fangen wir am besten an

101
00:15:07,800 --> 00:15:17,440
serverschrank 24 wieso klingt auch ganz normal anbieter hört sich halt bisschen

102
00:15:17,440 --> 00:15:24,360
oldschool an aber warum warum ich klingt auch klingt auch ganz normal

103
00:15:37,800 --> 00:15:53,240
berat uns doch erstmal ob kubernetes native stellt oder mini cube zum ausprobieren

104
00:15:53,240 --> 00:15:58,840
reicht das lokal voll und ganz ach ja ich weiß wo ich anfangen ich weiß wo ich anfangen und zwar

105
00:15:58,840 --> 00:16:07,680
dass wir es heute nicht der einzige kubernetes stream und zwar wir machen da mehrere ich weiß

106
00:16:07,680 --> 00:16:10,880
nicht inwieweit da bin ich wieder unschuldig weiß ich inwieweit das alles so aufeinander

107
00:16:10,880 --> 00:16:17,680
aufbauen wird wahrscheinlich kein raspberry pi cluster wahrscheinlich schon in gewisser

108
00:16:17,680 --> 00:16:22,480
weise wir machen aber nicht immer so exakt die gleichen beispiel und zwar also wir brauchen

109
00:16:22,480 --> 00:16:26,280
mehrere wir brauchen mehrere streams jena es hängt auch ein bisschen davon ab wie weit wir

110
00:16:27,280 --> 00:16:36,000
aber es wird auf jeden fall auch aus praktischen gründen mehrere streams geben das erste ist

111
00:16:36,000 --> 00:16:40,520
wir setzen uns damit lokal mal ein bisschen auseinander wir müssen nicht gleich in die

112
00:16:40,520 --> 00:16:49,920
cloud in der cloud irgendwas bauen das nächste ist wir gucken uns google cloud kubernetes an

113
00:16:49,920 --> 00:16:55,480
warum gucken uns google cloud kubernetes an weil dort wo ich am 1. april anfange zu arbeiten die

114
00:16:55,480 --> 00:16:59,560
alle google cloud verwenden ich weiß nicht warum das sind die einzigen die ich kenne die google

115
00:16:59,560 --> 00:17:07,520
cloud benutzen aktuell wo ich bin ist es ist es quasi fast nur ausschließlich azure ich

116
00:17:07,520 --> 00:17:12,920
habe schon ein bisschen was mit aws ich fasse nicht schon ein bisschen was privat gemacht mit

117
00:17:12,920 --> 00:17:18,720
google und mit aws würde ich sagen aber abstand am wenigsten aber ich kenne außerdem niemand der

118
00:17:18,720 --> 00:17:22,840
im professionellen umfeld google cloud verwendet gibt es allerdings genug nur weil ich keine

119
00:17:22,840 --> 00:17:28,880
kenne heißt das nix weil ganz einfach ich kenne nicht so viele läden von innen die

120
00:17:28,880 --> 00:17:32,240
paar handvoll da die ich gesehen habe die haben keine google cloud verwendet gut es heißt ja

121
00:17:32,240 --> 00:17:37,320
nichts erfolgreich ist es trotzdem und ich habe mir ein paar videos angeguckt und angeblich ist

122
00:17:37,320 --> 00:17:45,640
dass dieses autopilot kubernetes management feature von der google cloud wohl über diesen

123
00:17:45,640 --> 00:17:49,840
anwendungszweck am besten dann betreibst du nämlich gar kein kubernetes cluster mehr selbst in der

124
00:17:49,840 --> 00:17:55,440
google cloud sondern kannst direkt pots deployen und die scaling und managen das für dich aber

125
00:17:55,440 --> 00:17:59,160
natürlich machen wir damit nicht fangen wir damit nicht gleich an weil das ist ja langweilig

126
00:17:59,160 --> 00:18:05,160
muss erst mal ein bisschen so die grundlagen uns angucken dass man weiß wie das funktioniert

127
00:18:05,160 --> 00:18:09,280
weil nur was man macht von hand zumindest ich so ein bisschen selbst angeguckt hat blickt man

128
00:18:09,280 --> 00:18:11,720
dann auch durch was man besser sein lassen sollte

129
00:18:20,840 --> 00:18:27,360
ja deswegen gibt es mehrere streams wir machen wir wir gucken uns jetzt erst mal wir gucken uns jetzt

130
00:18:27,360 --> 00:18:38,200
erst mal das ganze lokal an da machen wir mal so ein setup aus irgendwie so eine 5 5 pots als

131
00:18:38,200 --> 00:18:45,840
application server mit einem load balancer und einem ssl zertifikat oder so mit ingress controller

132
00:18:45,840 --> 00:18:56,880
davor wir holen uns auch echte let's encrypt zertifikate über let's encrypt also echte

133
00:18:56,880 --> 00:19:15,520
echte ssl zertifikate über let's encrypt mit zert manager und was machen wir sonst noch wir

134
00:19:15,520 --> 00:19:22,920
machen den lokalen registry für container images und konfigurieren halt das deployment und den

135
00:19:22,920 --> 00:19:27,960
service gucken uns das alles mal ein bisschen an ist der moogame dankeschön für den snap

136
00:19:27,960 --> 00:19:38,200
was hältst du von IT zertifikat kommt ein bisschen auf die zertifikate an aber allgemein gesagt nicht

137
00:19:38,200 --> 00:19:47,520
ganz so viel ja ich würde sagen wir fangen mal relativ easy an ah ja und übrigens ich habe

138
00:19:47,520 --> 00:19:54,160
schon ein bisschen was vorbereitet wo ich abgucken kann also das ist jetzt nicht fix und fertig aber

139
00:19:54,160 --> 00:19:57,560
ich habe mir so ein paar kleine snippets raus kopiert falls ich jetzt im stream nicht direkt

140
00:19:57,560 --> 00:20:02,280
drauf komme weil alles auf den kopf weiß ich da auch nicht was hältst du von lpix also das

141
00:20:02,280 --> 00:20:08,400
was ich bisher gesehen habe sah sehr nach man pages aus wenn ich lerne aus aber kann auch kann

142
00:20:08,400 --> 00:20:19,520
mich auch täuschen wir verwenden kein windows server doch klar ich mache immer windows server

143
00:20:19,520 --> 00:20:25,880
windows server ist eindeutig die überlegene technologie deswegen läuft ja auch 90 prozent

144
00:20:25,880 --> 00:20:33,640
des internets auf linux guck hier ja was sonst verstehe ich auch die frage gar nicht was denn

145
00:20:33,640 --> 00:20:53,680
sonst gibt es noch was anderes windows server und powershell und es auf final auf was aber

146
00:20:53,680 --> 00:21:00,440
finals ist gerade irgendwas ich habe überhaupt nichts mitgekriegt cs go ist gerade glaube ich

147
00:21:00,440 --> 00:21:14,480
also wenn die windows server skalieren bist du nicht arm wenn die oracle datenbacken skalieren

148
00:21:14,480 --> 00:21:21,360
dann bist du arm wobei ne ne das stimmt nicht wir können es anders machen wenn die windows

149
00:21:21,360 --> 00:21:25,960
server skalieren bist du arm wenn die oracle datenbanken skalieren da kannst du gleich insolvenz

150
00:21:51,360 --> 00:22:04,560
weil ich weiß was ich machen muss um das problem zu fixen jetzt ist nur die frage möchtest du auch

151
00:22:04,560 --> 00:22:14,360
wissen wie man das problem fixt was muss man denn machen also die grundvoraussetzung ist schon mal

152
00:22:15,360 --> 00:22:23,800
das ist schon mal essentiell und dann zeige ich dir auch dass du gtkmm oder wie das heißt installieren

153
00:22:23,800 --> 00:22:38,600
musst das da musst du installieren und dann funktioniert probier mal aus das musst du

154
00:22:38,600 --> 00:22:47,400
installieren und dann startet die kiste am besten mal neu oder oder den system d service neu starten

155
00:22:47,400 --> 00:22:51,880
den hast ja bestimmt gestartet und so was aber das ding musste installieren diese library ist

156
00:22:51,880 --> 00:22:56,000
pflicht sonst funktioniert copy und paste nicht warum das keine dependency ist und warum das

157
00:22:56,000 --> 00:22:59,880
nirgendwo steht ich habe keine ahnung aber du brauchst diese library sonst geht copy und paste nicht

158
00:23:00,880 --> 00:23:14,280
gtk mm3 warum weiß nur vmw so also wir uns jetzt mal hier das kubernetes kubernetes vielleicht

159
00:23:14,280 --> 00:23:20,600
was sagen die denn was sagen die denn selbst ja das das trifft es eigentlich ganz gut ich

160
00:23:20,600 --> 00:23:26,320
wollte sagen kubernetes ist ein tool zur container orchestrierung aber das sagen sie ja selbst also

161
00:23:26,320 --> 00:23:34,000
für alle was genau wird heute mit kubernetes gemacht also erst mal erkläre ich kurz was

162
00:23:34,000 --> 00:23:45,680
kubernetes ist kubernetes ist quasi so was wie docker nur geclustert und mit wie wir klären

163
00:23:45,680 --> 00:23:55,320
das am besten es ist es ist so was wie docker nur verteilt über mehrere server ich glaube

164
00:23:55,400 --> 00:24:02,040
das kann man eigentlich am besten glaube das umschreibt eigentlich am ehesten ne du kannst

165
00:24:02,040 --> 00:24:06,120
auch einen server nehmen du kannst auch einen server nehmen aber für einen server macht es

166
00:24:06,120 --> 00:24:13,320
halt wenig sinn hochverfügbares docker ja ich glaube ich glaube dass das trifft eigentlich

167
00:24:13,320 --> 00:24:19,640
ganz gut sie sagen ja selbst sie sind ein ein orchestrierungstool für container infrastruktur

168
00:24:19,640 --> 00:24:25,960
also du kannst damit deine container in deine container verwalten du kannst damit zum beispiel

169
00:24:25,960 --> 00:24:32,360
einstellen dass du für einen ich nenne es mal service auch wenn die kubernetes service was

170
00:24:32,360 --> 00:24:39,280
anderes ist das wird eine pains champ reihe nur so so schlimm so schlimm ist es auch das einzige

171
00:24:39,280 --> 00:24:45,760
problem an kubernetes ist so zumindest wie ich das sehe also was vom lernen her dass es ein fass

172
00:24:45,760 --> 00:24:50,800
ohne boden ist es gibt 30 milliarden tools fünf tools für die gleichen sachen jede woche spawn

173
00:24:50,800 --> 00:24:56,400
irgendein neues tool die einfachsten sachen werden teilweise super krass verkompliziert

174
00:24:56,400 --> 00:25:06,280
aber insgesamt ist es an sich an sich ist das doch eine coole sache ja also was du das meinst ja

175
00:25:06,280 --> 00:25:13,040
also was du damit zum beispiel machen kannst mal ganz simpler use case ja du hast drei server

176
00:25:13,040 --> 00:25:22,320
und möchtest also du willst ein webservice anbieten willst webservice anbieten und du willst dass das

177
00:25:22,320 --> 00:25:29,720
ganze möglichst verfügbar ist und du willst dass das ding im laufenden betrieb geupdatet werden

178
00:25:29,720 --> 00:25:37,120
kann und du willst dass das auch je nachdem wie viel user gerade drauf sind ordentlich performed

179
00:25:37,120 --> 00:25:42,120
oder eben auch skaliert wie man so schön nennt dann ist kubernetes genau das richtige weil du

180
00:25:42,160 --> 00:25:46,840
kannst kubernetes nehmen stellst dir verschiedene notes hin heißt das bei kubernetes also verschiedene

181
00:25:46,840 --> 00:25:53,880
server notes sind bei kubernetes in der regel die unterschiedlichen server in einem cluster also

182
00:25:53,880 --> 00:26:00,720
cluster member sind quasi notes bei kubernetes das muss ich zwangsläufig eine hardware kiste

183
00:26:00,720 --> 00:26:07,080
sein das können auch vor ems sein der neueste schrei ist sowas wie kubernetes auf firecracker

184
00:26:07,080 --> 00:26:11,400
vor ems wenn man das jetzt mal hört und jemand weiß nicht was es ist er denkt jetzt erst mal was

185
00:26:11,400 --> 00:26:17,240
zum teufel will er von uns das machen wir heute nicht ich weiß nicht ob wir es überhaupt im

186
00:26:17,240 --> 00:26:22,920
stream machen ist auch was ganz ganz ab abgedrehtes das sind minimal vms firecracker das ist glaube

187
00:26:22,920 --> 00:26:29,560
ich von glaube das ist von amazon ich bin mir nicht ganz sicher ich glaube von amazon so

188
00:26:29,560 --> 00:26:41,160
eine minimal vm kubernetes selbst ist für container workload und der kubernetes cluster besteht

189
00:26:41,160 --> 00:26:46,200
aus unterschiedlichen notes in der regel ist es halt ein server jeder note das kann natürlich

190
00:26:46,200 --> 00:26:51,240
auch ein server sein worauf dann mehrere vm sind kann es kann es quasi auch sein kubernetes cluster

191
00:26:51,240 --> 00:26:57,600
in mehreren vmst auf einem eskserver laufen betreiben was auch immer oder theoretisch kannst

192
00:26:57,600 --> 00:27:01,920
das ding auch über mehrere cloud anbieter spannen wie dem auch sei da bist du sind ja

193
00:27:01,920 --> 00:27:08,040
deine kreativität keine grenzen gesetzt wie du das ganze aufbauen willst zumindest hast du dann

194
00:27:08,040 --> 00:27:14,200
den vorteil dass du so schöne sachen machen kannst wie es gibt ein das machen wir übrigens heute wenn

195
00:27:14,200 --> 00:27:20,680
wir so weit kommen du hast eine neue anwendungsversion und möchtest jetzt was deine anwendung läuft zur

196
00:27:20,680 --> 00:27:30,120
zeit auf version 1 und du willst jetzt auf version 2 und dann kannst du den config file editieren du

197
00:27:30,120 --> 00:27:34,520
kannst darüber kommandos teile machen aber in der regel macht man über config jammels dann

198
00:27:35,120 --> 00:27:39,480
ich will jetzt die version 2 von diesem moment ist an der tür

199
00:27:51,480 --> 00:28:00,720
hat mich abgelenkt also wenn du keine ahnung davon hast und wenn euer online shop so funktioniert

200
00:28:00,720 --> 00:28:04,440
dass nur ein service ist da brauchst wahrscheinlich kein kubernetes cluster wie gesagt man muss es

201
00:28:04,760 --> 00:28:10,760
man muss es auch nicht übertreiben manchmal tut es ohne probleme 123 vms und reverse proxy

202
00:28:10,760 --> 00:28:15,480
für ssl davor also es muss nicht sein da ist schon da ist schon ihr werdet wahrscheinlich

203
00:28:15,480 --> 00:28:20,040
so im lauf des streams ein bisschen an an klingen sehen da ist schon auch wenn es erstmal easy

204
00:28:20,040 --> 00:28:26,600
aussieht eine gehörige portion komplexität drinne gar nicht so sehr in den reinen basis funktionen

205
00:28:26,600 --> 00:28:32,760
von kubernetes sondern das gesamte ökosystem drum herum was es gibt ja wo bin ich jetzt stehengeblieben

206
00:28:32,760 --> 00:28:36,440
genau also du willst du hast ein service laufen du willst den service jetzt abqueren wessen von

207
00:28:36,440 --> 00:28:43,560
version 1 auf version 2 normalerweise wird es dann auf dich und vm einloggen neu pullen vm den service

208
00:28:43,560 --> 00:28:47,240
wieder starten was auch immer mit komponiert das geht es relativ einfach du gehst in den jammel

209
00:28:47,240 --> 00:28:52,560
feil machen wir heute auch alles jammel feil trägt die neue container image version ein das image

210
00:28:52,560 --> 00:28:58,280
bauste vorher irgendwo entweder lokal mit docker oder über jenkins oder github action so wie

211
00:28:58,280 --> 00:29:05,120
irgendwelche continues pipeline geschiss bauste dann image und pusht das in registry rein und

212
00:29:05,120 --> 00:29:09,920
dann trägst du dann im jammel feil ein ich will jetzt auf version 2 dann applies du diese konfig

213
00:29:09,920 --> 00:29:16,600
machen wir jetzt gleich alles dann applies diese konfig auf deinen kubernetes cluster und es

214
00:29:16,600 --> 00:29:27,440
skaliert dann automatisch also der reihe nach deine einzelnen container hoch also nicht skaliert

215
00:29:27,640 --> 00:29:34,040
der upgrade an der reihe nach deine einzelnen container ja richtig stripes genau so dass der

216
00:29:34,040 --> 00:29:47,040
service nicht ausfällt was ist der unterschied zwischen k8s und k3s ich glaube das eine ist

217
00:29:47,040 --> 00:29:52,320
irgendwie super leicht gewichtiges komponiert gibt es ein paar sachen es gibt ein paar sachen wenn

218
00:29:52,320 --> 00:29:57,560
man das ist zum beispiel was was du eher auf dem respiratory pie laufen lassen kann kannst

219
00:29:57,560 --> 00:30:01,920
das ist aber glaube ich soweit ich weiß 100 prozent api kompatibel zum großen kubernetes

220
00:30:01,920 --> 00:30:10,080
es gibt verschiedenste sachen für minimal kubernetes es gibt es gibt das originale kubernetes

221
00:30:10,080 --> 00:30:19,040
oftmals mit k8s abgekürzt gibt es auch null ks es gibt kind es gibt mini cube es gibt alle

222
00:30:19,040 --> 00:30:25,280
möglichen dinger total total viel sachen mini schiff feier cue war es auch immer alles wir

223
00:30:25,280 --> 00:30:33,440
nehmen heute mini cube wir nehmen heute mini cube weil es am einfachsten ist für mich mit

224
00:30:33,440 --> 00:30:44,120
mini cube lokal ein bisschen rum zu basteln so mini cube ist nahezu 100 prozent api kompatibel mit

225
00:30:45,120 --> 00:30:51,240
es kann halt einige sachen nicht ich kann euch aber nicht aus dem kopf sagen was es aber zum

226
00:30:51,240 --> 00:30:55,240
größten teil api kompatibel mit kubernetes und du kannst auch die ganz normalen kubernetes tools

227
00:30:55,240 --> 00:31:02,440
nehmen für für mini cube um damit lokal was auszuprobieren ist halt hauptsächlich gedacht

228
00:31:02,440 --> 00:31:14,320
für auf einer kiste lernen und üben mini cube wir machen jetzt mal ein eigenes wir machen jetzt

229
00:31:14,320 --> 00:31:23,600
mal ein eigenes verzeichnis dafür repose mk dir nennen wir es einfach mal sogar du brauchst

230
00:31:23,600 --> 00:31:38,640
noch cube ctl ne brauche ich nicht weil guck mal da ist es das ist mittlerweile bei mini cube

231
00:31:38,640 --> 00:31:45,320
dabei also was heißt dabei der lädt es im hintergrund runter aber trotzdem ich installier

232
00:31:45,320 --> 00:31:48,840
es trotzdem weil das braucht man normalerweise hast du schon recht

233
00:31:54,080 --> 00:32:01,120
plan der mission lernen ja also wie gesagt meine streams sind ja immer so so ein ding also ich

234
00:32:01,120 --> 00:32:05,320
mache meistens sachen wo ich selbst ein bisschen schon von ahnung habe aber nicht so krass den

235
00:32:05,320 --> 00:32:10,240
durchblick und dadurch dass ich das euch zeige und ein bisschen was erklären muss lernt man selbst

236
00:32:10,240 --> 00:32:23,080
besser das ist immer ganz gute kombination so sieht es aus jetzt können wir anfangen es ist

237
00:32:23,080 --> 00:32:29,200
relativ easy zu starten mit mini cube und zwar ihr braucht keine vm ihr braucht kein kubernetes

238
00:32:29,200 --> 00:32:35,160
installation und nix ihr sagt einfach mini cube start und jetzt macht ihr eine sache falls ihr

239
00:32:35,160 --> 00:32:45,240
das auch ausprobieren wollt macht ihr eine sache man muss mal kurz nachgucken insecure oder mir ist

240
00:32:45,240 --> 00:32:59,200
das insecure registry machte jetzt mini cube start ins insecure registry werdet gleich sehen warum

241
00:33:05,200 --> 00:33:10,600
jetzt leider kobe ne das geht uns runter und direkt best practice ist lokal es ist lokal

242
00:33:10,600 --> 00:33:28,280
übungs practice chat ihr werdet gedisst gerade im chat also quasi aber du bist auch teil des

243
00:33:28,280 --> 00:33:34,080
chats kommt eigentlich ein video zu dem mobil funk anbieter suchen was ich euch da erzählen soll

244
00:33:41,160 --> 00:33:50,520
so ach ja es gibt verschiedene nummer so der vollständigkeit vollständigkeit halber erwähnt

245
00:33:50,520 --> 00:33:59,240
es gibt verschiedene möglichkeiten mini cube zu betreiben die standard variante ist über

246
00:33:59,240 --> 00:34:06,400
irgendeinen virtualisierungs provider also meistens kvm also wenn ihr mini cube startet dann legt es

247
00:34:06,400 --> 00:34:14,360
normalerweise unter der haupe eine neue vm an wenn man keine vm anlegen möchte kann man das ganze

248
00:34:14,360 --> 00:34:20,040
auch selbst als container in docker laufen lassen ist ja kein ding ich mein kubernetes ist ja

249
00:34:20,040 --> 00:34:25,520
letztendlich tool zur container verwaltung warum sollte man das nicht auch selbst in

250
00:34:25,520 --> 00:34:33,160
dem container laufen lassen können also ihr seht ja hier ich habe keine vm installiert also ich

251
00:34:33,160 --> 00:34:37,920
habe hier keine virtualisierungsmöglichkeiten in der vm drin das heißt er lässt jetzt das back

252
00:34:37,920 --> 00:34:43,720
end einfach in einem eigenen docker container laufen also es ist jetzt quasi kubernetes in

253
00:34:43,720 --> 00:34:48,840
docker womit man eine weitere container verwalten gab es ist egal letztendlich muss man sich damit

254
00:34:48,840 --> 00:34:53,600
nicht beschäftigen das ist ja zum üben und die api und wie man das anspricht und so ist überhaupt

255
00:34:53,600 --> 00:35:00,200
kein unterschied also diese lokale lokale so entwicklungsumgebung mit mini cube können

256
00:35:00,200 --> 00:35:04,960
die genauso benutzen wie also die du brauchst keine extra sündung so ist quasi genau das

257
00:35:04,960 --> 00:35:12,480
gleiche wie fürs große kuppernet ist nur dass es lokal bei einem auf dem rechner läuft sagen

258
00:35:12,480 --> 00:35:18,360
mal logien halbist du irgendwie besoffen oder so ich kann dir nicht folgen was du für komisches

259
00:35:18,360 --> 00:35:28,000
teuch im chat schreibst die ganze zeit was was soll was soll uns das sagen lokal geschützt

260
00:35:28,000 --> 00:35:35,880
von meter alles klar written in rust container runtime nie kenne ich nicht ich kann nicht jede

261
00:35:35,880 --> 00:35:46,080
rust software kennen ich schreibe über mastadon schreibst du das einfach nur so oder schreibst du

262
00:35:46,080 --> 00:35:53,000
mit jemand ich glaube ich glaube du machst aktuell die taktik was ich auch manchmal mache alles was

263
00:35:53,000 --> 00:35:58,280
einem in den kopf fällt in irgendein text einkommen in irgendein text eingabe fällt tippen und enter

264
00:35:58,280 --> 00:36:07,040
drücken aber mach nur ich beschwer mich nicht alles interactions auf twitch wobei das war youtube

265
00:36:07,040 --> 00:36:13,960
wo das so wichtig ist ach ja und wir brauchen tatsächlich anscheinend doch nachher noch potman

266
00:36:13,960 --> 00:36:18,600
und so gucken wir uns an also wir haben mini cube gestartet wir können jetzt mal sowas machen wie

267
00:36:18,600 --> 00:36:26,400
cube ctl get ach nee ha sekunde leute lasst lasst euch nicht jebaden von irgendwelchen youtube

268
00:36:26,400 --> 00:36:33,000
tutorials oder sowas ich zeige euch jetzt mal wie das die ganzen youtube tutorial dudes machen und

269
00:36:33,000 --> 00:36:38,480
dann zeige ich euch wie man es richtig macht ok also die ganzen youtube nicht alle es gibt

270
00:36:38,480 --> 00:36:43,160
ein gut es gibt gute tutorials das beste deutschsprachige tutorial auf youtube was ich

271
00:36:43,160 --> 00:36:50,440
kenne dazu kubernetes ist also für leute die ein bisschen ahnung von linux und sich nicht

272
00:36:50,440 --> 00:36:56,840
vor kommando zeilen scheuen und relativ relativ ja schon ein bisschen bisschen background was

273
00:36:56,840 --> 00:37:04,400
container angeht haben das ist das beste also wenn wenn sich einmal wirklich in zwei stunden

274
00:37:04,400 --> 00:37:09,560
in zwei stunden gut strukturiert das kubernetes tutorial angucken will finde ich das persönlich

275
00:37:09,720 --> 00:37:15,720
auf deutsch finde ich das persönlich am besten ich könnte natürlich auch einfach dabei bleiben

276
00:37:15,720 --> 00:37:21,680
weil ich wir werden ja wahrscheinlich nicht alles machen was er im video macht aber in großteil und

277
00:37:21,680 --> 00:37:26,360
ihr könnt ja live auch noch was dazu beitragen und wir machen auch ein paar sachen die er so

278
00:37:26,360 --> 00:37:30,400
glaube ich nicht im video zeigt ich glaube es ist selbstwertig für karte über letzten

279
00:37:30,400 --> 00:37:33,880
krippen macht er im video gar nicht aber wenn mal einer sich in ruhe und tutorial angucken will

280
00:37:33,880 --> 00:37:47,640
ich finde das ist das beste so ja genau also ich zeige euch jetzt mal wie das die ganzen

281
00:37:47,640 --> 00:37:54,280
tutorial duz auf youtube und auch teilweise auf jude me und so machen wenn die kubanets

282
00:37:54,280 --> 00:37:58,440
kommandos oder generell wenn die kommando zeilen tools verwenden dann machen die so was hier guck

283
00:37:58,440 --> 00:38:11,600
jupe ctl get pots oder da machen sie so get events und solche dinger du siehst die typen

284
00:38:11,600 --> 00:38:17,640
in tutorial videos zum kurz ich drücke schon ins den ganzen krempel immer fünf mal tippen so

285
00:38:17,640 --> 00:38:23,600
nicht so nicht leute das ist das ist mist auch wenn man das in allen möglichen tutorials sieht das

286
00:38:23,600 --> 00:38:28,160
erste was man braucht ist und jeder linux admin wird wissen das erste was man braucht ist

287
00:38:28,160 --> 00:38:34,160
shell completion leute jetzt nicht unbedingt für minicube für minicube ist das relativ egal dann

288
00:38:34,160 --> 00:38:41,840
müssen wir nicht so viel machen aber für kubectl brauchen wir best completion mir hört das ist

289
00:38:41,840 --> 00:38:48,120
aktuell noch nicht der fall das geht noch nicht und wir wollen nicht nur einfach tab completion

290
00:38:48,120 --> 00:38:54,880
haben sondern wir wollen auch quasi ja kontext sensitive tab completion haben also wenn ich zum

291
00:38:54,880 --> 00:39:02,920
beispiel sage hier irgendwie describe potts oder ne pot genau describe nee nee quatsch nee das

292
00:39:02,920 --> 00:39:08,920
klappe kann ich so die ressource hinten dran schreiben blabla blub so und dann will ich dass

293
00:39:08,920 --> 00:39:14,840
das auto completed so und dazu gibt es folgendes kubectl jetzt muss ich mal überlegen wie das war

294
00:39:14,840 --> 00:39:27,760
completion zsh genau so kubectl bringt nämlich eine eigene completion definition für bash zsh

295
00:39:27,760 --> 00:39:31,280
und was noch

296
00:39:31,280 --> 00:39:42,280
best und zsh wahrscheinlich mit richtig nice so und das kann man dann in seine

297
00:39:42,280 --> 00:39:47,920
basher z eintragen die dann folgendermaßen aus muss bloß mal kurz seine zhsh wie auch immer

298
00:39:47,920 --> 00:39:59,440
shell konfig ich muss mal kurz gucken wo habe ich denn meine ach da da ist es doch muss doch

299
00:39:59,440 --> 00:40:17,800
unten irgendwie sein source und wie machen das jetzt so geht das einfach so bin ich gerade

300
00:40:17,800 --> 00:40:26,800
ein bisschen ich glaube ich glaube wir müssen es redirecten ich bin mir nicht ganz sicher ob

301
00:40:26,800 --> 00:40:36,960
das so funktioniert nein aber ich habe ich habe dings brauche ich nicht genau so ist gut

302
00:40:36,960 --> 00:40:47,320
ja genau und jetzt habe ich kubectl und guck mal tab tab jetzt habe ich autocomplete ja und

303
00:40:47,320 --> 00:40:56,480
ihr seht autocomplete hier endpoints autocomplete und der autocomplete jetzt quasi auch kontext

304
00:40:56,480 --> 00:41:01,600
sensitive infos so an der stelle gibt es halt einen endpoint der kubernetes heißt und den kann

305
00:41:01,600 --> 00:41:10,680
ich da eintragen jetzt kann ich zum beispiel describe irgendwie sowas wie hier da gibt es

306
00:41:10,680 --> 00:41:16,480
halt pots gibt es halt noch kein man kann auch sagen all namespaces dann zeigt er dann alle pots

307
00:41:16,480 --> 00:41:23,840
an die es gibt mal mal get pots dann erzähle ich mal ein bisschen so was zur zur benahmung wie

308
00:41:23,840 --> 00:41:29,640
kubernetes denkt dass man dinger nennen soll also das hier sind jetzt die laufenden container die

309
00:41:29,640 --> 00:41:35,120
wir zur zeit haben in unserem kubernetes cluster wobei das nicht stimmt wobei das nicht ganz

310
00:41:35,120 --> 00:41:44,200
richtig ist ich muss das ich muss das anders erklären also kubernetes ist zwar ein orchestrierung

311
00:41:44,200 --> 00:41:51,920
stuhl für container aber kubernetes arbeitet gar nicht auf container basis das klingt jetzt

312
00:41:51,920 --> 00:41:55,880
erst mal verwirrend aber wenn ich euch das ein bisschen genauer erklären wird es hoffentlich

313
00:41:55,880 --> 00:42:02,800
klarer und zwar das was somit kubernetes verwaltet sind zwar unter der haube container aber container

314
00:42:02,800 --> 00:42:10,000
werden in kubernetes zusammengefasst zu pots ein pot ist quasi so eine logische einheit wieviel

315
00:42:11,000 --> 00:42:24,600
du meinst wie viele notes mein cluster hat einen lokale vm gerade so also was wollte ich jetzt sagen

316
00:42:24,600 --> 00:42:36,200
genau kubernetes das kleinste mit dem kubernetes hantiert sind pots pots ist so die kleinste logische

317
00:42:36,200 --> 00:42:43,800
einheit die man die man mit kubernetes verwalten kann in der regel könnte man sagen dass ein pot

318
00:42:43,800 --> 00:42:49,520
so was wie ein container ist wobei das nicht stimmt ein pot ist quasi also ist quasi so der

319
00:42:49,520 --> 00:42:57,080
container für die container oder so dass so ist so die so die der rahmen oder so die kiste um die

320
00:42:57,080 --> 00:43:01,160
container klingt jetzt bescheuert kann man kann man echt schlecht beschreiben also ich erkläre

321
00:43:01,160 --> 00:43:08,440
ich mal zum beispiel warum man das braucht ich erkläre ich mal warum man das braucht und zwar

322
00:43:08,440 --> 00:43:14,560
mal angenommen du hast jetzt eine anwendung in die net anwendung die verpackst du in container

323
00:43:14,560 --> 00:43:22,080
image und die lässt du dann als pot laufen dann ist der pot genau ein container drin aber du

324
00:43:22,080 --> 00:43:27,520
könntest jetzt ja in diesem pot zum beispiel noch einen container für metriken haben oder noch

325
00:43:27,520 --> 00:43:37,360
ein container für secrets oder noch ein container für reverse proxy oder so was also könntest

326
00:43:37,360 --> 00:43:43,360
ja du könntest ja quasi damit die anwendung von als einheit funktioniert also ein docker

327
00:43:43,360 --> 00:43:51,920
compose file ist ein pot ja das kommt ungefähr hin wobei man sagen muss in so einem docker

328
00:43:51,920 --> 00:44:00,680
compose file definierst du ja auch mehrere logische services die du miteinander verbindest

329
00:44:00,680 --> 00:44:07,040
du kannst jetzt mit docker compose file auch eine datenbank reinschreiben ein application server

330
00:44:07,040 --> 00:44:11,120
und die dann miteinander verbinden das wird schon in einzelne pots machen das du würdest

331
00:44:11,120 --> 00:44:19,680
quasi nur sachen die logisch zusammengehören in ein pot packen ja also zum beispiel ein container

332
00:44:19,680 --> 00:44:32,160
für connection zu deinem secret store oder so was in der richtung also werd mal angenommen

333
00:44:32,160 --> 00:44:37,560
deine deine anwendung braucht api keys und sonstige geschichten die hast du nicht in

334
00:44:37,560 --> 00:44:42,680
einem kubernetes cluster sondern irgendwo extern liegen und du willst es auch nicht in kubernetes

335
00:44:42,680 --> 00:44:46,360
cluster integrieren dann kannst du dir noch einen zweiten container rein passen rein packen der

336
00:44:46,360 --> 00:44:49,600
nur dafür da ist diese secrets zeig mal wie ist denn dieses bild

337
00:44:57,120 --> 00:44:57,620
ja

338
00:45:03,760 --> 00:45:04,260
ja

339
00:45:07,840 --> 00:45:13,120
genau also das ganze nennt sich übrigens seit k wenn man noch mehrere container rein

340
00:45:13,120 --> 00:45:20,480
packt in so einen pot genau so was hier das ist das ist ein schönes beispiel das ist das

341
00:45:20,480 --> 00:45:27,760
ist ein schönes schönes beispiel ja aber aber chat gpt erklärt er nicht warum das ist ein

342
00:45:27,760 --> 00:45:33,160
schönes beispiel ja du hast zum beispiel deine anwendung die schreibt logs und jetzt willst

343
00:45:33,160 --> 00:45:40,160
du diese log files allerdings zu einem zentralen logserver schicken und die anwendung selbst kann

344
00:45:40,160 --> 00:45:44,160
kein syslog und hat auch keinen bock sich irgendwie mit logs am einsammeln dingern zu

345
00:45:44,160 --> 00:45:49,120
beschäftigen dann würdest du einen pot erstellen der enthält die anwendung und noch einen zweiten

346
00:45:49,120 --> 00:45:54,120
container der dafür da ist die logs einzusammeln und an irgendein zentrales log management system

347
00:45:54,120 --> 00:46:00,040
zu schicken das ist ein gutes beispiel ja du könntest zum beispiel noch einen dritten container

348
00:46:00,040 --> 00:46:07,320
dabei machen der metriken bereitstellt für prometheus monitoring oder so was hast du quasi eine logische

349
00:46:07,320 --> 00:46:13,520
einheit also das hier wäre dann quasi dein application server pot allerdings enthält er

350
00:46:13,520 --> 00:46:18,440
eben alle container in diesem pot die die anwendung braucht um ebenso als logische einheit

351
00:46:18,440 --> 00:46:25,360
gestartet werden zu können und das zu machen was sie machen soll eine datenbank wäre wiederum ein

352
00:46:25,360 --> 00:46:35,560
zweiter pot das ist eigentlich gar nicht so verkehrt was was ein bisschen doof ist an kuba

353
00:46:35,680 --> 00:46:46,600
die haben halt für alles irgendwelche gewöhnungsbedürftige bezeichnung ja container

354
00:46:46,600 --> 00:46:52,960
sind pots was schon irgendwie klar ist weil ein pot mehrere container enthalten kann du hast

355
00:46:52,960 --> 00:46:57,200
deployments da versteht jeder eigentlich was anderes darunter als irgendwelche komischen

356
00:46:57,200 --> 00:47:01,760
yaml files die pots definieren aber gut da muss man sich ein bisschen dran gewöhnen

357
00:47:02,520 --> 00:47:10,280
was phippe goes to the zoo cloud native computing foundation hat es kuba neta story moment

358
00:47:10,280 --> 00:47:19,520
jetzt lernen wir was ok pots hier hier werden pots erklärt

359
00:47:31,920 --> 00:47:34,040
ich verstehe den zusammenhang kann ich so genau

360
00:47:45,320 --> 00:47:49,160
ich verstehe den zusammenhang zwischen diesem bild und und potz nicht

361
00:47:49,160 --> 00:48:04,440
wie dem auch sei wir machen jetzt wir machen jetzt mal weiter man muss sich zumindest ein

362
00:48:04,440 --> 00:48:08,760
bisschen dran gewöhnen dass sie alles irgendwie irgendwie anders nennen

363
00:48:09,320 --> 00:48:21,680
und zwar ist es zum beispiel bei kuba neta ist auch so die nennen dort wo der traffic reingeht also

364
00:48:21,680 --> 00:48:27,000
quasi das was jeder normale mensch irgendwie reverse proxy nennt das nennen die ingress zum

365
00:48:27,000 --> 00:48:34,840
beispiel und das gegenteil von ingress also da wo der traffic quasi reingeht ist nicht etwa

366
00:48:34,840 --> 00:48:40,720
outgress sondern egress weil ist halt so

367
00:48:46,880 --> 00:48:52,200
und da gibt wie gesagt gibt gibt gibt noch mehr sachen wo ganz komisch benannt sind wo man sich

368
00:48:52,200 --> 00:48:57,000
einfach dran gewöhnen muss was genau ist minikub minikub ist ein tool wo du lokal

369
00:48:57,000 --> 00:49:04,600
bei dir kuba netas laufen lassen kannst zum üben also wir haben das ganze noch nicht gestartet doch

370
00:49:04,920 --> 00:49:09,640
also nachdem minikub installiert ist es ganz einfach über package manager oder als single

371
00:49:09,640 --> 00:49:14,080
binary runterladen es ist glaube ich auch in go programmiert als single binary runterladen

372
00:49:14,080 --> 00:49:19,320
starten dann startet ihr minikub am besten dass ihr noch hinten dran wenn ihr lokale

373
00:49:19,320 --> 00:49:24,160
container registry haben wollt und gut ist dann habt ihr minikub gestartet euer kuba netas läuft

374
00:49:24,160 --> 00:49:28,400
irgendwann mal läuft es dann

375
00:49:28,400 --> 00:49:35,240
und dann könnt ihr auch schon kommandos an euren kuba netas schicken und das ganze machen mit

376
00:49:35,240 --> 00:49:44,840
kubectl kubectl kubectl get pods zum beispiel so und man sieht hier schon folgendes das ist das wo

377
00:49:44,840 --> 00:49:53,720
ich gerade am wo ich gerade am erzählen gewesen bin ein port ist die kleinste logische einheit die

378
00:49:53,720 --> 00:50:03,800
kuba netas verwaltet kuba netas selbst oder in dem fall minikub selbst wenn du startest kommt

379
00:50:03,800 --> 00:50:09,840
schon mit ein paar vorinstallierten pods um die musst du dich nicht kümmern das ist es ja auch

380
00:50:09,840 --> 00:50:17,200
hier das ist im name space kube system und dort sind interne sind interne pods die man die das

381
00:50:17,200 --> 00:50:24,360
braucht dass es funktioniert was zum beispiel hier sowas wie core dns das ist das ist wichtig

382
00:50:24,360 --> 00:50:29,760
dafür dass die pods sich untereinander beziehungsweise auch die services aufgelöst

383
00:50:29,760 --> 00:50:36,080
werden können und im cluster selbst die dienste per namen angesprochen werden können und so was

384
00:50:36,080 --> 00:50:39,080
da muss man sich jetzt nicht so viel gedanken drüber machen aber damit kommt das halt also

385
00:50:39,080 --> 00:50:45,760
sprich man sieht hier laufen schon ein paar container was man hier auch schon sieht das

386
00:50:45,760 --> 00:50:52,440
brauchen wir später noch hier sieht man dass manche pods ready sind es ist so in kuba netas

387
00:50:52,440 --> 00:51:01,960
dass ein also in docker ist es so du startest das ding so und entweder es krascht oder es läuft

388
00:51:01,960 --> 00:51:10,920
aber so wirklich großartig wissen wann das jetzt ready ist und wann nicht tust du nicht

389
00:51:10,920 --> 00:51:14,800
ja du kannst den docker zwar einstellen dass er restarten soll wenn es krascht aber

390
00:51:14,800 --> 00:51:20,640
wann die webanwendung da drin gestartet ist und ich weiß nicht so und nachdem es in kuba netas

391
00:51:20,640 --> 00:51:28,200
ja unter anderem darum geht dass das ganze möglichst ausfallfrei läuft haben container

392
00:51:28,200 --> 00:51:30,840
oder pods muss man sagen sind da sind da keine container

393
00:51:30,840 --> 00:51:42,320
haben container verschiedene möglichkeiten zu überprüfen ob sie bereit sind da gibt es

394
00:51:42,320 --> 00:51:48,000
nämlich sowas was der andreas gerade schreibt es gibt so was wie readiness und leifnis da kann

395
00:51:48,000 --> 00:51:52,640
man dann wirklich health checks auf die container machen auf die pods machen und erst wenn die

396
00:51:52,640 --> 00:51:58,480
wirklich ready sind funktionieren also in dem fall dass ein web response web request durchgeht

397
00:51:58,480 --> 00:52:04,960
bei einer anwendung erst dann kommen die quasi in den ready state und der interne load balancer

398
00:52:04,960 --> 00:52:14,160
in kuba netas würde die dann ansteuern genau kompost kann auch so was in der richtung ja ich

399
00:52:14,160 --> 00:52:18,400
finde hier ist das jetzt das schöner gemacht so also mit was ich überlege gerade mit was wir

400
00:52:18,400 --> 00:52:22,280
anfangen wir machen uns erst mal eine leere datei nennen wir das einfach mal hier touch

401
00:52:22,280 --> 00:52:31,960
keine ahnung cute punkt jammel und machen wir wishell studio code auf ja wir

402
00:52:31,960 --> 00:52:38,520
trasten cute wir trasten nicht cute punkt jammel nope so jetzt können wir als erstes

403
00:52:38,520 --> 00:52:45,040
mal die kuba netas extension installieren ja ja reload mal die kuba netas extension ist

404
00:52:45,040 --> 00:52:54,960
nicht so dolle also ist ehrlich gesagt das einzige was ich von der kuba netas extension

405
00:52:54,960 --> 00:53:05,560
benutze ist das hier die janta jammel das jammel synthax autocomplete für kuba netas files so

406
00:53:05,680 --> 00:53:16,440
das nächste ist ein config file für kuba netas also so ein jammelfile hier das nennt sich wenn

407
00:53:16,440 --> 00:53:23,400
ich nicht ganz falsch liege manifest warum weil config datei zu dumm ist weil die das immer gerne

408
00:53:23,400 --> 00:53:29,880
ein bisschen fancy nennen was kuba netas angeht also ein jammel konfig datei für kuba netas

409
00:53:29,880 --> 00:53:36,560
nennt sich manifest und in so einem manifest kann man fast beliebig viele dinge reinschreiben die

410
00:53:36,560 --> 00:53:41,400
man konfigurieren will für seinen kuba netas cluster man kann wie gesagt man kann mehr als

411
00:53:41,400 --> 00:53:47,440
eins reinschreiben allerdings muss man sich immer überlegen man kann zwar jetzt auch gleich man

412
00:53:47,440 --> 00:53:55,200
kann diese datei immer nur im gesamten einlesen lassen von kuba netas also wenn ich da jetzt 20

413
00:53:55,200 --> 00:54:03,080
sachen drinne definiere und ich will dass kuba netas den kram übernimmt dann immer nur alles auf

414
00:54:03,080 --> 00:54:09,960
eimer wenn alles in einer datei drin steht also es macht durchaus sinn sachen die zusammengehören

415
00:54:09,960 --> 00:54:14,920
zusammen zu definieren also man könnte jetzt zum beispiel wobei da schreiten sich ja die geister

416
00:54:14,920 --> 00:54:22,800
darüber was man wie aufsplitten sollte in config files und ob man wie man es nennt und ob man für

417
00:54:22,800 --> 00:54:28,480
jeden dings in unterordner macht und dann ein eigenes jammelfile für service deployment was auch

418
00:54:28,480 --> 00:54:33,480
immer wir schreiben das jetzt erst einmal sinnvoll zum zum üben schreiben wir das jetzt erstmal

419
00:54:33,480 --> 00:54:41,760
alles in ein jammelfile also wir brauchen erstmal eine testanwendung würde ich sagen oder wir haben

420
00:54:41,760 --> 00:54:48,000
hier keine testanwendung wir machen man wir machen mal eine minimal dotnet testanwendung wobei da

421
00:54:48,000 --> 00:54:58,480
müssen wir einen container bauen und sowas hello world wir nehmen den hello world container da

422
00:54:58,480 --> 00:55:05,000
seht ihr auch schon mal gleich dass wie das aussieht wenn ein container crashed wir machen

423
00:55:05,000 --> 00:55:10,880
hello world hello world container der beendet sich nämlich da werdet ihr gleich sehen als kuba netas

424
00:55:10,880 --> 00:55:16,600
auch sagt das ding ist das ding läuft nicht mehr also deployment so sieht ein kuba netas deployment

425
00:55:16,600 --> 00:55:29,480
aus ich mache mal kurz die schriftgrößen ticken in ticken größer 18 aber wir waren sogar 20

426
00:55:29,480 --> 00:55:35,040
kommen dass man gescheit was sieht wunderbar also so sieht in deployment in kuba netas aus das ist

427
00:55:35,040 --> 00:55:42,520
das das ist das template was hier die studio add-on dabei hat also in deployment ist in kuba

428
00:55:42,520 --> 00:55:49,080
netas eine config die kuba netas sagt welche container es starten soll ganz platt gesagt

429
00:55:49,080 --> 00:55:54,080
leute ich glaube euch im chat dass ihr die super krassen kuba netas checker seid wahrscheinlich

430
00:55:54,080 --> 00:55:59,040
mehr als ich aber es hat keinen sinn wenn wir jetzt alle 800.000 kuba netas tools die es gibt

431
00:55:59,040 --> 00:56:05,800
immer wild durcheinander im chat schmeißen wie gesagt das ist ein unüberschaubare landscape an

432
00:56:05,800 --> 00:56:10,520
tools und sachen man könnte es auch man könnte man könnte auch gar kein manifest schreiben und

433
00:56:10,520 --> 00:56:14,960
man kann das manifest in python generieren das gibt es nämlich auch also wo wir gerade dabei

434
00:56:14,960 --> 00:56:18,920
sind hier man kann auch so was verwenden guck wenn man keinen wenn man keinen bock auf jammel hat

435
00:56:18,920 --> 00:56:26,080
kann man auch das komplett erstellen mit jeder x beliebigen programmiersprache was was haben

436
00:56:26,080 --> 00:56:30,680
die denn ich glaube python java und noch was aber das ist einfach zu viel auf einmal

437
00:56:41,520 --> 00:56:50,440
deswegen war jetzt erstmal jammel files und gucken uns das ganze an so also was gibt es

438
00:56:50,440 --> 00:56:58,280
denn so in einem deployment zu sehen erstmal in unseren namen ausdenken cute app super toll

439
00:56:58,280 --> 00:57:07,600
ich mache noch mal deployment cute app dann haben wir hier so sachen wie metadata das ist

440
00:57:07,600 --> 00:57:12,680
erstmal nicht so wild metadata kann man alles möglich reinschreiben es gibt übrigens auch

441
00:57:12,680 --> 00:57:23,880
noch annotations schwachsinn es gibt labels es gibt labels und es gibt annotations ich habe

442
00:57:23,880 --> 00:57:27,880
noch keine ahnung beziehungsweise ich habe ich habe noch nicht gecheckt wozu man annotations

443
00:57:27,880 --> 00:57:35,080
überhaupt braucht ehrlich gesagt außer dass manche ja nennen wir es mal third party tools

444
00:57:35,080 --> 00:57:41,160
gerne annotations benutzen normalerweise kommt man eigentlich mit labels mehr oder weniger aus

445
00:57:41,160 --> 00:57:48,600
kannst du den programm kurz kurz erklären es gibt noch gar kein programm code das ist das

446
00:57:48,600 --> 00:57:53,240
template was visual studio macht wenn ich deployment wenn ich deployment hinzufüge meiner

447
00:57:53,240 --> 00:58:01,880
kombiniertes config mehr gibt es da noch nicht also metadata das nennen wir mal cute app also

448
00:58:01,880 --> 00:58:08,440
quasi wie diese ressource ressource nennt sich das übrigens was angelegt wird also diese ganze

449
00:58:08,440 --> 00:58:16,320
datei nennt sich manifest und was hier angelegt wird ist glaube ich eine ressource und der typ

450
00:58:16,320 --> 00:58:25,320
der ressource ist in dem fall deployment damit eure jammel files auch garantiert immer funktionieren

451
00:58:25,320 --> 00:58:32,120
gibt es hier oben eine api version also das heißt mal angenommen die bringen version 2 irgendwann

452
00:58:32,120 --> 00:58:37,360
raus was viel viel mehr sachen unterstützt und hier oben immer noch api version 1 angegeben habt

453
00:58:37,360 --> 00:58:41,160
solange die version 1 weiter unterstützen funktioniert euer manifest auch weiter

454
00:58:41,160 --> 00:58:46,800
api version gibt es übrigens für für nahezu alle verschiedenen ressource typen

455
00:58:46,800 --> 00:58:57,480
so wir machen jetzt mal wir machen jetzt mal ein bisschen zackig da kannst du noch selektor

456
00:58:57,480 --> 00:59:03,320
und labels und so anlegen das ist wird gleich das wird gleich relevanter wenn wir da noch

457
00:59:03,320 --> 00:59:09,040
notbalancer und so was und so was da vorhängt so template metadata labels können wir auch so

458
00:59:09,040 --> 00:59:16,640
lassen cute app manifest v2 und v3 kann das war das in chrome ja sondern hier schreiben wir

459
00:59:16,640 --> 00:59:20,560
unser docker image rein beziehungsweise unser container image also immer einfach mal hello

460
00:59:20,560 --> 00:59:26,800
world dass du diese hello docker container dann kann man noch limits eintragen wie viel ram und

461
00:59:26,800 --> 00:59:32,160
cpu das verwenden darf ich kann euch ehrlich gesagt nicht genau sagen in welcher einheit die cpu ist

462
00:59:32,160 --> 00:59:40,240
das ist irgendwas irgendwas super super spezielles das ist nicht einfach nur anteile von einem cpu

463
00:59:40,240 --> 00:59:52,240
kern das sind irgendwelche megahertz sind nicht höchstwahrscheinlich nicht irgendwie irgendwie

464
00:59:52,240 --> 00:59:57,600
irgendwie cpu zeit oder sowas was auch immer das habe ich nicht so genau gecheckt was das jetzt für

465
00:59:57,600 --> 01:00:03,600
eine einheit ist zumindest ram ist relativ klar und man sollte auch limits angeben das ist sinnvoll

466
01:00:03,600 --> 01:00:10,840
weil wenn ihr meine anwendung habt mit memory leak dann frisst ihr euch im zweifelsfall euren

467
01:00:10,840 --> 01:00:15,040
kompletten note an ram voll wenn ihr da keine limits angegeben habt das heißt man sollte immer

468
01:00:15,040 --> 01:00:20,040
man kann durchaus großzügige limits angeben muss ja gar nicht sein aber ganz ohne limits ist meistens

469
01:00:20,040 --> 01:00:25,920
doof weil man kann das auch so einstellen beziehungsweise macht es automatisch man

470
01:00:26,000 --> 01:00:30,960
angenommen ihr habt memory leak und die anwendung wird immer größer immer größer immer größer und

471
01:00:30,960 --> 01:00:38,760
irgendwann nach einem gigabyte ram gerät es ans limit und kackt ab dann startet kuba netis

472
01:00:38,760 --> 01:00:42,000
die neu und dann läuft das ding wieder eine woche oder so was auch immer bis es wieder abkackt

473
01:00:42,000 --> 01:00:47,600
wegen memory leaks aber ganz ohne limits ist doof so container port tja geben wir einfach mal

474
01:00:47,600 --> 01:00:53,000
container port 80 ein wir haben kein container port weil dieses image kein port aufmacht so

475
01:00:53,000 --> 01:01:02,200
jetzt sagen wir mal kubectl deploy apply nicht deploy apply minus f cute wir machen hier unten

476
01:01:02,200 --> 01:01:15,040
mal was auf watch kubectl get pots ihr seht es gibt noch keine pots aber jetzt gibt es einen

477
01:01:15,040 --> 01:01:20,960
pot gibt es nämlich einen cute app pot und ihr seht das ding ist gleich wieder abgekackt

478
01:01:20,960 --> 01:01:29,960
weil es ist kein pot also das ist der standard docker hello world pot den ich hier gestartet

479
01:01:29,960 --> 01:01:36,760
habe der macht nichts anderes wie hello world ausgeben kuck docker run hello world der macht

480
01:01:36,760 --> 01:01:40,640
nichts anderes wie hello world ausgeben sich wieder zu beenden deswegen da hier guck hier

481
01:01:40,640 --> 01:01:46,520
deswegen funktioniert das natürlich nicht kuba neta sieht aha anwendung startet anwendung

482
01:01:46,520 --> 01:01:52,400
krascht kuba netas denkt die anwendung krascht weil die läuft ja nicht mehr und jetzt versucht

483
01:01:52,400 --> 01:01:58,760
er die neu zu starten und das krascht immer wieder doch doch der hat gepullt das geht das

484
01:01:58,760 --> 01:02:03,440
geht nur relativ relativ zackig das ist ja auch nichts nix dabei sind das docker image

485
01:02:03,440 --> 01:02:08,520
wofür muss man docker auch installiert sein nein du brauchst docker nicht installiert haben ich

486
01:02:08,520 --> 01:02:14,560
habe einfach bei mir lokal docker installiert und das sind streng genommen es sind docker images ja

487
01:02:14,560 --> 01:02:21,440
aber streng genommen sind docker images ja gar keine docker images mehr sondern sind oci images

488
01:02:21,440 --> 01:02:28,120
oder wie dieser kram jetzt heißt open container images also das ist was heißt ein oci open

489
01:02:28,120 --> 01:02:36,480
container image open container initiative image alles klar wäre auch zu einfach gewesen also das

490
01:02:36,480 --> 01:02:43,640
ist eine spezifikation von container images die auch docker verwendet aber mittlerweile auch ganz

491
01:02:43,640 --> 01:02:52,800
viele andere container tools aus dem container ökosystem also es muss kein docker image in

492
01:02:52,800 --> 01:02:59,840
dem sinn sein aber bietet sich jetzt in dem fall an so jetzt haben wir ein hello world container

493
01:02:59,840 --> 01:03:10,120
der niemals ready wird weil er immer krascht wie gesagt logisch weil naja macht ja macht ja auch

494
01:03:10,120 --> 01:03:18,480
nix der beendet sich auch einfach wieder so bevor wir ein netzwerk container starten können wir ja

495
01:03:18,480 --> 01:03:29,760
machen gut im eich traffic container traffic kurmei kommen wir mal starten wir bauen gleich noch eine

496
01:03:29,760 --> 01:03:34,280
kleine eigene dotnet anwendung das dauert zwei minuten doch jetzt sehen wir mal hier das zum

497
01:03:34,280 --> 01:03:42,600
beispiel traffic kurmei das ist was mit einem webserver wir applyen die datei wieder ihr erkennt

498
01:03:42,600 --> 01:03:47,760
ein gewisses muster wenn ihr schon mal beispielsweise euch den terraform stream

499
01:03:47,760 --> 01:03:51,880
angeguckt habt von mir das war ja oder generell wenn die terraform oder solche

500
01:03:51,880 --> 01:03:59,440
infrastructure management tools verwendet habt ihr erkennt ein gewisses muster es gibt

501
01:03:59,440 --> 01:04:05,680
eine config datei dessen state dann applied wird wobei man sagen muss terraform ist da etwas

502
01:04:06,680 --> 01:04:16,520
als die reinen kopernet des manifestes weil da werden teilweise nicht die states getrackt also

503
01:04:16,520 --> 01:04:21,240
wenn ich das hier jetzt umbenenne da kann es durchaus sein dass der pot weiter läuft

504
01:04:21,240 --> 01:04:32,560
so mal gucken zumindest jetzt starten wir mal anderen container so und wir sehen schon der

505
01:04:32,560 --> 01:04:37,200
alte container wurde gestartet und dann der neue container wurde gestartet der alte container wurde

506
01:04:37,200 --> 01:04:41,840
gestoppt ich nenne mal container es ist eigentlich ein pot steht man auch hier oben aber irgendwie

507
01:04:41,840 --> 01:04:46,720
kommt mir container einfacher von den lippen wurde gestartet und der scheint jetzt auch zu

508
01:04:46,720 --> 01:04:55,800
funktionieren denn da ist running der ist ab des abend running und das passt ja eigentlich so weit

509
01:04:55,800 --> 01:05:04,000
ganz gut jetzt muss man sich natürlich überlegen ok ich bin übrigens gar nicht sicher ob das

510
01:05:04,000 --> 01:05:10,040
ding standardmäßig auf pot 80 läuft das ist eine gute frage doch kann man probieren mal aus

511
01:05:10,040 --> 01:05:22,560
weiß ich gar nicht was macht das standardmäßig pot 80 ok alles klar dann ups na geil jetzt

512
01:05:22,560 --> 01:05:32,120
ha eine sache wo ich nicht weiß wie das in meinem neuen terminal geht wie switche ich die

513
01:05:32,120 --> 01:05:44,640
terminals jetzt lull einfach gar nicht aber irgendwie geht das ich war noch nie in der

514
01:05:44,640 --> 01:05:49,040
dass ich musste das noch nie ausprobieren so jetzt ist natürlich die sache gut wir haben

515
01:05:49,240 --> 01:05:55,000
wir haben jetzt ein pot laufen mit einem service drin auf pot 80 wir kommen da allerdings nicht

516
01:05:55,000 --> 01:06:01,840
dran also selbstverständlich mal karl lokal host oder so da geht nichts ich kann mir mal zum

517
01:06:01,840 --> 01:06:09,520
beispiel die mini cube ip angucken und dann kann ich sagen karl ip auf mini cube geht aber auch

518
01:06:09,520 --> 01:06:16,240
nett also der läuft zwar und wir wissen auch dass da was auf pot das wird funktionieren ja

519
01:06:16,240 --> 01:06:23,560
wir können wir können auch mini cube tunnel und so gedöns machen kann man alles machen aber man

520
01:06:23,560 --> 01:06:28,120
sieht der container ist nicht so wirklich erreichbar damit ein container erreichbar ist

521
01:06:28,120 --> 01:06:38,280
müssen wir erst einen service davor bauen einen service kann man sich so als art ja

522
01:06:38,280 --> 01:06:42,640
nie kann man nicht wirklich laut balancer kann man nicht so als eingang kann man nicht so als

523
01:06:42,640 --> 01:06:49,480
eingang zu diesem zu diesem zu diesen pots vorstellen so und jetzt kommt das was ich am

524
01:06:49,480 --> 01:06:56,000
anfang gesagt habe man kann in so einen kubernetes manifest nahezu beliebig viele ressourcen

525
01:06:56,000 --> 01:07:04,960
definieren und wir machen das jetzt zu übungszwecken so dass wir den service für dieses deployment also

526
01:07:04,960 --> 01:07:09,400
im prinzip für die anwendung hier unten drunter definieren ich finde das ich finde das an der

527
01:07:09,400 --> 01:07:14,320
stelle nicht verkehrt das gehört hier auch direkt zusammen das kann man kann man finde ich schon

528
01:07:14,320 --> 01:07:21,560
machen an der stelle da streiten sich tatsächlich da jetzt die geister dran wie man das macht und

529
01:07:21,560 --> 01:07:28,120
auch wie man das benennt ja ich kenne leute die machen ordner also gut ordner ist prinzipiell

530
01:07:28,120 --> 01:07:32,120
für einzelne anwendung nicht verkehrt machen ordner machen da drunter dann immer so was wie

531
01:07:32,120 --> 01:07:41,080
deployment extra service sonst wie manche machen auch eine datei mit dem namen von dem jeweiligen

532
01:07:41,080 --> 01:07:47,840
jeweilige anwendung dieser drin laufen lassen wollen und schreiben dann deployments und service

533
01:07:47,840 --> 01:07:54,400
in eine datei allerdings ingress in der anderen ist ein bisschen ist die musik zu laut wirklich

534
01:07:54,720 --> 01:07:57,920
passt doch eigentlich oder bin ich zu leise

535
01:08:03,720 --> 01:08:08,760
ich glaube die ist an sich einfach nur kratten bisschen sehr intensiv

536
01:08:08,760 --> 01:08:27,720
ok komm wir machen dass alle happy sind so jetzt ist es minimal leiser aber immer noch gut

537
01:08:27,720 --> 01:08:57,200
so also damit diese ports verfügbar sind oder wahrscheinlich müsste man eher sagen

538
01:08:57,200 --> 01:09:01,760
dass die pots aus diesem deployment verfügbar sind also nicht nur innerhalb des clusters sondern

539
01:09:01,760 --> 01:09:08,680
auch von außen muss man da ein service davon und service ist quasi so der eingang zu einem

540
01:09:08,680 --> 01:09:14,920
deployment denkt das kann man ganz gut sagen es gibt verschiedene möglichkeiten wie man

541
01:09:14,920 --> 01:09:23,560
services definieren kann also verschiedene typen von von services der in dem fall jetzt ganz

542
01:09:23,560 --> 01:09:28,120
praktische service wäre so was wie den load balancer zum beispiel weil wir machen auch gleich

543
01:09:28,120 --> 01:09:33,440
noch mehrere mehrere pots hier aktuell ist es ja nur ein potter läuft so also sagen wir jetzt hier

544
01:09:33,440 --> 01:09:40,480
mal service jetzt muss ich mal kurz überlegen meta meta metadata kann das gleiche sein das ist

545
01:09:40,480 --> 01:09:46,400
übrigens auch da streiten sich auch die geister dran ob das hier nicht irgendwie app heißen soll

546
01:09:46,400 --> 01:09:52,360
und das irgendwie service da kann man sich da kann man sich auch darüber streiten wie man das machen

547
01:09:52,360 --> 01:10:06,880
will so port port muss rein wo ich möchte dass dieser service erreichbar ist von außen in dem

548
01:10:06,880 --> 01:10:14,480
fall sagen wir auch mal pot 80 und taget port ist auch 80 kann man im kubernetes manifest auch

549
01:10:15,080 --> 01:10:21,600
ja klar warum nicht das ist ja ganz normal textart ganz normales jammel so das heißt wir legen

550
01:10:21,600 --> 01:10:30,000
jetzt ein service an auf port 80 der auf diesen service ich nenne es mal balance balance an der

551
01:10:30,000 --> 01:10:39,920
stelle oder nicht so und hier ist das entscheidende hier im selektor entscheidet man jetzt wohin dieser

552
01:10:39,920 --> 01:10:46,480
service seine requests weiter leitet also nur weil das in der gleichen datei drinne steht

553
01:10:46,480 --> 01:10:51,960
bedeutet es nicht automatisch dass das zusammen gehört also hier wo ich den selektor angebe

554
01:10:51,960 --> 01:11:09,320
selektor ab cute ab und ihr seht hier das hier ist ich vermute mal das hier ist das relevante

555
01:11:09,320 --> 01:11:22,680
zumindest hier drauf match der also der guckt danach was es für deployments gibt was es für

556
01:11:22,680 --> 01:11:30,560
pots gibt mit diesem passenden tag dazu und dann balance der da drauf also sprich ist es egal in

557
01:11:30,560 --> 01:11:42,080
welchen dateien die stehen also wir sagen wir wollen alle cute so und jetzt damit das

558
01:11:42,080 --> 01:11:47,720
ganze hier testweise funktioniert müssen wir noch ein typ angeben man sieht es gibt mehrere typ es

559
01:11:47,720 --> 01:11:53,320
gibt cluster ip ich glaube cluster ip ist der default wenn ich nicht ganz falsch liege

560
01:11:53,320 --> 01:12:05,720
so mal gucken ob ich das aus dem kopf halbwegs hinkriege also external name weiß ich jetzt gar

561
01:12:05,720 --> 01:12:11,160
nicht was heißt cluster ip hat heißt dieser service kriegt eine ip aus dem cluster zugewiesen

562
01:12:11,160 --> 01:12:20,720
also irgendeine ip aus der aus der cluster range not port bedeutet auf dem jeweiligen cluster knoten

563
01:12:20,720 --> 01:12:31,600
wo der container gerade läuft kriegt er kriegt er was zugewiesen und also random port zwischen

564
01:12:31,600 --> 01:12:43,200
30.000 und 35.000 oder so und in dem fall will ich load balance haben und jetzt applyen wir das

565
01:12:43,200 --> 01:12:48,560
ganze mal und dann hoffe ich dass ich nichts vergessen habe und der kram funktioniert

566
01:12:48,560 --> 01:13:00,400
so jetzt können wir zum beispiel hier unten mal sagen kubectl get service und man sieht da

567
01:13:00,400 --> 01:13:06,960
aha gucke mal da wir haben ein load balancer angelegt mit dieser cluster ip per external

568
01:13:06,960 --> 01:13:14,880
ip pending kann ruhig pendeln soviel es will und im port mapping das heißt wenn ich jetzt

569
01:13:14,880 --> 01:13:21,080
einen curl mache mini cube ip können wir uns merken wenn ich jetzt einen curl drauf mache

570
01:13:27,120 --> 01:13:29,440
da hätte ich jetzt eigentlich gedacht dass es funktioniert

571
01:13:29,440 --> 01:13:38,560
keck wait

572
01:13:55,040 --> 01:13:59,360
das geht mit mini cube ich habe das selbst so mit mini cube schon gemacht

573
01:13:59,840 --> 01:14:03,840
da hat ja auch eine klasse ne ne die klasse die klasse ip da müsstest du dich tunnen

574
01:14:03,840 --> 01:14:11,840
ne ne ne ne ne das funktioniert so glaube ich oder das ist immer jetzt jetzt jetzt lernen wir

575
01:14:11,840 --> 01:14:20,680
was okay wir probieren mal was aus braucht der lb nicht noch eine externe ip

576
01:14:20,680 --> 01:14:30,840
ne daten garten port mapping das sollte eigentlich

577
01:14:43,320 --> 01:14:48,600
ich meine wir könnten jetzt weiter gehen und noch noch den ingress davor machen aber

578
01:14:48,600 --> 01:14:51,800
sollte das nicht einfach so gehen jetzt

579
01:14:51,800 --> 01:15:01,280
ok ok also übrigens ich zeige mal dass hier das hier funktioniert an der stelle nicht ja

580
01:15:01,280 --> 01:15:07,400
die du kannst die dinger nicht erreichen du kannst aber zum beispiel sagen mini cube ssh

581
01:15:07,400 --> 01:15:15,640
und dann müsste es da drinne wahrscheinlich jetzt auch nicht

582
01:15:18,600 --> 01:15:23,640
ne ne ne ich brauche kein ingress wenn ich das hier ok mal gucken wir das mit cluster ip ist

583
01:15:23,640 --> 01:15:27,680
ich hätte jetzt eigentlich wecken können das funktioniert so egal probieren wir mal aus apply

584
01:15:27,680 --> 01:15:36,000
ja guck mal mal hier unten was er macht cluster ip das das wird das wird so natürlich auch

585
01:15:36,000 --> 01:15:40,840
nicht funktionieren ich bin mir das muss das muss mit laut balancer noch funktionieren

586
01:15:49,600 --> 01:15:54,840
ja not port können wir auch ausprobieren dass in dem fall ja immer immer das gleiche

587
01:15:54,840 --> 01:16:00,920
in dem fall macht es ja keinen unterschied ist ja immer der gleiche note

588
01:16:00,920 --> 01:16:11,000
mal irgendwas habe ich irgendwas habe ich verkehrt gemacht irgendwas ergibt gerade keinen sinn

589
01:16:19,600 --> 01:16:27,240
ich habe wir können weitermachen und den und den reverse proxy davor pappen

590
01:16:37,240 --> 01:16:44,000
ach ich weiß was ich mache was ich falsch mache ich benutze es doch auch falsch ich benutze es

591
01:16:44,480 --> 01:16:49,640
ich habe alles richtig gemacht ich habe alles richtig gemacht ich bin bescheuert also apply

592
01:16:49,640 --> 01:16:57,440
ist es stimmt alles passt mal auf es stimmt alles ich habe das nur falsch gemacht so

593
01:16:57,440 --> 01:17:05,120
natürlich die cluster ip ist ja nicht erreichbar intern deswegen muss ich jetzt folgendes machen

594
01:17:05,120 --> 01:17:19,000
mini cube service cute app und siehe da das service funktioniert da hätte ich drauf

595
01:17:19,000 --> 01:17:23,280
gemusst ich hätte ja auf die gemäbte auf den gemäbten port gehen müssen guck auf den port

596
01:17:23,280 --> 01:17:30,480
hätte ich gehen müssen der map der port 30.000 430 466 auf port 80 von dem von dem container

597
01:17:30,480 --> 01:17:38,280
so so ist richtig jetzt funktioniert so das ist das ist mein service der hier läuft

598
01:17:38,280 --> 01:17:50,080
das ist dieser hallo welt container von von traffic das ist der mini cube ip mit dem

599
01:17:50,080 --> 01:17:57,560
porter weitergeleitet wird ne load balance hast recht wahrscheinlich bräuchte ich das bräuchte

600
01:17:57,720 --> 01:18:01,160
das nicht wir können zwar wir können es mal weglassen und gucken ob es dann funktioniert

601
01:18:01,160 --> 01:18:16,360
nope siehst du funktioniert nicht notport würde funktionieren notport würde in dem

602
01:18:16,360 --> 01:18:24,080
fall wahrscheinlich auch funktionieren hallo mein gottes auto komplett wieder buggy ups

603
01:18:27,560 --> 01:18:36,320
ja das funktioniert auch also laut balancer braucht man an der stelle nicht wirklich

604
01:18:47,000 --> 01:18:51,680
und der service type notport auch externer ja das müssen wie gesagt ich will es ja da gar

605
01:18:52,280 --> 01:18:58,960
so zumindest man sieht das service funktioniert damit was man jetzt ja schon sieht was ein

606
01:18:58,960 --> 01:19:03,240
bisschen doof ist ich meine wer kann hier wer hantiert damit den dinger wer kann damit rum

607
01:19:03,240 --> 01:19:08,120
hantieren mit den ports und und so also ich meine woher will jetzt zum beispiel jemand der auf

608
01:19:08,120 --> 01:19:16,480
mein service zugreift woher will der wissen dass er das über port 3 2 2 5 9 machen muss das kann

609
01:19:16,480 --> 01:19:20,880
er nicht wissen so was man jetzt machen könnte ist man stellt das hier auf typ load balancer

610
01:19:20,880 --> 01:19:29,200
und mit einer wirklich externen erreichbaren ip dann müsstest du aber die jedes mal wenn

611
01:19:29,200 --> 01:19:35,560
du das über den cloud anbieter machst da müsste es müsste sich quasi über jedes mal müsstest du

612
01:19:35,560 --> 01:19:40,240
dann eine externe ip ressource anlegen in deiner cloud und hast dann am ende ganz viele externe

613
01:19:40,600 --> 01:19:46,680
viel sinnvoller ist es an der stelle so was wie ein reverse proxy davor zu pappen was wir auch

614
01:19:46,680 --> 01:19:50,880
schon gemacht haben mit docker compose mit docker mit zeug haben wir im stream schon öfters gemacht

615
01:19:50,880 --> 01:19:58,720
und zwar ein reverse proxy der dann auch am besten mit einem gültigen let's encrypt zertifikat

616
01:19:58,720 --> 01:20:06,880
ausgestattet ist und der über port 80 und 443 erreichbar ist das heißt neben dieser

617
01:20:06,880 --> 01:20:14,400
definition von den pots und dem service brauchen wir jetzt noch was für eingehenden traffic und

618
01:20:14,400 --> 01:20:22,000
das nennt sich bei kubernetes ingress das gegenteil von ingress ist egress nicht outgress so da

619
01:20:22,000 --> 01:20:29,080
gibt es verschiedene programme die man verwenden kann man kann traffic verwenden man kann engine

620
01:20:29,080 --> 01:20:38,080
x verwenden oder proxy oder sowas wir verwenden jetzt bei engine x aus dem einzigen grund weil

621
01:20:38,080 --> 01:20:47,320
bei mini cube schon in engine x addon für ingress dabei ist das macht man folgendermaßen also wenn

622
01:20:47,320 --> 01:20:55,000
ihr eine richtig fette kubernetes installation habt die bei jedem cloud anbieter läuft oder so da

623
01:20:55,000 --> 01:20:59,400
könnt ihr natürlich daneben was ihr wollt aber mini cube bringt verschiedene addons mit und da

624
01:20:59,400 --> 01:21:06,400
ist zum beispiel dabei sowas wie ein ingress und das ist in dem fall engine x das hat noch

625
01:21:06,400 --> 01:21:10,440
mehrere praktische addons dabei zum beispiel registry die benutzen wir auch gleich noch wir

626
01:21:10,440 --> 01:21:21,240
machen nämlich eine eigene dotnet anwendung die wir dann deployen hier über zu der lokalen

627
01:21:21,800 --> 01:21:27,880
lokalen container registry ich muss noch mal kurz überlegen in welcher reihenfolge wir das machen

628
01:21:27,880 --> 01:21:34,640
also ich würde sagen wir machen jetzt als erstes mal

629
01:21:34,640 --> 01:21:48,760
wir machen das in zwei stufen wir machen als erstes den ingress dann machen wir die dotnet an

630
01:21:48,760 --> 01:21:53,680
das drei zeilen dort netter es dauert nicht lang die dotnet anwendung und eine lokale registry

631
01:21:53,680 --> 01:22:00,240
und dann machen wir gültige let's encrypt zertifikate für den ingress ich glaube das

632
01:22:00,240 --> 01:22:08,160
ist eine gute eine gute reinfolge das so zu machen ok das heißt als erstes enable wir mal

633
01:22:08,160 --> 01:22:22,040
unseren engine x addons enable ingress so und jetzt muss das muss ich ein bisschen

634
01:22:22,040 --> 01:22:29,680
abgucken leute das kriege ich nämlich aus dem kopf nicht gebacken so also wir haben unsere

635
01:22:29,680 --> 01:22:34,960
pots bei der gelegenheit ihr seht hier vielleicht kommt mal mal im watch ihr seht hier wir haben

636
01:22:34,960 --> 01:22:40,480
aktuell nur einen pot laufen also quasi einen pot mit einem container drin das ist natürlich

637
01:22:40,480 --> 01:22:44,400
jetzt nicht sonderlich ausfallsicher man kann sagen das ist natürlich eh nicht ausfallsicher

638
01:22:44,400 --> 01:22:50,000
weil das alles auf meiner vm läuft aber geben wir mal von aus es wäre nicht so ich habe im

639
01:22:50,000 --> 01:22:56,240
anfang gesagt eigentlich das kombiniert ist dafür da um mehrere instanzen so von containern für

640
01:22:56,240 --> 01:23:01,200
uns zu verwalten deswegen kann man auch sagen man möchte mehrere davon laufen haben da geht

641
01:23:01,200 --> 01:23:06,480
man hier hinten den moment wo muss man da hin templates ach fuck ich kann mir das immer nicht

642
01:23:06,480 --> 01:23:13,480
merken in spex spex muss man das irgendwo muss man replica reinschreiben man alter wo muss

643
01:23:13,480 --> 01:23:28,720
denn das wo muss denn das hin das muss doch unter spex oder ja das muss doch unter spex

644
01:23:28,720 --> 01:23:37,840
bin im deployment oder nicht

645
01:23:37,840 --> 01:23:55,600
ach da in die spex meine güte mal ja genau ja ich bin großer jammel fan was das angeht also da

646
01:23:55,600 --> 01:24:02,880
kann man jetzt eingeben wie viele pots standardmäßig laufen sollen sagen wir mal zum beispiel fünf

647
01:24:02,880 --> 01:24:09,040
ja komm vier wenn ich das jetzt noch mal apply werdet ihr feststellen auf einmal hoch guck mal da

648
01:24:09,040 --> 01:24:15,880
damit ja vier container das heißt unsere anwendung läuft jetzt vier mal und wenn ich jetzt hier

649
01:24:16,440 --> 01:24:33,160
minikube service aufmach und funktioniert das auch kein ding aber es gibt noch mehr möglichkeiten

650
01:24:33,160 --> 01:24:49,820
der chrome kecht ja scheint so wir können das ganze auch noch mal stimmt aber machen wir das

651
01:24:50,820 --> 01:25:07,140
guckt ihr seht jetzt auch die ip ändert sich immer seht ihr das guck 12 6 12 10 11 also ihr

652
01:25:07,140 --> 01:25:12,900
seht die ip ändert sich immer ich komme immer auf unterschiedlichen pots raus guck mal 69 pots

653
01:25:12,900 --> 01:25:17,980
machen wir jetzt mal jetzt wird hyperscaled hier apply ich hoffe das geht überhaupt in meiner

654
01:25:17,980 --> 01:25:24,420
fremden gescheit bämm jetzt haben wir die anwendung 69 mal laufen wenn ich jetzt in köln mache wir

655
01:25:24,420 --> 01:25:29,340
müssen kurz warten bis alles erstellt wurde das ist leute ist das high performer mindset

656
01:25:37,340 --> 01:25:38,380
jetzt habe ich

657
01:25:43,380 --> 01:25:47,220
so guckt ich lande jetzt jedes mal auf einem anderen oder fast jedes mal auf

658
01:25:47,220 --> 01:25:54,580
einem anderen pot jetzt hier an der ip oben so und jetzt guckt mal was wo man jetzt schon mal

659
01:25:54,580 --> 01:25:59,140
sieht dass es sehr praktisch ist so ein container orchestrierungstool zu verwenden es gibt natürlich

660
01:25:59,140 --> 01:26:04,900
auch möglichkeiten das automatisch zu skalieren anhand der last der ram auslastung und sonst was

661
01:26:04,900 --> 01:26:09,420
das machen wir heute nicht das nächste mal geben wir auf was realistisches runter ich sag jetzt mal

662
01:26:09,420 --> 01:26:16,780
vier jetzt sage ich apply und passt auf es wird automatisch runter skaliert auf nur vier laufende

663
01:26:16,780 --> 01:26:29,180
pots warum ich linux verwende weil man gerade so netzwerk und technische sachen viel besser

664
01:26:29,180 --> 01:26:37,900
unter linux machen kann minikube unter windows geht auch dann macht er unter der haube glaube

665
01:26:38,060 --> 01:26:44,300
wie vm in der dann aber höchstwahrscheinlich linux läuft weil letztendlich sind es ja alles

666
01:26:44,300 --> 01:26:51,900
linux container und ich finde so sachen unter linux zu machen tausendmal angenehmer als unter

667
01:26:51,900 --> 01:26:58,060
windows allein schon dass man ein gescheites terminal hat ja das neue terminal unter windows

668
01:26:58,060 --> 01:27:07,380
ist halbwegs erträglich aber nix gegen ordentlich ordentliche linux umgebung so jetzt habt ihr

669
01:27:07,380 --> 01:27:11,780
gesehen man kann den kram hier auch ordentlich rauf und runter und runter skalieren wie man will

670
01:27:11,780 --> 01:27:15,100
am besten ist natürlich später man macht das automatisch aber das gucken wir uns mal in einem

671
01:27:15,100 --> 01:27:27,580
anderen stream an da habe ich auch gerade gesagt vor zwei minuten so soll das mal überlegen was

672
01:27:27,580 --> 01:27:33,340
wollte ich als nächstes machen genau also wir machen jetzt wir machen jetzt den ingress controller

673
01:27:33,340 --> 01:27:38,260
also es ist immer noch das problem dass ich hier in köln machen muss mit so einem komischen port

674
01:27:38,260 --> 01:27:44,740
normalerweise will man ja dass jemand so drauf zugreifen am besten noch mit dem dns namen ja

675
01:27:44,740 --> 01:27:50,460
darauf zugreifen kann also gar nicht gar nicht mal mit einem dns vor allem aber auf jeden fall über

676
01:27:50,460 --> 01:27:55,300
port 80 und dann auf dem richtigen service rauskommt das heißt wir brauchen jetzt noch

677
01:27:55,300 --> 01:28:02,700
irgendein service der das ob dessen ingress ingress template hat ja wir brauchen das noch

678
01:28:02,700 --> 01:28:11,700
irgendein service der eben am eingang sitzt das entgegen nimmt und dann weiter leitet an

679
01:28:11,700 --> 01:28:19,980
den service wiederum an die pots das ganze nennt sich mal kubernetes nennt sich das ingress also

680
01:28:19,980 --> 01:28:26,860
nennen wir das hier mal cute app ingress weiß ja nicht ob es minus in ingress wir können es

681
01:28:26,860 --> 01:28:38,460
nennen es aber wieder cute so wobei das tatsächlich sinnvoll ist das vielleicht ja anderweitig zu

682
01:28:38,460 --> 01:28:45,500
bedenken weil es könnte ja mehrere eingänge geben aber wir machen es jetzt einfach mal so so host

683
01:28:50,980 --> 01:28:58,300
da können wir jetzt in dns name eintragen was auch sinnvoll ist ja dann nehmen wir jetzt nehmen

684
01:28:58,300 --> 01:29:10,300
wir jetzt zum beispiel mal kackel punkt keck w punkt services prefix alles service bei service

685
01:29:10,300 --> 01:29:15,780
kommt jetzt der name rein das service ist was wir hier oben definiert haben das ist cute app und

686
01:29:15,780 --> 01:29:24,020
bei port port 80 so und da muss man jetzt und da muss man jetzt ein bisschen gucken hier geht

687
01:29:24,020 --> 01:29:35,980
es drum um also um den target service nicht nicht hier irgendwie vom vom ingress controller dann

688
01:29:35,980 --> 01:29:39,580
brauchen wir noch ein paar andere sachen damit das ganze funktioniert das ist so magic kubernetes

689
01:29:39,580 --> 01:29:44,860
zeug und das muss ich jetzt abgucken weil das kriege ich aus dem kopf nicht hin wir verwenden

690
01:29:44,860 --> 01:29:52,100
als eingangs proxy engine x das heißt ich muss das wie gesagt das gucke ich ab das war ich aus

691
01:29:52,100 --> 01:30:01,540
dem kopf nicht ingress class name muss ich eintragen nämlich engine x warum weil es

692
01:30:01,540 --> 01:30:16,700
nicht funktioniert jammel brauchste ultra wide screen monitore so und wenn ich jetzt alles

693
01:30:16,700 --> 01:30:28,060
richtig gemacht habe was ich mal hoffe dann sollten wir jetzt den ingress bekommen der

694
01:30:28,060 --> 01:30:40,380
sich für diese domain zuständig fühlt und dahin weiter leitet apply ok cube ctl get ingress

695
01:30:40,380 --> 01:30:55,060
what the fuck ingress ja haben wir host kackel punkt keck w services port 80 damit das damit

696
01:30:55,060 --> 01:31:01,060
das ganze funktioniert lokal müssen wir folgendes machen und zwar in die host datei dieses ding hier

697
01:31:01,060 --> 01:31:10,780
mal eintragen also kacke punkt services aus dem kopf ip ist zuerst ja ip ist zuerst genau

698
01:31:10,780 --> 01:31:23,740
ip ist zuerst einer ip mit mehreren amt punkt 49 punkt 2 ist glaube ich die mini cube ip ok

699
01:31:23,740 --> 01:31:40,300
guck mal mal pink pink ok karl moment der wahrheit es funktioniert chrome was nein chrome und siehe

700
01:31:40,300 --> 01:31:48,780
da kackel kacke punkt services ist verfügbar unter der domain und wir kommen auf unseren

701
01:31:48,780 --> 01:31:59,820
verschiedenen verschiedenen pots raus also der der traffic fluss ist jetzt so ich muss den namen

702
01:31:59,820 --> 01:32:06,580
auflösen in dem fall hier kackel punkt keck w punkt services da kommt die ip von meinem kubanet

703
01:32:06,580 --> 01:32:14,660
ist klasse da raus 1 2 1 6 8 4 9 punkt 2 dann geht das hier in den engine x ingress controller

704
01:32:14,660 --> 01:32:21,620
rein der leitet es weiter auf dieses backer der leitet wohlgemerkt alles weiter man kann auch

705
01:32:21,620 --> 01:32:27,900
sagen ich möchte bloß ab hier weiter leiten und sowas er leitet alles weiter an dieses backer mit

706
01:32:27,900 --> 01:32:34,820
dem namen cute app auf port 80 also auf den service cute app port 80 den service haben wir

707
01:32:34,820 --> 01:32:42,180
hier definiert target port port das ist das worauf der ingress controller das ganze weiter

708
01:32:42,180 --> 01:32:49,620
leitet und das service selbst verteilt das dann wieder auf alle möglichen pots so heißt im

709
01:32:49,620 --> 01:32:55,700
endeffekt es funktioniert auch immer noch wenn ich hier reinschreibe 69 pots machen wir es

710
01:32:55,700 --> 01:33:11,940
mal apply damit skaliert das ganze hoch diagonales 5 hat hyperskalierungs cloud native high IQ zeug

711
01:33:11,940 --> 01:33:19,820
wie jetzt hoch skaliert und wenn ich jetzt wieder ein köln mache auf keck w punkt services sehen

712
01:33:19,820 --> 01:33:27,980
wir kriegen fast immer eine andere ip und wir landen jetzt auf einem von 96 69 verschiedenen

713
01:33:27,980 --> 01:33:37,220
pots kann euch das sogar zeigen dass das relativ viel viel ab kann was jetzt kein wunder ist wir

714
01:33:37,220 --> 01:33:45,740
können mal einen htp benchmark starten können man hatte tp benchmark starten sowas wie hey für

715
01:33:45,740 --> 01:33:46,500
eine minuten

716
01:33:53,060 --> 01:34:01,980
warum geht altpunkt nicht was sind das z mal zehn sekunden zehn sekunden volle pulle und ihr seht

717
01:34:01,980 --> 01:34:11,260
guck mal meine cpu last hier oben ist jetzt einfach mal ist jetzt einfach mal 100% oh ja

718
01:34:12,140 --> 01:34:15,220
habe ich hatte tp vergessen

719
01:34:25,700 --> 01:34:34,060
ihr seht auch meine laut geht übelst hoch ja und wir haben 195.000 request geschickt alle hatten

720
01:34:34,060 --> 01:34:42,980
hatte tp status 200 hat wohl funktioniert ich bin mir jetzt gerade aus dem kopf nicht sicher wie

721
01:34:42,980 --> 01:34:53,020
man sich kommando zeilen mäßig die auslastung anzeigen lassen kann gibt es kubectl top oder

722
01:34:53,020 --> 01:34:58,980
so dinge also man kann zusatztool sowas wie lenz und sowas verwenden aber mal gucken ob kann man

723
01:34:58,980 --> 01:35:13,740
kubectl top gibt sowas hot node node minikube matrix api not verfügbar ok

724
01:35:14,300 --> 01:35:25,900
minikube add-ons enable matrix server ist das so aber

725
01:35:32,340 --> 01:35:35,940
ok ok

726
01:35:35,940 --> 01:35:47,700
wo ich das restarten oder so das könnte jetzt in dem minikube geschichte sein dass das nicht will

727
01:35:47,700 --> 01:35:52,780
matrix server ist enabled

728
01:36:03,780 --> 01:36:05,020
der ram ist voll quatsch

729
01:36:06,460 --> 01:36:14,020
glaube ich nicht ach so ja doch das könnte tatsächlich sein ich war mal kurz vier aber

730
01:36:14,020 --> 01:36:24,060
ich glaube nicht dass da voll ist weil so dieser container braucht ja nix ich glaube da hat keine

731
01:36:24,060 --> 01:36:35,180
schmerzen so und wir sehen hier ist autocomplete das ok naja ich war mir können einfach mal

732
01:36:35,180 --> 01:36:46,740
minikube können das ding mal neu starten moment moment insecure konti registries

733
01:36:46,740 --> 01:36:53,700
ich glaube dann einfach probleme mit der matrix api wir starten wir starten das ding mal neu

734
01:36:53,700 --> 01:37:01,340
vielleicht geht es dann muss man manchmal machen ich hatte schon öfters das minikube

735
01:37:01,340 --> 01:37:04,820
lokal manche sachen ich wollte da muss man das neu starten oder funktioniert

736
01:37:04,820 --> 01:37:17,140
dass wir das mal neu starten dann gucken so weil als nächstes gucken wir uns mal an wie man das

737
01:37:17,140 --> 01:37:25,660
mit lokaler image registry macht weil aktuell verwenden wir hier öffentliche public verfügbare

738
01:37:25,660 --> 01:37:30,540
docker images das ist ja meistens nicht der fall also wenn man eigene anwendung laufen lassen

739
01:37:30,540 --> 01:37:34,700
will da will man in der regel nicht diese anwendung public in einem docker container

740
01:37:34,700 --> 01:37:42,420
beziehungsweise in container image ins internet stellen zumindest viele wollen das nicht jetzt geht's

741
01:37:50,980 --> 01:37:51,980
in nebel

742
01:37:51,980 --> 01:38:01,380
ok minikube hat keinen bock

743
01:38:01,380 --> 01:38:08,060
minikube not found ok

744
01:38:08,060 --> 01:38:20,300
kann ich sowas machen wie get node also minikube wie dem auch sei pot ich kann

745
01:38:20,660 --> 01:38:28,580
mir anzeigen lassen kann man das so watchen lassen oder muss man das von hand machen wir

746
01:38:28,580 --> 01:38:33,940
führen jetzt noch mal den kram hier aus also moment ne wobei es doch eigentlich ok

747
01:38:39,940 --> 01:38:46,940
keine ahnung na gut die selbst können ja gar nicht so viel sachen hier abkommen dass ich

748
01:38:46,940 --> 01:38:52,540
das sehe bin ich ein bisschen doof dass es nicht geht aber

749
01:38:52,540 --> 01:38:59,020
ach jetzt funktioniert not minikube auf einmal ok alles klar nice gut zu wissen

750
01:38:59,020 --> 01:39:02,620
hat wahrscheinlich einfach ein bisschen gedauert bis es gestartet ist und sagt

751
01:39:02,620 --> 01:39:16,900
jetzt würde ich eigentlich erwarten dass der ein bisschen mehr ausgelastet ist ist er nicht

752
01:39:16,900 --> 01:39:24,900
hatte aber kein bock drauf denkt sich nope was was interessieren mich 128.000 naja gut machen

753
01:39:24,900 --> 01:39:28,740
wir mal machen wir einfach mal mehr potts ist ja apply

754
01:39:28,740 --> 01:39:41,540
kubectl get potts haben wieder jede menge potts am start das ding ist hat einfach nur

755
01:39:41,540 --> 01:39:48,820
eine krasse krasse verzirkt ne wobei das ist jetzt jetzt pot erstellen so und jetzt

756
01:39:48,980 --> 01:40:01,980
nochmal attp benchmark mein ganzer rechner ist voll man es könnte auch sein dass das

757
01:40:01,980 --> 01:40:09,340
irgendwie richtig funktioniert weil das im container läuft keine ahnung weiß eh nicht

758
01:40:09,340 --> 01:40:14,540
wie man sich das gescheit auf kommando zeile anzeigen lässt anscheinend so aber wirklich

759
01:40:15,100 --> 01:40:22,460
tut es ja nicht wirklich ja cpu 15 prozent na gut durchaus möglich dass es nicht mehr sein kann

760
01:40:22,460 --> 01:40:31,380
als 15 prozent weil ich ja nur in zwei kerne docker container habe für mein minikube ach guck

761
01:40:31,380 --> 01:40:37,820
jetzt geht es ein bisschen hoch also wirklich wirklich wirklich toll zur übersicht ist das ist

762
01:40:38,220 --> 01:40:45,340
gut aber jetzt war mal wieder mit dem was gescheites jetzt machen wir eine lokale container

763
01:40:45,340 --> 01:40:52,180
registry normalerweise ist es ja so wenn ihr anwendungen programmiert habt oder wenn ihr

764
01:40:52,180 --> 01:40:57,900
in einem unternehmen seid das der anwendung entwickelt hat und das auf kubanetis deployed

765
01:40:58,460 --> 01:41:10,300
dann ist das ja keine open source anwendung die irgendwo im internet verfügbar ist ja das

766
01:41:10,300 --> 01:41:15,100
kenne ich das kenne ich habe ich aber noch nicht benutzt ich kenne das ich habe ich habe erst

767
01:41:15,100 --> 01:41:19,380
gestern mir ein paar kubanetis frontends angeguckt

768
01:41:26,020 --> 01:41:33,700
so und dementsprechend willst du ja auch keine container images bauen mit deiner

769
01:41:33,700 --> 01:41:40,380
close source super secret versicherungs banken anwendung und hier auf docker hab

770
01:41:40,380 --> 01:41:47,940
öffentlich ins internet pushen so was du natürlich machen kannst ist wenn die firma in

771
01:41:47,940 --> 01:41:55,540
der cloud ist und in einem cloud anbieter vertraut kann man eine container registry verwenden also

772
01:41:55,540 --> 01:42:01,860
ich sag mal ihr kennt docker hab wahrscheinlich docker hab ist so die älteste container registry

773
01:42:01,860 --> 01:42:07,180
die es gibt docker hab ist nicht die einzige github hat beispielsweise auch eine eigene

774
01:42:08,180 --> 01:42:14,980
docker hab kennen die meisten aber so docker hab ist halt public oder man meldet sich an und

775
01:42:14,980 --> 01:42:18,340
kriegt da auch ein private account aber es ist immer noch in der cloud das ist im internet also

776
01:42:18,340 --> 01:42:24,660
vielleicht möchte man nicht seine anwendung oder die das unternehmen die anwendung ins internet

777
01:42:24,660 --> 01:42:33,140
stellen entweder benutzt man dann irgendeine registry wie docker hab allerdings bloß angemeldet

778
01:42:33,140 --> 01:42:41,380
und private oder github private registry oder man hostet sich eine container registry selber ich

779
01:42:41,380 --> 01:42:47,060
persönlich würde eher dazu tendieren die container registry nicht selber zu hosten sondern die von

780
01:42:47,060 --> 01:42:53,380
jeweiligen cloud anbieter zu nehmen also wenn man zum beispiel bei amazon ist bei azure oder bei

781
01:42:53,380 --> 01:42:59,620
google oder geben wir mal bei google wenn ihr gcp google cloud kunde seid dann könnt ihr auch da

782
01:42:59,620 --> 01:43:06,380
eine container registry verwenden für unseren fall werden wir jetzt eine lokale container registry

783
01:43:06,380 --> 01:43:13,860
mit mit einem add-on was im minikube eingebaut ist verwenden das ist ganz praktisch dann muss

784
01:43:13,860 --> 01:43:19,180
ich mich hier nirgendswo anmelden docker hab technisch sondern kann das hier alles lokal machen

785
01:43:19,180 --> 01:43:25,500
dann machen wir eine kleine dotnet anwendung und die packen wir dann anstelle hier von who am i

786
01:43:25,500 --> 01:43:31,500
traffic container packen wir in einen docker container bzw. bauen container image und pushen

787
01:43:31,500 --> 01:43:37,020
das zu unserer lokalen container registry und bei der gelegenheit gucken wir uns dann auch noch

788
01:43:37,020 --> 01:43:46,900
ein paar einheiten an damit man so was updaten kann ohne dass die anwendung dabei ausfällt

789
01:43:46,900 --> 01:43:52,740
so wir machen jetzt erstmal hier in den ordner nennen wir mal app so dotnet habe ich überhaupt

790
01:43:52,740 --> 01:44:05,060
habe ich überhaupt asp dotnet runtime installiert asp habe ich gar nicht null dachte mir noch

791
01:44:05,060 --> 01:44:11,100
irgendwie ich gehe mal kurz durch den chat durch was was da so gekommen ist ich habe wieder die

792
01:44:11,100 --> 01:44:18,980
hälfte nicht gelesen wenn firmenleute mit kubernetes erfahrung suchen wo ist dann in dem

793
01:44:18,980 --> 01:44:22,620
job genau die schwierigkeit dass die firmen wahrscheinlich gar nicht wissen was sie wollen

794
01:44:22,620 --> 01:44:29,060
ich glaube viele denken sie wollen kubernetes weil man das kennt und damit ja automatisch alles

795
01:44:29,060 --> 01:44:36,500
agil wird und skaliert automatisch und alles super verfügbar ist das ist aber ein trugschluss also

796
01:44:36,500 --> 01:44:43,420
man ist wahrscheinlich mit bekannter technologie mit leuten die sich damit auskennen besser als

797
01:44:43,420 --> 01:44:47,420
wenn man jetzt übers kniepricht kubernetes für irgendeinen anwendungszweck wo es vielleicht

798
01:44:47,420 --> 01:44:56,100
noch gar nicht mal großartig sinnvoll ist ja sie juzu dankeschön für den sub also ich glaube die

799
01:44:56,100 --> 01:44:58,820
größte schwierigkeit ist dass die firmen wahrscheinlich nicht so genau wissen was sie

800
01:44:58,820 --> 01:45:04,300
wollen und ansonsten das für mich komplizierteste was kubernetes angeht ist eindeutig in dem

801
01:45:04,300 --> 01:45:08,620
ökosystem den überblick zu behalten wie gesagt ich habe es am anfang gesagt ich bin auch nicht

802
01:45:08,620 --> 01:45:15,020
die pot sind running ich bin auch nicht das super krasse kubernetes checker ja und das

803
01:45:15,020 --> 01:45:24,300
ökosystem ist wirklich unglaublich komplex es gibt für es gibt für alles acht verschiedene

804
01:45:24,300 --> 01:45:31,820
lösungen allein schon allein schon wie speichert man apk und passwörter in kubernetes da gibt es

805
01:45:31,820 --> 01:45:37,260
fünf sechs verschiedene varianten von einfach bis super von ein bisschen einfacher und super

806
01:45:37,260 --> 01:45:53,940
kompliziert ne habe ich nicht da als secrets stores die besser nicht weil als secrets steht

807
01:45:53,940 --> 01:46:00,500
das im klartext in dein jammel files drinnen das kann man machen aber sobald du den jammel

808
01:46:00,500 --> 01:46:06,460
files ins git einchecks stehen deine secrets im klartext drinnen so da gibt es verschiedene

809
01:46:06,460 --> 01:46:11,900
möglichkeiten es gibt so sachen wie siehe secrets dann speichert man das ganze verschlüsselt

810
01:46:11,900 --> 01:46:22,900
verschlüsselt im git und entsperrt das quasi per key beim kubernetes cluster start dann gibt

811
01:46:22,900 --> 01:46:28,180
es irgendwas komisches von mozilla was quasi irgendwie so ein makro für jammel files ist

812
01:46:28,180 --> 01:46:34,100
dann gibt es sowas wie wollt und so da wird es aber schon langsam richtig kompliziert also

813
01:46:34,100 --> 01:46:44,060
gibt es unglaublich viel geschiss drumherum also gibt es ganz viel also da die ich glaube es

814
01:46:44,060 --> 01:46:50,020
gibt keinen den überblick behält ja da gibt es so sachen wie helm wo dran steht es ist ein

815
01:46:50,020 --> 01:46:55,860
paket ein package manager für kubernetes und du guckst dir mal helm chart definitionen an

816
01:46:55,860 --> 01:47:01,460
und musst erst mal kotzen wenn du die dateien siehst also da gibt es dann ja auch es ist auch

817
01:47:01,460 --> 01:47:07,060
nicht das einzige was es gibt gibt es auch wieder drei verschiedene sachen dann kannst du im

818
01:47:07,060 --> 01:47:12,140
zweifelsfall auch einfach sagen auch ich scheiß auf jammel und kannst es direkt über terraform

819
01:47:13,140 --> 01:47:32,580
kubernetes provider und das ist also dadurch zu blicken ist tatsächlich für mich für mich

820
01:47:32,580 --> 01:47:42,180
das schwierigste ich blicke da auch nicht durch soll ich ganz ehrlich also es gibt es gibt so

821
01:47:42,180 --> 01:47:49,580
viele sachen wo ich keine ahnung von hab an sich tools was es für möglichkeiten gibt und

822
01:47:49,580 --> 01:47:55,100
und später wenn es dann richtung service mesh und solche geschichten geht habe ich mich auch

823
01:47:55,100 --> 01:48:00,660
nur am rande mit beschäftigt da wird sein ganz abgedreht also muss sagen so die basic funktion

824
01:48:00,660 --> 01:48:04,620
von kubernetes sowas wie das was wir gemacht haben das ist tatsächlich gar nicht so schwer

825
01:48:04,620 --> 01:48:11,420
wenn man sich ein bisschen an die namen gewöhnt hat wie die den kram nennen aber das was damit

826
01:48:11,420 --> 01:48:15,860
dann noch zusätzlich kommt macht es kompliziert eine sache werden wir vielleicht gleich noch

827
01:48:15,860 --> 01:48:21,340
sehen mit manager und und zertifikate anlegen damit dann schon wieder ein bisschen komplizierter so

828
01:48:21,420 --> 01:48:30,660
wir bauen jetzt mal eine eigene net anwendung die wir benutzen als application application

829
01:48:30,660 --> 01:48:36,060
wie gesagt leute kein dotnet programmier stream das wird was ganz kleines was im

830
01:48:36,060 --> 01:48:45,180
prinzip nur aus drei zeilen oder so besteht also dort net new web

831
01:48:45,180 --> 01:48:57,460
so eine neue net anwendung und verwendest du das wim plugin wischl zu kontinue wenn ich

832
01:48:57,460 --> 01:49:04,740
wimm aufmache ist es der reale wimm noch nicht mal neowimm tatsächlich da stinkt normale wimm

833
01:49:05,340 --> 01:49:13,860
das ok ja ich traste traste alles hier voller trust

834
01:49:13,860 --> 01:49:24,340
dollen anwendung am start ja das habe ich da habe ich da habe ich jetzt gar nicht dran

835
01:49:24,340 --> 01:49:30,020
gedacht leute ja die ganzen cluster und storage möglichkeiten gibt es ja auch noch du musst ja

836
01:49:30,020 --> 01:49:34,460
das müssen wir uns ja auch noch angucken hier nicht heute im stream aber an der nächsten

837
01:49:34,460 --> 01:49:40,820
stein guckt mal meine anwendungen hier sind ja komplett stateless aktuell es sollen sie im

838
01:49:40,820 --> 01:49:47,740
besten fall auch sein in kuba jedes ja aber irgendwo müssen die daten ja hin der einfachste fall ist

839
01:49:47,740 --> 01:49:51,220
es gibt irgendwo den datenbank service und du connectest dich dahin liest und schreibst ein

840
01:49:51,220 --> 01:49:58,180
gutes aber manchmal brauchst du auch persistente dateien oder config files oder config einträge

841
01:49:58,180 --> 01:50:02,340
mit environment variable und sowas also aber spätestens bei dateien fängt es dann so an

842
01:50:02,340 --> 01:50:08,380
wo wie bekommst du wie bekommst du falls in den container da gibt es auch 1000 varianten von

843
01:50:08,380 --> 01:50:14,940
clusterfile system bis s3 du kannst darüber s3 machen gibt es 1000 varianten und gerade diese

844
01:50:14,940 --> 01:50:21,300
vielfalt und dann die auswahl aus dieser vielfalt was lohnt sich denn jetzt für den jeweiligen

845
01:50:21,300 --> 01:50:26,900
anwendungsfall anwendungsfall ja das ist das ist moment ist glaube ich nicht die landkarte die

846
01:50:26,900 --> 01:50:37,820
ich kenne doch das ist die landkarte ich kenne ja die ist wirklich nice ja und das ist beim

847
01:50:37,820 --> 01:50:44,380
weitem nicht alles was da drin steht wenn ich reingucke gibt es viele sagen es ist vieles

848
01:50:44,380 --> 01:50:48,940
weil ich noch nie davon gehört habe und auch einiges was hier noch fehlt also da den überblick zu

849
01:50:48,940 --> 01:50:54,380
behalten was es alles gibt und dann das passende auszuwählen für den anwendungsfall den man hat

850
01:50:54,380 --> 01:50:59,820
das ist fast das schwierigste an der ganzen kubanides geschichte und was man ehrlicherweise

851
01:50:59,820 --> 01:51:09,300
auch sagen muss was auch schwieriger ist als mit vms ist so ich meine ich habe jetzt hier

852
01:51:09,300 --> 01:51:14,860
drei pots laufen alles schön und gut aber wenn dann mal irgendwas nicht läuft in so einem

853
01:51:14,860 --> 01:51:19,460
kubanides cluster rauszufinden warum da jetzt also mal so eine anwendung zu debuggen in so einem

854
01:51:19,460 --> 01:51:24,740
kubanides cluster ist gar nicht mal so einfach im prinzip könnt ihr eigentlich nur folgendes

855
01:51:24,740 --> 01:51:31,020
machen logs für den container könnt ihr euch angucken so viel mehr dbug möglichkeiten habt

856
01:51:31,020 --> 01:51:36,420
ihr nicht es gibt noch die möglichkeit sich rein zu connecten in den container das können wir uns

857
01:51:36,420 --> 01:51:43,100
können wir uns auch gleich angucken also man kann ja mit docker was ist docker exek minus it

858
01:51:43,100 --> 01:51:51,100
und bin wäsche also wir machen das mal docker beispiel ja ich krieg das immer nicht aus dem

859
01:51:51,100 --> 01:52:09,060
kopf hin was habe ich verkehrt gemacht docker exek und wenn er schon läuft docker exek wenn

860
01:52:09,100 --> 01:52:15,380
er schon läuft docker exek kann man sich ja in lokale docker container rein verbinden das

861
01:52:15,380 --> 01:52:23,460
gleiche gibt es auch gibt es auch cube ctl exek oder kann man sich versuchen in weiß ich aber aus

862
01:52:23,460 --> 01:52:27,540
dem kopf überhaupt nicht wird es funktionieren kann man sich versuchen rein zu connecten in die

863
01:52:27,540 --> 01:52:30,020
container wenn es da zum beispiel eine shell gibt und sowas

864
01:52:30,020 --> 01:52:43,260
es minus minus kommandok die haben aber die haben aber aktuell keine shell aber nicht dass du

865
01:52:43,260 --> 01:52:49,620
trotz ist es trotzdem schwierig so was so was zu dbuggen also da muss ich sagen das ist immer noch

866
01:52:49,620 --> 01:52:57,100
wenn du so eine vm hast wurde dich rein connecten kannst und da dann rum wurschteln

867
01:52:57,100 --> 01:53:04,020
kannst drinne angenehmer so wirklich rauszufinden wo ist der fehler zu gucken ok warum funktioniert

868
01:53:04,020 --> 01:53:10,060
jetzt die namensauflösung nicht und so was also so ein container deployment zu dbuggen finde ich

869
01:53:10,060 --> 01:53:15,940
persönlich eine ganze ecke anspruchsvoller ich habe das leider wieder zugemacht anspruchsvoller

870
01:53:15,940 --> 01:53:22,900
als eine vm wo was drinne läuft heißt die frage wo kommen deine locks raus deine locks sind ja

871
01:53:22,900 --> 01:53:29,060
wahrscheinlich da nicht lokal in dem container sondern auf irgendeiner lock aggregierungs loki

872
01:53:29,060 --> 01:53:35,180
oder irgendwas oder lock sammel plattform oder elastix und was gibt es denn da alles mir fällt

873
01:53:35,180 --> 01:53:43,780
es muss loki ein von dem was ich verwenden würde kibana gibt es da noch und und zeugs

874
01:53:43,780 --> 01:53:55,140
jenkins nicht jenkins ist kein lock lock sammel plattform das ist das falsche was ich hier auf

875
01:53:55,140 --> 01:54:01,460
mache das ist nicht gecheckt dass ich hier moment ich mache das writer ist wieder zu

876
01:54:01,460 --> 01:54:18,980
pepega ok hat es hat es wieder nicht gecheckt hier max nepos minikube ja trust ok wir machen

877
01:54:19,980 --> 01:54:30,580
anwendung wo ich noch ein paar Sachen zeigen kann hatten wir hier noch nie rider offen auf

878
01:54:30,580 --> 01:54:36,020
der neuen vm ich glaube nicht ich glaube das ist neu ok sekunde da müssen wir erst mal was

879
01:54:36,020 --> 01:54:52,860
einstellen file settings short cuts ja fast fast ein action braucht wieder den standard

880
01:54:52,860 --> 01:55:11,820
short cuts ok ja ja remove und editor font ja mal wegen jet planes mono soll mir recht sein ok

881
01:55:11,820 --> 01:55:27,980
so jetzt jetzt sieht man ja hier was ach ja und sie pass mal auf leute flashbang

882
01:55:27,980 --> 01:55:42,700
ich war noch ein bisschen größer so also wir machen jetzt wirklich eine ganz simple minimale

883
01:55:42,700 --> 01:55:58,660
dotnet anwendung also hello world wollen wir nicht wir wollen return cute chatter

884
01:55:58,660 --> 01:56:08,860
so und dann müssen wir noch noch einstellen hier war name gleich wir machen das auch gleich mit

885
01:56:08,860 --> 01:56:27,340
environment variablen dass man auch was weiteres lernen kann environment variablen get so wunderbar

886
01:56:27,340 --> 01:56:35,180
reicht gut das ist unser unsere minimal dotnet web anwendung das reicht auch mehr brauchen wir

887
01:56:35,180 --> 01:56:40,700
zum testen an der stelle auch nicht reicht voll und ganz aus wir machen jetzt noch zwei sachen oder

888
01:56:40,700 --> 01:56:48,740
besser gesagt eine sache die sehr nützlich ist und zwar sagen wir noch ich glaube bilder

889
01:56:48,740 --> 01:57:03,180
bilder ad health checks nee service ad health checks und dann bei ad ad nee ach fuck wie war

890
01:57:03,180 --> 01:57:12,220
das map map health checks und zwar das ganze unter slash helft wisst ihr warum helft und

891
01:57:13,220 --> 01:57:18,980
weil aus irgendwelchen gründen die kubanete leute sich gedacht haben es ist eine tolle idee

892
01:57:18,980 --> 01:57:24,420
das mit z hinten dran zu schreiben wahrscheinlich weil das andere schon zu oft belegt war oder so

893
01:57:24,420 --> 01:57:30,660
keine ahnung worum das herkommt aber die finden es cooler dass das mit slash helft vielleicht

894
01:57:30,660 --> 01:57:36,900
weiß das deck overflow auch warum das so ist historisch die it comes from google internal best

895
01:57:36,900 --> 01:57:53,580
practices ok leute ihr habt es gehört helft ist google best practice excellent danke google so

896
01:57:53,580 --> 01:57:59,620
das ist unsere dotnet anwendung das war es auch schon mehr brauchen wir nicht was wir jetzt machen

897
01:57:59,620 --> 01:58:08,380
müssen ist ein image bauen für diese dotnet anwendung und das mache ich ganz einfach ich

898
01:58:08,380 --> 01:58:16,140
klaue mir den image weil habe ich nämlich schon vorbereitet kioko dankeschön für den sub und

899
01:58:16,140 --> 01:58:24,300
sorry falls ich irgendjemanden übersehen habe mit subs subscriptions ad docker support linux docker

900
01:58:24,300 --> 01:58:32,460
file das kommt alles weg weil das rider template kacke ist und jetzt bärm soll ich das noch mal

901
01:58:32,460 --> 01:58:36,220
kurz erklären oder wollen wir das docker feil einfach zur kenntnis nehmen und nicht mehr

902
01:58:36,220 --> 01:58:42,340
reingucken kann ich den stream als arbeits- oder weiterbildungszeit absetzen ich würde sagen schon

903
01:58:42,340 --> 01:58:48,060
wir machen hier schon wichtige wichtige dinge so weil mit diesem docker feil kann ich jetzt aus

904
01:58:48,060 --> 01:58:54,820
meiner dotnet anwendung ein container bauen und diesen image bauen und dieses image kann ich in

905
01:58:54,820 --> 01:59:00,420
eine container registry pushen und auf diese container registry kann ich dann an der stelle

906
01:59:00,420 --> 01:59:05,540
hier von kubernetes drauf zugreifen und meine eigene anwendung aus meiner eigenen container

907
01:59:05,540 --> 01:59:12,820
registry ziehen und nicht mehr aus einer öffentlichen container registry im internet ja so sieht es aus

908
01:59:12,820 --> 01:59:18,820
wir können mal kurz schauen ob mein bild funktioniert docker bild punkt

909
01:59:18,820 --> 01:59:27,940
ich spreche mal kurz ab docker bild minus t cute app

910
01:59:27,940 --> 01:59:32,380
schauen wir mal

911
01:59:39,140 --> 01:59:39,660
irgendwann

912
01:59:43,300 --> 01:59:45,060
ist das dann auch fertig gebaut

913
01:59:51,340 --> 01:59:57,420
so docker run it's minus minus m cute app

914
01:59:57,420 --> 02:00:04,420
jawoll da sind wir port 80 karl localhost

915
02:00:04,420 --> 02:00:16,300
achso ich habe keinen ports weitergeleitet lull pk 80 80 cute chatter gibt es nicht guck mal

916
02:00:16,300 --> 02:00:22,900
keiner unsere anwendung hatten back wir brauchen noch wenn wenn die environment variable nicht

917
02:00:22,900 --> 02:00:36,060
gesetzt ist brauchen wir noch default value excellent ok cute app noch mal bilden keine cute

918
02:00:36,060 --> 02:00:52,340
chatters bekannt ok run cute app also wunderbar ok das ist unsere absolut high IQs maximum IQ

919
02:00:52,460 --> 02:00:57,100
also bessere web anwendung geht nicht mehr und wenn ich jetzt slash health mache dann

920
02:00:57,100 --> 02:01:01,740
kommt healthy zurück und wenn ich weglasse kommt nichts weil bei google sagt da muss

921
02:01:01,740 --> 02:01:07,460
ein z hinten dran gut das ist unsere web anwendung fertig aus das war es mit c sharp für heute

922
02:01:07,460 --> 02:01:17,900
demnächst wieder mehr hier test machen das nächste mal wobei man keine tests braucht

923
02:01:17,900 --> 02:01:21,340
wenn man immer fehlerfreien code schreibt dann braucht man keine doku keine tests

924
02:01:21,340 --> 02:01:31,140
und keine kommentare weil es geht ja eh also sagen wir unsere unsere unsere unsere anwendung

925
02:01:31,140 --> 02:01:41,860
und jetzt müssen wir diese anwendung pushen in unsere lokale container registry ich habe

926
02:01:41,860 --> 02:01:49,540
hier schon mal in weißer voraussicht mein kubanete ist gestartet mit insecure registries

927
02:01:49,540 --> 02:01:55,340
weil naja von meiner container registries kein gültiges SSL zertifikat als erstes

928
02:01:56,340 --> 02:02:13,380
mal enable registry und irgendwann ist es dann durch ich kann euch auch mal zeichnen cube ctl

929
02:02:13,380 --> 02:02:22,860
get ports for all namespaces und da seht ihr hier kommt mal da cube system code s etcd bla bla bla

930
02:02:22,860 --> 02:02:32,100
und hier ist die container registry also die addons sind unter der haube auch nur container

931
02:02:32,100 --> 02:02:39,500
warum nicht pots tja muss man mal google fragen wie das sein kann gut und jetzt müssen wir in

932
02:02:39,500 --> 02:02:50,180
diese lokale container registry unsere app pushen das machen wir nicht mit docker ich kann euch

933
02:02:50,180 --> 02:02:57,300
auch sagen warum wir das nicht mit docker machen weil docker es nicht mag wenn die registry kein

934
02:02:57,300 --> 02:03:04,860
gültiges SSL zertifikat hat das muss man das kann man irgendwie konfigurieren bei docker fragt

935
02:03:04,860 --> 02:03:11,340
mich nicht wo also von der idee her würde man würde man das bilden und dann würde man sagen

936
02:03:11,340 --> 02:03:25,260
docker push und dann die registry ja man muss in irgendeine konfig feier kann man es reinschreiben

937
02:03:25,260 --> 02:03:33,540
aber wir nehmen einfach potman weil potman hat eine konfig option dafür potman ist quasi

938
02:03:33,540 --> 02:03:40,140
ein docker klon von rett hat mit ein paar sachen die docker nicht kann und umgedreht

939
02:03:40,140 --> 02:03:47,500
so weil jetzt kann man sagen potman bild und jetzt kommt es darauf an wie man das

940
02:03:47,500 --> 02:03:53,940
image nennt damit das ganze funktioniert warum nicht pot woman fragt mal twitter

941
02:03:53,940 --> 02:04:00,220
heute ist heute ist equal payday weißt du das eigentlich leute

942
02:04:00,220 --> 02:04:08,340
equal payday ist heute jetzt da sollte man schon mal potman in pot woman wenigstens mal

943
02:04:08,340 --> 02:04:17,900
zumindest für heute umbenennen so also damit das ganze funktioniert damit man sein sein image in

944
02:04:18,500 --> 02:04:24,260
die lokale container registry pushen kann muss man das taggen und zwar richtig taggen und zwar

945
02:04:24,260 --> 02:04:32,580
mit der ip und mit der ip beziehungsweise dem namen von der container registry und mit dem

946
02:04:32,580 --> 02:04:39,060
image wie das wie das ganze wie das ganze heißen also ich muss mal sagen wie potman bild wie

947
02:04:39,060 --> 02:04:44,380
gesagt mit docker geht das auch wenn es gültiges zertifikat vor der registry hat also potman

948
02:04:44,380 --> 02:04:50,180
bild 192 wobei wir machen es anders wir machen das wir machen wir machen den script kommen wir

949
02:04:50,180 --> 02:05:01,700
sind wir sind mal super ordentlich wir machen bild.sh bin bash registry gleich hoffe ich schreibe

950
02:05:01,700 --> 02:05:15,260
das ist jetzt richtig registry gleich mini cube ip auf port 5000 läuft die registry das weiß ich

951
02:05:15,260 --> 02:05:21,020
weil ich nachgeguckt habe und wir können noch so was wie einen tag hinten angeben vielleicht

952
02:05:21,020 --> 02:05:27,940
vielleicht gar nicht so blöd wenn wir tag hinten angeben so und jetzt kommt das was wir an potman

953
02:05:27,940 --> 02:05:35,740
kommandos ausführen ist nämlich potman bild minus t registry also in dem fall die ip und

954
02:05:35,740 --> 02:05:41,860
der port und der port name von der app und jetzt können wir noch einen tag hinten dran machen

955
02:05:41,860 --> 02:05:48,140
so und wenn das fertig ist können wir sagen potman push und das muss ich mir jetzt kopieren weil

956
02:05:48,140 --> 02:05:55,460
ich das aus dem kopf nicht weiß minus minus tls verify gleich falls und dann funktioniert das

957
02:05:55,460 --> 02:06:00,620
auch alles über htp beziehungsweise auch mit ungültigen zertifikaten und jetzt hier den

958
02:06:00,620 --> 02:06:07,100
gleichen krempel ich habe übrigens auch einen punkt vergessen so wenn ich das script jetzt

959
02:06:07,100 --> 02:06:14,220
richtig gebaut habe dann sollte der uns jetzt einen container image bilden und in die registry

960
02:06:14,220 --> 02:06:34,500
pushen ok was habe ich denn verkehrt gemacht potman bild minus t registry ah ich habe den

961
02:06:34,500 --> 02:06:44,540
tag vergessen anzugeben ok ja also 1.0.0 hrq app ok jetzt ok er baut und ihr seht es sieht fast

962
02:06:44,540 --> 02:06:50,780
aus wie bei docker nur dass jetzt potman ist wieso der code war richtig funktioniert ohne

963
02:06:50,780 --> 02:07:02,980
jegliche änderung so image ist gepusht nice und was ich jetzt machen kann ist folgendes ich

964
02:07:03,060 --> 02:07:11,020
trage jetzt an der stelle einfach ein localhost ich kann an der stelle jetzt localhost verwenden

965
02:07:11,020 --> 02:07:15,300
weil die registry innerhalb des kubanier des clusters läuft es funktioniert an der stelle

966
02:07:15,300 --> 02:07:26,180
localhost 5000 slash cute app doppelpunkt versionsnummer 1.0.0 und jetzt werdet ihr

967
02:07:26,180 --> 02:07:33,620
feststellen ich zeige jetzt mal watch mein karl keckel

968
02:07:40,020 --> 02:07:45,740
ihr seht hier das ist der aktuelle service der da läuft das ist noch der hallo welt service das

969
02:07:45,740 --> 02:07:56,060
ist noch nicht noch nicht unsere web anwendung was ist köln minus s glaube ich für weniger

970
02:07:56,060 --> 02:08:01,020
output genau so das ist noch nicht unser unser web anwendung ich habe jetzt in dem fall hier in

971
02:08:01,020 --> 02:08:08,540
unserer in unserem manifest unserem kubanier das manifest das image ausgetauscht was ich als

972
02:08:08,540 --> 02:08:12,340
anwendung verwenden will vorher hatte ich hier diese traffic hello world ab und jetzt habe ich

973
02:08:12,340 --> 02:08:18,340
unsere eigene anwendung da rein gepackt die wir die wir vorher als container image verpackt haben

974
02:08:18,340 --> 02:08:23,180
und in diese registry gepusht haben und wenn jetzt alles funktioniert ich hoffe es mal wir

975
02:08:23,180 --> 02:08:32,940
machen hier wir machen hier parallel noch mal ein get pods dass wir nämlich sehen wenn es fehler

976
02:08:32,940 --> 02:08:45,740
gibt studio muss mal kurz weg und jetzt sage ich apply und vorher immer raus apply bär so alte

977
02:08:45,740 --> 02:08:51,060
container werden neue container werden gestartet alte container werden gestattet cute chat eier

978
02:08:51,060 --> 02:08:57,780
zack ich habe jetzt quasi neue anwendung deployed ohne das request kaputt gegangen sind zwischendurch

979
02:08:57,780 --> 02:09:02,420
wie euch vielleicht aufgefallen ist das natürlich schon nice gelb

980
02:09:02,420 --> 02:09:15,300
machen wir das mal weg also wir wissen jetzt dass mit dem image funktioniert so jetzt haben wir

981
02:09:15,300 --> 02:09:19,260
hier unsere eigene anwendung drauf laufen jetzt brauchen wir noch ein paar andere geschichten

982
02:09:19,740 --> 02:09:27,500
dass das ordentlich funktioniert weil aktuell ist es so und um euch das mal zu demonstrieren

983
02:09:27,500 --> 02:09:31,660
beziehungsweise dass man ich zeige es auch mal dass man sich besser vorstellen kann machen wir mal

984
02:09:31,660 --> 02:09:36,180
sexo machen wir mal 69 container

985
02:09:36,180 --> 02:09:44,820
ihr werdet feststellen gleich gibt es wieder jede menge container

986
02:09:44,820 --> 02:09:57,380
während das aufbauen wir machen mal eine ein ein dirty hack in unserem build script den sehe ich

987
02:09:57,380 --> 02:10:05,940
hier nehme ich gerade drüben dass ich das auch aus anderen verzeichnissen ausführen kann so

988
02:10:05,940 --> 02:10:16,500
abbild und jetzt machen wir mal eine neue versionsnummer von der app ja also zum

989
02:10:16,500 --> 02:10:20,940
beispiel okay ich ändere ich ändere der form halber auch noch was ja es gibt ja west version

990
02:10:20,940 --> 02:10:30,580
1.0.1 von dieser app und zwar ist es cute chatter ja ich will ich will hier wobei irgendwas

991
02:10:30,580 --> 02:10:52,460
ist es jetzt okay schreibt man das überhaupt so ist es jetzt noch noch mehr alles und das will

992
02:10:52,460 --> 02:10:57,660
ich jetzt einchecken also ich baue neues image draus aus der anwendung mit diesem mit diesem fix

993
02:10:58,260 --> 02:11:09,540
image version 1.0.1 pusht das wieder in die registry so und jetzt apply ich das und was

994
02:11:09,540 --> 02:11:17,940
wird jetzt passieren leute es wird nix passieren es wird nix passieren weil es hat sich ja nix

995
02:11:17,940 --> 02:11:27,020
geändert es hat sich ja nix geändert warum sind meine pots eigentlich alle pending da unten

996
02:11:27,020 --> 02:11:35,100
ich glaube ich habe zu viele kann es sein dass ich mit den ressourcen am limit bin dass das meine

997
02:11:35,100 --> 02:11:41,460
dass ich zu viele pots habe okay moment wir skalieren es mal runter auf was sinnvolles auf

998
02:11:41,460 --> 02:12:00,540
10 oder so also wenn ich das jetzt applye und wieder curl mache werdet ihr vielleicht

999
02:12:00,540 --> 02:12:08,420
feststellen es ist immer noch die alte message warum na ja weil die versionsnummer die hier

1000
02:12:08,420 --> 02:12:14,380
drin ist immer noch 1.0 ist ich will ja 1.0.1 haben so und jetzt wird euch gleich ein problem

1001
02:12:14,380 --> 02:12:21,980
auffallen wenn ich das jetzt applye dann wird er updaten dann wird er updaten von dieser von

1002
02:12:21,980 --> 02:12:28,660
dem tag 1.0.0 auf 1.0.1 und wenn ihr mal genau guckt was er hier unten macht wird euch vielleicht

1003
02:12:28,660 --> 02:12:39,300
was auffallen der startet neue container und lässt dann die alten container löst dann die

1004
02:12:39,300 --> 02:12:51,100
alten container aber euch wird auffallen das zeug ist relativ schnell ready das zeug ist relativ

1005
02:12:51,100 --> 02:12:58,980
schnell ready das komisch und das ist aber auch doof weil wenn jetzt im falschen momenten ein

1006
02:12:58,980 --> 02:13:05,380
request rankommt könnte es ja theoretisch sogar sein dass der request auf dem container landet

1007
02:13:05,380 --> 02:13:13,860
der noch gar nicht richtig gestartet ist das heißt wir müssen jetzt nicht nur den container

1008
02:13:13,860 --> 02:13:19,380
starten sondern wir müssen auch checken ob der container bereit ist ob der container bereit ist

1009
02:13:19,380 --> 02:13:28,860
machen wir mit den health checks hier drinnen wenn du eine fehlerhafte version deploys

1010
02:13:28,860 --> 02:13:35,820
der ist ja quasi ach so jaja jaja ach das ist eine gute idee das kann ich auch zeigen das kann

1011
02:13:35,820 --> 02:13:41,100
ich auch zeigen guckt mal ich skaliere das mal ein bisschen runter auf sechs stück erst mal

1012
02:13:41,100 --> 02:13:47,540
wir werfen keine exception ich trage einfach eine tag ein den es nicht gibt also ich gehe

1013
02:13:47,580 --> 02:13:53,180
mal kurz runter auf sechs das sieht man also mal angenommen ich sage jetzt hier nehm mal

1014
02:13:53,180 --> 02:14:00,860
image version 1.0 2 die es noch nicht gibt und ich applye das jetzt dann werdet ihr feststellen

1015
02:14:00,860 --> 02:14:09,540
der versucht es zu applyen aber er image pull oder macht nicht weiter und die alten laufen weiter

1016
02:14:09,540 --> 02:14:13,260
das heißt ich habe obwohl ich eine fehlerhafte konfig haben das ist wirklich auch eine coole

1017
02:14:14,020 --> 02:14:21,540
obwohl ich eine fehlerhafte konfig habe ein weiterhin funktionierenden service zwar die

1018
02:14:21,540 --> 02:14:29,900
alte version aber egal ich meine besser als kaputt kaputt wäre glaube ich das blödeste

1019
02:14:29,900 --> 02:14:36,260
was was an der stelle passieren könnte so wenn ich das als wieder rückgängig mache mal wieder

1020
02:14:36,260 --> 02:14:43,300
version 1 rein sache play dann checkt er das ganze auch und er geht wieder auf sechs replikas hoch

1021
02:14:43,300 --> 02:14:48,020
also ich habe angeheben ich möchte sechs davon laufen lassen und das ist wirklich cool und das

1022
02:14:48,020 --> 02:14:55,340
im großen stil ist eigentlich der grund schlechthin also dieses solche features in der richtung ist

1023
02:14:55,340 --> 02:15:00,540
nicht explizit dieses ist der grund schlechthin warum kuba netis sich überhaupt so durchgesetzt

1024
02:15:00,540 --> 02:15:09,340
hat du kannst halt wunderbar deinen ganzen workload über mehrere notes skalieren und du

1025
02:15:09,340 --> 02:15:16,820
kannst relativ gut ausfallfrei deine software managen damit das ist eigentlich der hauptsächliche

1026
02:15:16,820 --> 02:15:22,740
grund warum warum kuba netis so beliebt ist oder sich auch so durchgesetzt hat gab ja noch ein

1027
02:15:22,740 --> 02:15:33,260
paar andere andere dinge es gab dann zwischenzeitlich mal docker swarm was ja immer noch gibt kaum

1028
02:15:33,260 --> 02:15:37,340
jemand benutzt da gibt es noch ein paar andere geschichten wo mir grad nichts ein gibt es noch

1029
02:15:37,340 --> 02:15:42,500
nomad gibt es noch das ist aber glaube ich auch noch mehr mit vms dabei fällt jemand nehmen eine

1030
02:15:42,500 --> 02:15:48,580
gute kuba netis alternative ein hat der canonical nicht auch mal den versuch mit lxd gestartet

1031
02:15:48,580 --> 02:15:53,180
irgendwie sowas zu bauen was keiner haben wollte

1032
02:15:53,180 --> 02:16:06,260
mesos mesos gibt es noch richtig apache war das apache openshift wobei ist openshift noch

1033
02:16:06,260 --> 02:16:13,980
deutlich mehr nicht noch deutlich mehr dabei dass du da auch ne moment das ist nicht openshift das

1034
02:16:13,980 --> 02:16:19,940
ist openshift also openshift ist die telekom cloud das weiß ich die telekom cloud ist

1035
02:16:19,940 --> 02:16:27,540
openshift aber das heißt ja nicht dass es das heißt ja nicht dass es schlecht sein muss wie

1036
02:16:27,540 --> 02:16:38,020
heißt das andere wo noch vms und so dabei sind open stack meine ich ich meine open stack und

1037
02:16:38,020 --> 02:16:43,500
die telekom cloud ist open stack darum war das nicht openshift open stack meine ich genau

1038
02:16:43,500 --> 02:17:00,260
ja richtig richtig so sieht es aus so was wollte ich was wollte ich denn jetzt noch machen ja also

1039
02:17:00,260 --> 02:17:06,540
ihr habt jetzt ja gesehen es sind jetzt ganz viele services neu gestartet worden aber die

1040
02:17:06,580 --> 02:17:11,740
dinge waren sofort ready das will man ja nicht das heißt wir haben ja hier einen health check

1041
02:17:11,740 --> 02:17:20,900
definiert service fabric okay mir fällt schon außer kuba netis gar nicht gar nicht mehr so viel

1042
02:17:20,900 --> 02:17:26,700
ein so man kann jetzt an der stelle sagen hier wo man wo man replikas einträgt kann ich auch noch

1043
02:17:26,900 --> 02:17:42,700
sagen strategy type rolling ich glaube rolling update glaube ich ist sogar der default da bin

1044
02:17:42,700 --> 02:17:47,860
ich mir aber nicht ganz sicher rolling update und dann kann man das braucht man eigentlich gar

1045
02:17:47,860 --> 02:17:59,980
nicht ja da kann man dann noch so was sagen wie max unavailable 1 und max max search 1 oder man

1046
02:17:59,980 --> 02:18:05,700
kann auch 2 in dem fall so kann man jetzt einstellen wie er updates machen soll also

1047
02:18:05,700 --> 02:18:13,780
rolling update ist glaube ich relativ selbsterklärend und wobei das ja noch nicht alles ist was wir

1048
02:18:13,780 --> 02:18:22,780
machen müssen und hier kann man jetzt auswählen wie er vorgehen soll beim rolling upgrade also von

1049
02:18:22,780 --> 02:18:32,060
diesen sechs replikas wie viele dürfen nicht erreichbar sein während dem update und wie

1050
02:18:32,060 --> 02:18:38,980
viele dürfen mehr da sein als target also mit diesen settings würde folgendes passieren er

1051
02:18:38,980 --> 02:18:46,420
könnte zum beispiel einen neuen container erzeugen schon im vorfeld bevor er den alten

1052
02:18:46,420 --> 02:18:52,620
stoppt und dann können alten stoppen so dass kurzzeitig fünf nur laufen und das zwischenzeitlich

1053
02:18:52,620 --> 02:18:58,780
kurz auch mal sieben laufen können was ja wichtig ist weil bei einem update müssen ja neue container

1054
02:18:58,780 --> 02:19:02,540
gestartet werden alte container gestoppt werden ist halt die frage wie man das macht man kann

1055
02:19:02,540 --> 02:19:08,540
natürlich auch hier mehr eintragen wenn man damit dacor ist dass auch mal von diesen replikas weniger

1056
02:19:08,540 --> 02:19:13,780
laufen hiermit kann man das quasi ein bisschen feintunen wie man dieses update wie man dieses

1057
02:19:13,780 --> 02:19:20,500
update durchführen will wenn ich jetzt wenn ich jetzt sag wie ging das jetzt die deployment

1058
02:19:20,500 --> 02:19:35,620
cube cube rollout cube ctl rollout restart wobei ich brauche ich gar nicht ich kann es einfach

1059
02:19:35,620 --> 02:19:52,020
machen doch anscheinend ja ok cube ctl rollout restart deployment das sieht man jetzt macht

1060
02:19:52,020 --> 02:20:02,140
er das halt entsprechend dieser policy das maximum einer eben hier immer abgecreated wird aber wenn

1061
02:20:02,140 --> 02:20:08,460
ich jetzt hier zum version runter runter gehe auf version eins sach apply dann seht ihr ok

1062
02:20:08,460 --> 02:20:14,740
der erzeugt zwei neue und er stoppt immer kann auch immer ein zwei austauschen immer ein mehr

1063
02:20:14,740 --> 02:20:23,140
und ein weniger kann man das ein bisschen feintunen was er was er machen darf so was aber viel

1064
02:20:23,140 --> 02:20:30,380
wichtiger ist wir brauchen noch health checks weil ihr seht jedes mal wenn der container

1065
02:20:30,380 --> 02:20:35,180
gestartet ist er sofort ready das stimmt ja gar nicht der container ist gar nicht sofort ready

1066
02:20:35,180 --> 02:20:40,660
der muss ja auch erst mal starten die web anwendung muss starten ich mein das geht schnell ja mein

1067
02:20:40,660 --> 02:20:52,540
potman run cute cute app ach so das hieß ja irgendwie anders was weiß ich

1068
02:21:02,540 --> 02:21:07,140
so ihr seht so ein container startet schnell ist mal exemplarisch lokal bei mir mit docker

1069
02:21:07,220 --> 02:21:13,180
der startet schnell aber es ist trotzdem eine halbe sekunde wo der container gestartet ist aber noch

1070
02:21:13,180 --> 02:21:17,980
nicht bereit ist requests anzunehmen und es könnte ja auch durchaus länger dauern ok keine frage

1071
02:21:17,980 --> 02:21:24,100
so und dafür gibt es solche sachen wie ready probe und lifeboard oder life nes probe und

1072
02:21:24,100 --> 02:21:30,620
readiness probe das muss man das muss man abgucken wo das hin muss unter unter ports

1073
02:21:30,620 --> 02:21:36,660
muss unterhalb von ports also dahin muss das an der stelle

1074
02:21:51,660 --> 02:21:55,660
als wer cringe das kann ich dir nicht erzählen habe ich keine große erfahrung drinne

1075
02:21:55,660 --> 02:22:04,900
ich würde mal sagen mit datenbank migrations aber du willst die postgres version updaten

1076
02:22:04,900 --> 02:22:09,260
oder was also willst du nicht deine datenbank intern die struktur updaten du willst die

1077
02:22:09,260 --> 02:22:18,100
datenbank version updaten oder wie das eigentlich erwarten dass deine anwendung sowohl mit der

1078
02:22:18,100 --> 02:22:23,500
alten als auch mit der neuen version funktioniert weil ansonsten ansonsten wäre das easy du

1079
02:22:23,500 --> 02:22:28,820
updatest zuerst die datenbank wenn du die datenbank version updaten willst du updatest zuerst die

1080
02:22:28,820 --> 02:22:36,460
datenbank dann die anwendung und dann ist gut das schema ok du willst so was wie eine datenbank

1081
02:22:36,460 --> 02:22:40,580
migration oder so haben das ist eine gute frage habe ich keine erfahrung mit wie man das gescheit

1082
02:22:40,580 --> 02:22:49,900
synchronisiert jetzt bestimmt irgendwelche super tollen best practice sachen für aber ich kann

1083
02:22:49,980 --> 02:22:56,460
da nichts sinnvolles zu sagen ich kann jetzt höchstens was zusammen reiben was mir da so

1084
02:22:56,460 --> 02:23:06,900
auf dem stegreif einfällt aber ich wenn du das schema updatest dann erweiterst du das schema

1085
02:23:06,900 --> 02:23:12,260
ja in der regel oder machst du das schema incompatibel also geht die alte anwendung

1086
02:23:12,260 --> 02:23:15,220
noch mit der neuen schema version oder nicht wahrscheinlich nicht

1087
02:23:20,380 --> 02:23:27,540
wenn das so wenn das so voneinander abhängt müsste ich mir gedanken zu machen kann ich dir so

1088
02:23:27,540 --> 02:23:34,180
vielleicht an der chat ahnung wir haben hier viele 5 hat cloud native kubernetes 6 herz vielleicht

1089
02:23:34,180 --> 02:23:42,340
fällt da jemand was zu ein wahrscheinlich kommen die leute jetzt wahrscheinlich kommen die leute

1090
02:23:42,340 --> 02:23:47,700
jetzt an und sagen ha ha null gar keine sql datenbanken mehr verwenden sondern einfach nur

1091
02:23:47,700 --> 02:23:57,860
noch cloud native data basis wobei das halt nicht realistisch ist das ist dann wenn du die

1092
02:23:57,860 --> 02:24:01,740
falschen leute was sie kommen dann immer mit so was so ja warum verwendest du auch nicht

1093
02:24:01,740 --> 02:24:07,140
klaut technologie in kürze bescheuern wer definiert was klaut technologie sachen ist und was nicht

1094
02:24:07,140 --> 02:24:15,820
also das ist das ist was du hast zwerggründe ist ein sehr praktischer und realer anwendungsfall

1095
02:24:15,820 --> 02:24:22,220
und darauf gibt es bestimmt auch eine gute lösung habe ich aber keine erfahrung mit kann

1096
02:24:22,220 --> 02:24:29,380
ich dir gerade nicht sagen zu also das naheliegendste ist natürlich du musst sicherstellen dass die alte

1097
02:24:29,380 --> 02:24:34,500
anwendung auch mit dem neuen schema funktioniert also dass du kannst das schema zwar erweitern aber

1098
02:24:34,500 --> 02:24:40,340
dass es nicht incompatibel zur alten anwendung machen dann funktioniert es dann ist easy dann

1099
02:24:40,340 --> 02:24:47,260
kannst du zuerst die datenbank updaten und dann die anwendung und wenn das nicht so ist fällt

1100
02:24:47,260 --> 02:24:55,220
jetzt so spontan nicht so viel ein weil da müsstest du ja sicherstellen dass du irgendwie so einen

1101
02:24:55,220 --> 02:25:02,420
rolling update machst so die datenbank updaten dann wobei es halt je nach datenbank auch so ist

1102
02:25:02,420 --> 02:25:07,820
dass du gar keine unterschiedlichen datenbank anspricht sondern alle datenbanken in dem cluster

1103
02:25:07,820 --> 02:25:14,180
über halt ein connection string wenn du so willst dass du gar nicht explizit sagen kannst ich will

1104
02:25:14,180 --> 02:25:23,140
jetzt nur auf diese tja da gibt es bestimmt coole möglichkeiten zu bis jetzt hatte ich das muss

1105
02:25:23,140 --> 02:25:26,300
ich mich mit diesem problem noch nicht beschäftigen wenn es soweit ist sag ich dir bescheid

1106
02:25:26,300 --> 02:25:37,500
ich würde einfach sagen ist job der dba es kümmert dich nicht drum dass sie das machen

1107
02:25:37,500 --> 02:25:40,380
sag einfach nicht mein problem easy

1108
02:25:47,060 --> 02:25:50,620
ja aber kommen wir mal zur container geschichte zurück

1109
02:25:50,620 --> 02:26:00,820
damit ich mitbekomme wann meine anwendung wirklich gestartet ist gibt es readiness probes und es

1110
02:26:00,820 --> 02:26:11,900
gibt dieses autocomplete alter ist es schlecht man leifnis probe gibt es das eine ist wenn

1111
02:26:11,900 --> 02:26:16,260
der container ready also wenn der container gestartet ist zum ersten mal und das zweite

1112
02:26:16,260 --> 02:26:24,860
ist ob der container noch weiterhin funktioniert und ich copy paste mir das jetzt hieraus aus

1113
02:26:24,860 --> 02:26:31,780
dem beispiel weil ich keinen bock habe das nochmal alles zu tippen so sieht das ganze

1114
02:26:31,780 --> 02:26:38,700
dann aus aber gibt sogar eine hilfe dazu der guckt ob der ob der container ready ist und

1115
02:26:38,700 --> 02:26:43,940
der guckt ob der container noch am leben ist und wenn diese das ist der unterschied wenn

1116
02:26:43,980 --> 02:26:51,260
diese leifnis probe fehlschlägt dann restartet kubernetes den container kann auch sehr praktisch

1117
02:26:51,260 --> 02:26:55,140
sein falls die anwendung nicht komplett krascht sondern intern bloß in so einem

1118
02:26:55,140 --> 02:27:00,340
zustand gerät dass sie nicht mehr richtig funktioniert also leifnis probe startet

1119
02:27:00,340 --> 02:27:06,420
kubernetes im zweifelsfall den container neu und hier kann unter anderem dieser ready check

1120
02:27:06,420 --> 02:27:11,860
entscheiden wann das denn in den load balancer aufgenommen wird es gibt auch startup probe ja

1121
02:27:11,860 --> 02:27:17,740
aber das braucht man in der regel nicht genau so und wenn ich das jetzt apply dann werdet ihr

1122
02:27:17,740 --> 02:27:26,020
vielleicht gleich was feststellen guckt mal das geht jetzt deutlich langsamer seht ihr das

1123
02:27:26,020 --> 02:27:36,980
das das geht jetzt deutlich langsamer alles und warum weil er halt immer fünf sekunden wartet

1124
02:27:36,980 --> 02:27:42,220
bis das ding auch wirklich am leben ist also der wartet fünf sekunden macht dann diesen health

1125
02:27:42,220 --> 02:27:47,860
check ob es am leben seht es dauert deutlich länger aber jetzt haben wir den großen vorteil

1126
02:27:47,860 --> 02:27:54,140
jetzt gehen keine requests mehr keine neuen requests mehr verloren also wenn ihr einen ganz

1127
02:27:54,140 --> 02:28:01,020
ungünstigen moment erwischt dass ihr gerade weiter geleitet worden seid auf einen server und der

1128
02:28:01,020 --> 02:28:06,460
wird gerade weg gestartet oder so dann kann es sein dass man immer noch einen fehler kriegt aber

1129
02:28:06,460 --> 02:28:11,500
es verschwindet gering und das kann ich euch jetzt auch zeigen ich mache mal einen ich mache mal

1130
02:28:11,500 --> 02:28:16,860
den benchmark ok ich mache ich mache eine neue version wir gehen wieder zurück zu cute cute

1131
02:28:16,860 --> 02:28:24,740
chatter ich mache ich mache eine neue version 1.0.2 von unserem container pusht das in die

1132
02:28:24,740 --> 02:28:30,220
registry update die container version und jetzt passt mal auf ich mache einen benchmark

1133
02:28:30,220 --> 02:28:38,740
hey haben wir waren 30 sekunden dann war mal länger eine minute aber eine minute eine minute

1134
02:28:38,740 --> 02:28:47,300
holle pulle requests auf diesen service ich fange jetzt an und jetzt mache ich das update apply

1135
02:28:47,300 --> 02:28:55,180
wir können wir können nebenbei nebenbei zugucken cute

1136
02:28:56,180 --> 02:29:02,180
pots ja ihr seht die pots werden neu gestartet und werden hinzugenommen und alles

1137
02:29:02,180 --> 02:29:11,940
latest funktioniert nicht apply läuft immer nur dann wenn sich das manifest geändert hat latest

1138
02:29:11,940 --> 02:29:22,100
funktioniert nicht es gibt tricks dass es mit latest funktioniert aber das stammt mich funktioniert

1139
02:29:22,100 --> 02:29:29,500
das mit latest nicht so unser rolling update ist fertig und jetzt bin ich mal gespannt ob

1140
02:29:29,500 --> 02:29:41,460
requests verloren gegangen sind das läuft noch ok irgendwie das zum irgendwie spackt es rum wir

1141
02:29:41,460 --> 02:29:47,940
warten mal kurz die minute ab es spämt es spämt immer noch heftig so requests und guck mal wir

1142
02:29:47,940 --> 02:29:56,820
haben eine millionen requests gemacht und nur und jetzt halt euch mal von einer millionen requests

1143
02:29:56,820 --> 02:30:06,580
sind nur während diesem rolling update 39 oder 40 requests mal als nicht erreichbar zurückgekommen

1144
02:30:06,580 --> 02:30:13,780
von einer millionen request 40 und wir haben unsere anwendung geupdatet im hintergrund ich

1145
02:30:13,780 --> 02:30:21,140
weiß wir hatten mal so einen krassen manager dude der gesagt hätte jetzt 40 requests dann sollten

1146
02:30:21,140 --> 02:30:25,300
wir uns jetzt mal auf die konzentrieren die nicht funktioniert haben haben wir vielleicht logs wo

1147
02:30:25,300 --> 02:30:31,300
wir die bangen können warum diese requests fehlgeschlagen sind aber ich glaube das ist

1148
02:30:31,300 --> 02:30:38,460
eine ganz gute ausbeute von einer millionen requests 40 requests fehlgeschlagen und das

1149
02:30:38,460 --> 02:30:47,620
während wir unsere anwendung geupdatet haben also das ist schwierig hinzukriegen anderweitig

1150
02:31:08,460 --> 02:31:22,020
hättest du 100 prozent wenn du kein crawling ab du meinst in rolling update machen würdest

1151
02:31:22,020 --> 02:31:31,100
die rolling update ist das beste was man machen kann du hast als du hast als auswahl sollst du

1152
02:31:31,100 --> 02:31:40,660
recreate ich bin den haus gebrauche ist das nix es gibt so verrückte leute auf youtube die

1153
02:31:40,660 --> 02:31:46,980
haben drei kubernetes cluster daheim ist unsinnig und was man an der stelle auch noch mal dazu sagen

1154
02:31:46,980 --> 02:31:51,780
muss wir haben jetzt ja ihren kubernetes cluster selbst erstellt und verwalten den kubernetes

1155
02:31:51,780 --> 02:32:01,500
cluster selbst normalerweise musst du dich mit so grundlegenden sachen wie skalierung und so gar

1156
02:32:01,500 --> 02:32:05,860
nicht großartig auseinandersetzen wenn du ein managed cluster also nicht einfach nur ein managed

1157
02:32:05,860 --> 02:32:10,900
cluster sondern so wenn du den autopilot cluster von google beispielsweise wenn es da brauchst du

1158
02:32:10,900 --> 02:32:16,100
nur noch deployments machen damit müssen wir uns auch noch beschäftigen die nächsten tage

1159
02:32:16,100 --> 02:32:24,380
oder versions updates versions updates von kubernetes und solche geschichte da musste

1160
02:32:24,380 --> 02:32:28,700
dich nicht mit beschäftigen wenn du managed cluster verwenden also vieles von diesen basic

1161
02:32:28,700 --> 02:32:36,140
sachen musst du gar nicht selbst machen zumal ich meine wenn du den benchmark jetzt ausführst sind

1162
02:32:36,140 --> 02:32:42,980
dann alle 100 prozent kann schauen wir mal ich lasse noch mal laufen kann durchaus sein dass die

1163
02:32:43,300 --> 02:32:52,020
meine cpu ist ja auch voll am anschlag dass die ein oder anderen requests einfach nicht nicht

1164
02:32:52,020 --> 02:32:58,860
richtig durchgehen also managed cluster kümmern sich um versions updates von kubernetes und so

1165
02:32:58,860 --> 02:33:03,540
was schon da hat man viel arbeit nicht mehr was aber eigentlich auch ganz gut ist weil ganz ehrlich

1166
02:33:03,540 --> 02:33:09,460
da hängt halt sehr viel so lowlevel kram dran wo es schwierig ist das alles das alles richtig

1167
02:33:09,460 --> 02:33:16,940
zu machen und was auch ein gewisses tiefgreifendes know-how erfordert alle staub

1168
02:33:16,940 --> 02:33:25,340
ja das waren die control set ich habe kein control set gemacht ich habe terminal auf und zu gemacht

1169
02:33:39,820 --> 02:33:45,900
ja jetzt habe ich eine millionen responses und zwar alles 200 ja also wir hatten tatsächlich

1170
02:33:45,900 --> 02:33:54,820
40 requests verlust in unserem upgrade gibt schlimmeres oder von eine millionen requests

1171
02:33:54,820 --> 02:34:02,900
ok chat wie hat es euch bis jetzt gefallen kubernetes stells

1172
02:34:10,460 --> 02:34:16,100
wie gesagt ich bin ich ich bin selbst nicht ich bin ja selbst nicht das super super

1173
02:34:16,100 --> 02:34:23,820
oberkombiniertes checker aber ich glaube so mit lokaler registry und so was hier das war

1174
02:34:23,820 --> 02:34:29,780
schon ganz cool dann lasst uns doch jetzt noch mal kurz eine viertelstunde überlegen was wir

1175
02:34:29,780 --> 02:34:43,340
als nächstes machen also als nächstes eine sache die mir eingefallen ist ja environment

1176
02:34:43,340 --> 02:34:57,540
variablen genau n so volume secrets cert manager das will ich unbedingt zeichen mit

1177
02:34:57,540 --> 02:35:08,100
let's encrypt lokal dns challenge na service mesh das ist jetzt schon ein

1178
02:35:08,100 --> 02:35:35,180
bisschen zu etwas dann vielleicht irgendwann noch mal ja und ends backends traffic gibt

1179
02:35:35,180 --> 02:35:38,620
naja bisschen ja ok

1180
02:35:38,620 --> 02:35:48,380
geht aber ich finde den namen so dass es da hat man eigentlich was recht logisches also was

1181
02:35:48,380 --> 02:35:53,860
naheliegendes so nach dem motto man checkt seine config in geht ein wieder super cool benannt

1182
02:35:53,860 --> 02:36:01,460
dazu kommt da natürlich aber auch noch so dinger wie automatische tests und also man könnte man

1183
02:36:01,780 --> 02:36:06,500
zum beispiel sogar solche dinger machen wie man ganz abgedreht weiterspinnen man könnte ja zum

1184
02:36:06,500 --> 02:36:12,100
beispiel sagen ok man hat noch eine test suite für diese test suite fürs jetzt super krasse

1185
02:36:12,100 --> 02:36:22,820
dort net anwendung und man lässt es dann irgendwie automatisch noch bilden und lässt die tests

1186
02:36:22,820 --> 02:36:29,380
durchlaufen und lässt sich dinger machen dann automatisch noch auf irgendeinem ce server das

1187
02:36:29,380 --> 02:36:36,940
image bauen dass man das nicht lokal machen muss so was in der richtung gibt ja gibt ja viele

1188
02:36:36,940 --> 02:36:41,860
viele dinger man kann ganz abgedrehte sachen machen ja also irgendwann was wir uns auf jeden

1189
02:36:41,860 --> 02:36:46,420
fall noch angucken ist das finde ich persönlich eine coole sache weil du damit weil du hiermit

1190
02:36:46,420 --> 02:36:53,980
kannst du solche manifest erstellen in pyson zum beispiel finde ich persönlich eine super

1191
02:36:53,980 --> 02:37:03,540
geschichte ist eigentlich overkill und komplett unsinnig für vieles aber ich persönlich finde es

1192
02:37:03,540 --> 02:37:14,380
sehr nice weil man halt zum beispiel so sachen definieren kann guck hier hier hier kann man zum

1193
02:37:14,380 --> 02:37:20,100
beispiel sagen hier cube service load balancer cube deployment also das was wir eben im manifest

1194
02:37:20,100 --> 02:37:25,420
definiert haben kann man hier drin der ja ich weiß man kann auch hellen und so was verwenden

1195
02:37:25,420 --> 02:37:29,940
ich persönlich würde dann aber fast sagen mir persönlich ist das hier finde ich den ansatz hier

1196
02:37:29,940 --> 02:37:37,540
cooler weil man dann vollständige programmier sprache und ich mache halt lieber das im source

1197
02:37:37,540 --> 02:37:45,620
code als irgendwelche jamme files und description files und so bauen also das ist cool ja hellen

1198
02:37:45,620 --> 02:37:50,860
müssen müssen wir uns aber der vollständigkeit halber auf jeden fall angucken weil fast jedes

1199
02:37:50,860 --> 02:37:58,740
zweite tutorial heißt ja in hellen repo enden und ausführen zum beispiel secret manager secret

1200
02:37:58,740 --> 02:38:08,380
manager sagt das auch customize habe ich keine ahnung von kein plan vielleicht können wir uns

1201
02:38:08,380 --> 02:38:12,460
irgendwann auch mal terraform noch in kombination mit dem kubernetes provider angucken habe ich

1202
02:38:12,460 --> 02:38:26,740
jetzt auch noch nicht gemacht dann gucken wir uns natürlich noch google cloud managed kubernetes

1203
02:38:26,740 --> 02:38:33,940
und auto autopilot an das ist der eigentliche grund warum ich mich in den letzten tagen wieder

1204
02:38:33,940 --> 02:38:38,260
ein bisschen mehr damit beschäftigt habe weil ich weiß dass bei meinem neuen arbeitgeber google

1205
02:38:38,260 --> 02:38:42,300
cloud mit wahrscheinlich managed kubernetes oder autopilot cluster vielleicht darf sogar ich

1206
02:38:42,300 --> 02:38:45,500
mir aussuchen was ich haben will einsetzen wer das heißt da muss ich ein bisschen gucken

1207
02:38:45,500 --> 02:38:55,660
metal lb ich habe keine ahnung was das ist ich kenne kong kong ist auch so ein

1208
02:38:55,660 --> 02:38:59,660
lautballon kein lautballon so ein api gateway ist das harambe

1209
02:39:05,180 --> 02:39:10,020
ich habe keine ahnung was es mir sagen soll ehrlich gesagt netwerk lautballon

1210
02:39:10,900 --> 02:39:19,660
was ja selbstverständlich da habe ich ja ganz vergessen das müssen wir noch mal hier

1211
02:39:19,660 --> 02:39:32,220
matrix ja matrix auch natürlich da müssen wir uns noch sidecar container angucken für so

1212
02:39:32,220 --> 02:39:41,660
monitoring und logs also ihr seht schon die einfache die bild in kubernetes sachen die

1213
02:39:41,660 --> 02:39:49,860
sind an sich recht easy ja kommt man recht schnell mit aber das ist ein loch ohne boden was da alles

1214
02:39:49,860 --> 02:39:55,060
dran hängt dann ja volumes volumes ja haben wir ja schon

1215
02:40:03,220 --> 02:40:10,700
und das was da dran ist wirklich ein fast ohne boden so bild in sachen den kubernetes jammel

1216
02:40:10,700 --> 02:40:15,740
eintragen apply ja kein ding aber dieses ganze zeug was hier noch dabei kommt das ist halt

1217
02:40:15,740 --> 02:40:24,220
extrem viel was es da gibt ja autodiscovery ja das sollten wir uns auch mal angucken ja ja genau

1218
02:40:24,220 --> 02:40:33,340
ne traffic prominent engine ich bin ich bin team engine ich habe traffic selbst auch schon

1219
02:40:33,340 --> 02:40:43,340
verwendet ich muss sagen ganz im ernst ich bleibe bei engine ich benutze kadi wenn super simpel

1220
02:40:43,340 --> 02:40:48,820
sein muss traffic von hand konfigurieren ist eh abfakt und traffic macht halt in so einem

1221
02:40:48,820 --> 02:40:53,340
umfeld hier schon irgendwie sinn weil es auch viele service discovery funktionen ganz ehrlich

1222
02:40:53,380 --> 02:40:58,700
aber es ist so easy in engine x ingress zu machen warum soll ich ja traffic verwenden

1223
02:40:58,700 --> 02:41:04,460
glaubt glaube ich einen bogen erst mal drum machen

1224
02:41:11,140 --> 02:41:11,460
ja

1225
02:41:11,460 --> 02:41:17,100
schreiben wir nochmal

1226
02:41:17,100 --> 02:41:28,300
dass wir uns das dann auch grafisch angucken können dahinter wenn euch noch was einfällt

1227
02:41:28,300 --> 02:41:32,540
könnt ihr ruhig auch im nächsten stream schreiben da können wir uns das noch angucken also wir

1228
02:41:32,540 --> 02:41:36,300
machen jetzt auf jeden fall erst mal weiter mit zert manager und environments und volumes und so

1229
02:41:36,300 --> 02:41:37,300
was im nächsten stream ist

1230
02:41:37,300 --> 02:41:49,660
ach du scheiße das ist nicht nice so nice jetzt fängt dieses wortling scheiße schon in deutschland

1231
02:41:49,660 --> 02:42:00,100
an oder was hat er seine adresse geleakt oder oder was war da mega für ein arsch man

1232
02:42:07,300 --> 02:42:18,260
ok leute ich wann machst du tiktok sein ja ich macht ich werd krasser kubernetes cloud native

1233
02:42:18,260 --> 02:42:24,420
influencer auf auf tiktok leute es ist fast 22 ich muss jetzt eh mal ins bett außerdem muss ich

1234
02:42:24,420 --> 02:42:33,540
mal ganz dringend kacken also das wird eine serie ja nicht unbedingt am stück nicht unbedingt am

1235
02:42:33,580 --> 02:42:41,260
stück jetzt kubernetes jeden stream bis wir mit allem durch den immer mal wieder machen wir machen

1236
02:42:41,260 --> 02:42:47,780
wir ja ok leute wir sehen uns dann bis denn zu

